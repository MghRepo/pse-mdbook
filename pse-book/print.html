<!DOCTYPE HTML>
<html lang="fr" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Fiches de préparation PSE</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Préface</a></li><li class="chapter-item expanded "><a href="PSE_Algo/index.html"><strong aria-hidden="true">1.</strong> Algorithmique et méthodes de programmation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/index.html"><strong aria-hidden="true">1.1.</strong> Structures de contrôles</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/structures-de-controles-sequentielles.html"><strong aria-hidden="true">1.1.1.</strong> Structures de contrôles séquentielles</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/structures-de-controles-iteratives.html"><strong aria-hidden="true">1.1.2.</strong> Structures de contrôles itératives</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/extensions-de-la-notion-de-boucle.html"><strong aria-hidden="true">1.1.3.</strong> Extension de la notion de boucle</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/sous-programmes.html"><strong aria-hidden="true">1.1.4.</strong> Sous-programmes</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/exceptions.html"><strong aria-hidden="true">1.1.5.</strong> Exceptions</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/programmation-multitache.html"><strong aria-hidden="true">1.1.6.</strong> Programmation multitâche</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_controles/programmation-evenementielle.html"><strong aria-hidden="true">1.1.7.</strong> Programmation événementielle</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Algo/algorithmes_de_tri/index.html"><strong aria-hidden="true">1.2.</strong> Algorithmes de tri</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Algo/algorithmes_de_tri/critere-de-classification.html"><strong aria-hidden="true">1.2.1.</strong> Critère de classification</a></li><li class="chapter-item expanded "><a href="PSE_Algo/algorithmes_de_tri/exemples-dalgorithmes-de-tri.html"><strong aria-hidden="true">1.2.2.</strong> Exemples d'algorithmes de tri</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/index.html"><strong aria-hidden="true">1.3.</strong> Structures de données</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/pile.html"><strong aria-hidden="true">1.3.1.</strong> Pile</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/file.html"><strong aria-hidden="true">1.3.2.</strong> File</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/liste.html"><strong aria-hidden="true">1.3.3.</strong> Liste</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/arbre-enracine.html"><strong aria-hidden="true">1.3.4.</strong> Arbre enraciné</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/arbre-binaire-de-recherche.html"><strong aria-hidden="true">1.3.5.</strong> Arbre binaire de recherche</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/arbre-b.html"><strong aria-hidden="true">1.3.6.</strong> Arbre B</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/arbre-rouge-noir.html"><strong aria-hidden="true">1.3.7.</strong> Arbre rouge-noir</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/tas.html"><strong aria-hidden="true">1.3.8.</strong> Tas</a></li><li class="chapter-item expanded "><a href="PSE_Algo/structures_de_donnees/table-de-hachage.html"><strong aria-hidden="true">1.3.9.</strong> Table de hachage</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Algo/algorithmes_de_chiffrements/index.html"><strong aria-hidden="true">1.4.</strong> Algorithmes de chiffrements</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Algo/algorithmes_de_chiffrements/chiffrement-symetrique-aes.html"><strong aria-hidden="true">1.4.1.</strong> Chiffrement symétrique AES</a></li><li class="chapter-item expanded "><a href="PSE_Algo/algorithmes_de_chiffrements/chiffrement-asymetrique-rsa.html"><strong aria-hidden="true">1.4.2.</strong> Chiffrement asymétrique RSA</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Algo/programmation-orientee-objet.html"><strong aria-hidden="true">1.5.</strong> Programmation orientée objet</a></li><li class="chapter-item expanded "><a href="PSE_Algo/compilation.html"><strong aria-hidden="true">1.6.</strong> Compilation</a></li><li class="chapter-item expanded "><a href="PSE_Algo/api/index.html"><strong aria-hidden="true">1.7.</strong> API</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Algo/api/soap.html"><strong aria-hidden="true">1.7.1.</strong> SOAP</a></li><li class="chapter-item expanded "><a href="PSE_Algo/api/rest.html"><strong aria-hidden="true">1.7.2.</strong> REST</a></li><li class="chapter-item expanded "><a href="PSE_Algo/api/graphql.html"><strong aria-hidden="true">1.7.3.</strong> GraphQL</a></li><li class="chapter-item expanded "><a href="PSE_Algo/api/grpc.html"><strong aria-hidden="true">1.7.4.</strong> gRPC</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="PSE_Sys/index.html"><strong aria-hidden="true">2.</strong> Système</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/index.html"><strong aria-hidden="true">2.1.</strong> Processus et mécanismes de communication</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/multitache-cooperatif.html"><strong aria-hidden="true">2.1.1.</strong> Multitâche coopératif</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/multitache-preemptif.html"><strong aria-hidden="true">2.1.2.</strong> Multitâche préemptif</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/algorithmes-dordonnancement.html"><strong aria-hidden="true">2.1.3.</strong> Algorithmes d'ordonnancement</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/synchronisation.html"><strong aria-hidden="true">2.1.4.</strong> Synchronisation</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/signaux.html"><strong aria-hidden="true">2.1.5.</strong> Signaux</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/socket-reseau.html"><strong aria-hidden="true">2.1.6.</strong> Socket réseau</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/socket-ipc.html"><strong aria-hidden="true">2.1.7.</strong> Socket IPC</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/socket-netlink.html"><strong aria-hidden="true">2.1.8.</strong> Socket Netlink</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/tube-anonyme.html"><strong aria-hidden="true">2.1.9.</strong> Tube anonyme</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/tube-nomme.html"><strong aria-hidden="true">2.1.10.</strong> Tube nommé</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/passage-de-messages.html"><strong aria-hidden="true">2.1.11.</strong> Passage de messages</a></li><li class="chapter-item expanded "><a href="PSE_Sys/processus_et_mecanismes_de_communication/d-bus.html"><strong aria-hidden="true">2.1.12.</strong> D-Bus</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_de_la_memoire_centrale/index.html"><strong aria-hidden="true">2.2.</strong> Gestion de la mémoire centrale</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Sys/gestion_de_la_memoire_centrale/fichier-mappe-en-memoire.html"><strong aria-hidden="true">2.2.1.</strong> Fichier mappé en mémoire</a></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_de_la_memoire_centrale/memoire-virtuelle.html"><strong aria-hidden="true">2.2.2.</strong> Mémoire virtuelle</a></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_de_la_memoire_centrale/pagination.html"><strong aria-hidden="true">2.2.3.</strong> Pagination</a></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_de_la_memoire_centrale/segmentation.html"><strong aria-hidden="true">2.2.4.</strong> Segmentation</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_des_peripheriques/index.html"><strong aria-hidden="true">2.3.</strong> Gestion des périphériques</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Sys/gestion_des_peripheriques/pilotes.html"><strong aria-hidden="true">2.3.1.</strong> Pilotes</a></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_des_peripheriques/sysfs.html"><strong aria-hidden="true">2.3.2.</strong> Sysfs</a></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_des_peripheriques/udev.html"><strong aria-hidden="true">2.3.3.</strong> Udev</a></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_des_peripheriques/bus.html"><strong aria-hidden="true">2.3.4.</strong> Bus</a></li><li class="chapter-item expanded "><a href="PSE_Sys/gestion_des_peripheriques/acces-direct-a-la-memoire.html"><strong aria-hidden="true">2.3.5.</strong> Accès direct à la mémoire</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/index.html"><strong aria-hidden="true">2.4.</strong> Éléments de démarrage</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/bios.html"><strong aria-hidden="true">2.4.1.</strong> BIOS</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/uefi.html"><strong aria-hidden="true">2.4.2.</strong> UEFI</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/partitionnement-de-la-memoire.html"><strong aria-hidden="true">2.4.3.</strong> Partitionnement de la mémoire</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/mbr.html"><strong aria-hidden="true">2.4.4.</strong> MBR</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/gpt.html"><strong aria-hidden="true">2.4.5.</strong> GPT</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/lvm.html"><strong aria-hidden="true">2.4.6.</strong> LVM</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/raid.html"><strong aria-hidden="true">2.4.7.</strong> RAID</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/dm-crypt.html"><strong aria-hidden="true">2.4.8.</strong> Dm-crypt</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/luks.html"><strong aria-hidden="true">2.4.9.</strong> LUKS</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/chargeur-damorçage.html"><strong aria-hidden="true">2.4.10.</strong> Chargeur d'amorçage</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/initramfs.html"><strong aria-hidden="true">2.4.11.</strong> Initramfs</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/noyau.html"><strong aria-hidden="true">2.4.12.</strong> Noyau</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/talon-de-demarrage-uefi-et-image-noyau-unifiee.html"><strong aria-hidden="true">2.4.13.</strong> Talon de démarrage UEFI et Image noyau unifiée</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/cgroups.html"><strong aria-hidden="true">2.4.14.</strong> Cgroups</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/espaces-de-noms.html"><strong aria-hidden="true">2.4.15.</strong> Espaces de noms</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/systemd.html"><strong aria-hidden="true">2.4.16.</strong> Systemd</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_demarrage/shell.html"><strong aria-hidden="true">2.4.17.</strong> Shell</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/index.html"><strong aria-hidden="true">2.5.</strong> Éléments de sécurité</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/secure-shell.html"><strong aria-hidden="true">2.5.1.</strong> Secure Shell</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/openssh.html"><strong aria-hidden="true">2.5.2.</strong> OpenSSH</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/netfilter.html"><strong aria-hidden="true">2.5.3.</strong> Netfilter</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/bpf-et-ebpf.html"><strong aria-hidden="true">2.5.4.</strong> BPF et eBPF</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/ids.html"><strong aria-hidden="true">2.5.5.</strong> IDS</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/controle-dacces-discretionnaire-et-droits.html"><strong aria-hidden="true">2.5.6.</strong> Contrôle d'accès discrétionnaire et droits</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/listes-de-controle-dacces-ACL.html"><strong aria-hidden="true">2.5.7.</strong> Listes de contrôle d'accès ACL</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/seLinux.html"><strong aria-hidden="true">2.5.8.</strong> SELinux</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/pam.html"><strong aria-hidden="true">2.5.9.</strong> PAM</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/sudo.html"><strong aria-hidden="true">2.5.10.</strong> Sudo</a></li><li class="chapter-item expanded "><a href="PSE_Sys/elements_de_securite/auditd.html"><strong aria-hidden="true">2.5.11.</strong> Auditd</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/index.html"><strong aria-hidden="true">2.6.</strong> Virtualisation et conteneurisation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/chroot.html"><strong aria-hidden="true">2.6.1.</strong> Chroot</a></li><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/systemd-nspawn.html"><strong aria-hidden="true">2.6.2.</strong> Systemd-nspawn</a></li><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/conteneurisation-lxc.html"><strong aria-hidden="true">2.6.3.</strong> Conteneurisation LXC</a></li><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/conteneurisation-docker.html"><strong aria-hidden="true">2.6.4.</strong> Conteneurisation Docker</a></li><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/orchestrateur-kubernetes.html"><strong aria-hidden="true">2.6.5.</strong> Orchestrateur Kubernetes</a></li><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/libvirt.html"><strong aria-hidden="true">2.6.6.</strong> Libvirt</a></li><li class="chapter-item expanded "><a href="PSE_Sys/virtualisation_et_conteneurisation/hyperviseurs.html"><strong aria-hidden="true">2.6.7.</strong> Hyperviseurs</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="PSE_Don/index.html"><strong aria-hidden="true">3.</strong> Données</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Don/bases_de_donnees/index.html"><strong aria-hidden="true">3.1.</strong> Bases de données</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Don/bases_de_donnees/crud.html"><strong aria-hidden="true">3.1.1.</strong> CRUD</a></li><li class="chapter-item expanded "><a href="PSE_Don/bases_de_donnees/acid.html"><strong aria-hidden="true">3.1.2.</strong> ACID</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Don/algebre-relationnelle.html"><strong aria-hidden="true">3.2.</strong> Algèbre relationnelle</a></li><li class="chapter-item expanded "><a href="PSE_Don/administration-sgbdr-postgresql/index.html"><strong aria-hidden="true">3.3.</strong> Administration SGBDR PostgreSQL</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Don/administration-sgbdr-postgresql/stockage-et-replication.html"><strong aria-hidden="true">3.3.1.</strong> Stockage et réplication</a></li><li class="chapter-item expanded "><a href="PSE_Don/administration-sgbdr-postgresql/controle-et-connectivite.html"><strong aria-hidden="true">3.3.2.</strong> Contrôle et connectivité</a></li><li class="chapter-item expanded "><a href="PSE_Don/administration-sgbdr-postgresql/securite.html"><strong aria-hidden="true">3.3.3.</strong> Sécurité</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Don/big-data-et-lac-de-donnees.html"><strong aria-hidden="true">3.4.</strong> Big data et lac de données</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Res/index.html"><strong aria-hidden="true">4.</strong> Réseau</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Res/topologie_de_reseau/index.html"><strong aria-hidden="true">4.1.</strong> Topologie de réseau</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Res/topologie_de_reseau/liens.html"><strong aria-hidden="true">4.1.1.</strong> Liens</a></li><li class="chapter-item expanded "><a href="PSE_Res/topologie_de_reseau/noeuds.html"><strong aria-hidden="true">4.1.2.</strong> Noeuds</a></li><li class="chapter-item expanded "><a href="PSE_Res/topologie_de_reseau/classification.html"><strong aria-hidden="true">4.1.3.</strong> Classification</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Res/vlan.html"><strong aria-hidden="true">4.2.</strong> VLAN</a></li><li class="chapter-item expanded "><a href="PSE_Res/vpn.html"><strong aria-hidden="true">4.3.</strong> VPN</a></li><li class="chapter-item expanded "><a href="PSE_Res/nas.html"><strong aria-hidden="true">4.4.</strong> NAS</a></li><li class="chapter-item expanded "><a href="PSE_Res/san.html"><strong aria-hidden="true">4.5.</strong> SAN</a></li><li class="chapter-item expanded "><a href="PSE_Res/modele-osi.html"><strong aria-hidden="true">4.6.</strong> Modèle OSI</a></li><li class="chapter-item expanded "><a href="PSE_Res/architecture-tcpip.html"><strong aria-hidden="true">4.7.</strong> Architecture TCP/IP</a></li><li class="chapter-item expanded "><a href="PSE_Res/protocoles/index.html"><strong aria-hidden="true">4.8.</strong> Protocoles</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Res/protocoles/couche-application.html"><strong aria-hidden="true">4.8.1.</strong> Couche application</a></li><li class="chapter-item expanded "><a href="PSE_Res/protocoles/couche-transport.html"><strong aria-hidden="true">4.8.2.</strong> Couche transport</a></li><li class="chapter-item expanded "><a href="PSE_Res/protocoles/couche-reseau.html"><strong aria-hidden="true">4.8.3.</strong> Couche réseau</a></li><li class="chapter-item expanded "><a href="PSE_Res/protocoles/couche-liaison.html"><strong aria-hidden="true">4.8.4.</strong> Couche liaison</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Res/mib.html"><strong aria-hidden="true">4.9.</strong> MIB</a></li><li class="chapter-item expanded "><a href="PSE_Res/active-directory.html"><strong aria-hidden="true">4.10.</strong> Active Directory</a></li><li class="chapter-item expanded "><a href="PSE_Res/samba.html"><strong aria-hidden="true">4.11.</strong> Samba</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Log/index.html"><strong aria-hidden="true">5.</strong> Logiciels</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Log/architecture_logicielle/index.html"><strong aria-hidden="true">5.1.</strong> Architecture logicielle</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Log/architecture_logicielle/client-serveur.html"><strong aria-hidden="true">5.1.1.</strong> Client serveur</a></li><li class="chapter-item expanded "><a href="PSE_Log/architecture_logicielle/trois-niveaux.html"><strong aria-hidden="true">5.1.2.</strong> Trois niveaux</a></li><li class="chapter-item expanded "><a href="PSE_Log/architecture_logicielle/n-tiers.html"><strong aria-hidden="true">5.1.3.</strong> N-tiers</a></li><li class="chapter-item expanded "><a href="PSE_Log/architecture_logicielle/modele-vue-controleur.html"><strong aria-hidden="true">5.1.4.</strong> Modèle-Vue-Contrôleur</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Log/haute-disponibilite.html"><strong aria-hidden="true">5.2.</strong> Haute disponibilité</a></li><li class="chapter-item expanded "><a href="PSE_Log/langages-de-presentation.html"><strong aria-hidden="true">5.3.</strong> Langages de présentation</a></li><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/index.html"><strong aria-hidden="true">5.4.</strong> Construction et automatisation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/maven.html"><strong aria-hidden="true">5.4.1.</strong> Maven</a></li><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/jenkins.html"><strong aria-hidden="true">5.4.2.</strong> Jenkins</a></li><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/cobbler.html"><strong aria-hidden="true">5.4.3.</strong> Cobbler</a></li><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/puppet.html"><strong aria-hidden="true">5.4.4.</strong> Puppet</a></li><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/ansible.html"><strong aria-hidden="true">5.4.5.</strong> Ansible</a></li><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/vagrant.html"><strong aria-hidden="true">5.4.6.</strong> Vagrant</a></li><li class="chapter-item expanded "><a href="PSE_Log/construction_et_automatisation/terraform.html"><strong aria-hidden="true">5.4.7.</strong> Terraform</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Log/metrologie-et-supervision-nagios.html"><strong aria-hidden="true">5.5.</strong> Métrologie et supervision Nagios</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Env/index.html"><strong aria-hidden="true">6.</strong> Environnement</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Env/normalisation/index.html"><strong aria-hidden="true">6.1.</strong> Normalisation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Env/normalisation/itil.html"><strong aria-hidden="true">6.1.1.</strong> ITIL</a></li><li class="chapter-item expanded "><a href="PSE_Env/normalisation/cobit.html"><strong aria-hidden="true">6.1.2.</strong> COBIT</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Env/notions_generales_sur_le_droit_de_linformatique/index.html"><strong aria-hidden="true">6.2.</strong> Notions générales sur le droit de l'informatique</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Env/notions_generales_sur_le_droit_de_linformatique/protection-des-donnees-individuelles.html"><strong aria-hidden="true">6.2.1.</strong> Protection des données individuelles</a></li><li class="chapter-item expanded "><a href="PSE_Env/notions_generales_sur_le_droit_de_linformatique/lusage-de-la-messagerie.html"><strong aria-hidden="true">6.2.2.</strong> L'usage de la messagerie</a></li><li class="chapter-item expanded "><a href="PSE_Env/notions_generales_sur_le_droit_de_linformatique/role-de-la-cnil.html"><strong aria-hidden="true">6.2.3.</strong> Rôle de la CNIL</a></li><li class="chapter-item expanded "><a href="PSE_Env/notions_generales_sur_le_droit_de_linformatique/licences.html"><strong aria-hidden="true">6.2.4.</strong> Licences</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Env/organisation_du_travail/index.html"><strong aria-hidden="true">6.3.</strong> Organisation du travail</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Env/organisation_du_travail/methode-agile.html"><strong aria-hidden="true">6.3.1.</strong> Méthode agile</a></li><li class="chapter-item expanded "><a href="PSE_Env/organisation_du_travail/devops.html"><strong aria-hidden="true">6.3.2.</strong> Devops</a></li></ol></li><li class="chapter-item expanded "><a href="PSE_Env/fonctions-de-pse.html"><strong aria-hidden="true">6.4.</strong> Fonctions de PSE</a></li><li class="chapter-item expanded "><a href="PSE_Env/plan_de_secours/index.html"><strong aria-hidden="true">6.5.</strong> Plan de secours</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="PSE_Env/plan_de_secours/plan-de-continuite-dactivite.html"><strong aria-hidden="true">6.5.1.</strong> Plan de continuité d'activité</a></li><li class="chapter-item expanded "><a href="PSE_Env/plan_de_secours/plan-de-reprise-dactivite.html"><strong aria-hidden="true">6.5.2.</strong> Plan de reprise d'activité</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="shell_introduction/index.html"><strong aria-hidden="true">7.</strong> Introduction au Shell</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="shell_introduction/quest-ce-que-le-shell.html"><strong aria-hidden="true">7.1.</strong> Qu'est-ce que le shell ?</a></li><li class="chapter-item expanded "><a href="shell_introduction/les-chemins.html"><strong aria-hidden="true">7.2.</strong> Les chemins</a></li><li class="chapter-item expanded "><a href="shell_introduction/lister-le-contenu-dun-repertoire-et-droits.html"><strong aria-hidden="true">7.3.</strong> Lister le contenu d'un répertoire et droits</a></li><li class="chapter-item expanded "><a href="shell_introduction/dautres-commandes.html"><strong aria-hidden="true">7.4.</strong> D'autres commandes</a></li><li class="chapter-item expanded "><a href="shell_introduction/redirection-dentreesortie-descripteurs-de-fichiers-et-tubes.html"><strong aria-hidden="true">7.5.</strong> Redirection d'entrée/sortie, descripteurs de fichiers et tubes</a></li><li class="chapter-item expanded "><a href="shell_introduction/un-outil-versatile-et-puissant.html"><strong aria-hidden="true">7.6.</strong> Un outil versatile et puissant</a></li><li class="chapter-item expanded "><a href="shell_introduction/scripts-shell.html"><strong aria-hidden="true">7.7.</strong> Scripts shell</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Fiches de préparation PSE</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="programme-informatique-du-concours-dinspecteur-pse"><a class="header" href="#programme-informatique-du-concours-dinspecteur-pse">Programme informatique du concours d'inspecteur PSE</a></h1>
<h4 id="introduction"><a class="header" href="#introduction">Introduction</a></h4>
<p>Ce livre est une compilation de mes fiches de préparation pour le concours d'inspecteur PSE concernant le <a href="https://www.economie.gouv.fr/recrutement/aide-a-preparation-concours-interne-dinspecteur-programmeur-systeme-dexploitation-pse-de">programme
informatique</a>.
J'ai séparé les différentes grandes parties du programme en six chapitres plus un chapitre supplémentaire d'introduction au
shell.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="algorithmique-et-méthodes-de-programmation"><a class="header" href="#algorithmique-et-méthodes-de-programmation">Algorithmique et méthodes de programmation</a></h1>
<h4 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h4>
<p>Ce chapitre traite de la partie algorithmique et méthodes de programmation du programme PSE.</p>
<p>Les trois premières parties présentent les bases de l'algorithmique avec les structures de contrôle, les tris et les structures
de données. La quatrième partie traite très rapidement du sujet hautement important des algorithmes de chiffrements. La
cinquième présente succinctement la POO. La sixième survole les mécanismes de la compilation et traite de la différence entre
langage compilé et langage interprété. Enfin la dernière partie traite des APIs (utilisés dans les échanges de données
inter-applicatifs) des spécifications SOAP, REST et de leurs évolutions récentes : GraphQL de Facebook et gRPC de Google.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle"><a class="header" href="#structures-de-contrôle">Structures de contrôle</a></h2>
<p>En programmation informatique, une structure de contrôle est une instruction particulière à un langage de programmation
impératif pouvant dévier le flot de contrôle du programme la contenant lorsqu'elle est exécutée. Si, au plus bas niveau,
l'éventail se limite généralement aux branchements et aux appels de sous-programme, les langages structurés offrent des
constructions plus élaborées comme les alternatives (if, if-else, switch...), les boucles (while, do-while, for...) ou encore
les appels de fonction. Outre les structures usuelles, la large palette des structures de contrôle s'étend des constructions de
gestion d'exceptions (try-catch...) fréquemment trouvés dans les langages de haut niveau aux particularismes de certains
langages comme les instructions différées (defer) de Go.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle-1"><a class="header" href="#structures-de-contrôle-1">Structures de contrôle</a></h2>
<h3 id="structures-de-contrôle-séquentielles"><a class="header" href="#structures-de-contrôle-séquentielles">Structures de contrôle séquentielles</a></h3>
<p>Un programme informatique impératif est une suite d'instructions. Un registre interne de processeur, le compteur ordinal (PC),
est chargé de mémoriser l'adresse de la prochaine instruction à exécuter.</p>
<p>La plupart des instructions d'un programme sont exécutées séquentiellement : après le traitement de l'instruction courante le
compteur ordinal est incrémenté, et la prochaine instruction est chargée.</p>
<p>La séquence est donc la structure de contrôle implicite. Elle donne l'ordre d'exécution des instructions, souvent séparées par
un point-virgule ou par des retours chariots.</p>
<p>Un programme s'arrête généralement après l'exécution de la dernière instruction. La plupart des langages de programmation
proposent également une ou plusieurs instructions pour stopper l'exécution du programme à une position arbitraire.</p>
<p>Selon l'environnement d'exécution sous-jacent (système d'exploitation ou microprocesseur), cet arrêt peut être définitif ou
correspondre à une suspension de l'exécution du programme en attendant un évènement externe : c'est par exemple le
fonctionnement habituel de la plupart des instructions d'entrée sorties qui bloquent le flot d'exécution (mécanisme
d'interruption avec stockage en mémoire tampon) jusqu'à ce que le périphérique concerné ait terminé de traiter les données.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle-2"><a class="header" href="#structures-de-contrôle-2">Structures de contrôle</a></h2>
<h3 id="structures-de-contrôle-itératives"><a class="header" href="#structures-de-contrôle-itératives">Structures de contrôle itératives</a></h3>
<p>Ces instructions permettent de réaliser une machine à états finis, cela signifie que leur seul effet de bord est de modifier un
registre qui correspond à l'état courant du programme.</p>
<p>Dans un processeur, cet état correspond à la valeur du compteur ordinal.</p>
<p>Commandes à étiquettes :</p>
<ul>
<li>Sauts inconditionnels</li>
<li>Sauts conditionnels</li>
<li>Sous programmes, commandes de sorties de boucles</li>
</ul>
<p>Commandes de blocs :</p>
<ul>
<li>Blocs d'instructions</li>
<li>Alternatives (if, then, else, switch)</li>
<li>Boucles (do, while, each)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle-3"><a class="header" href="#structures-de-contrôle-3">Structures de contrôle</a></h2>
<h3 id="extensions-de-la-notion-de-boucles"><a class="header" href="#extensions-de-la-notion-de-boucles">Extensions de la notion de boucles</a></h3>
<p>Un compteur permet de réaliser une boucle associée à une variable entière ou un pointeur qui sera incrémenté à chaque itération.
Il est souvent utilisé pour exploiter les données d'une collection indexée (boucle for).</p>
<p>Un itérateur (ou curseur ou énumérateur) est un objet qui permet de réaliser une boucle parcourant tous les éléments contenus
dans une structure de données.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle-4"><a class="header" href="#structures-de-contrôle-4">Structures de contrôle</a></h2>
<h3 id="sous-programmes"><a class="header" href="#sous-programmes">Sous-programmes</a></h3>
<p>Un sous-programme permet la réutilisation d'une partie du code et ainsi le développement des algorithmes récursifs.</p>
<p>Beaucoup de langages modernes ne supportent pas directement la notion de sous-programme au profit de constructions de haut
niveau qui peuvent être appelées, d'un langage à l'autre <strong>procédure, fonction, méthode</strong>, ou <strong>routine</strong>. Ces constructions
ajoutent la notion de passage de paramètres et surtout le cloisonnement des espaces de noms pour éviter que le sous-programme
ait un effet de bord sur la routine appelante.</p>
<p>Il existe diverses extensions à la notion de procédure comme les coroutines (routine avec suspension), signaux, et slots
(signaux implémentés pour les objets), fonctions de rappel (callback, traitement post-fonction), méthodes virtuelles
(programmation par contrat, méthode implémentée dans les classes héritées) Elles permettent de modifier dynamiquement, c'est à
dire à l'exécution, la structure du flot d'exécution du programme.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle-5"><a class="header" href="#structures-de-contrôle-5">Structures de contrôle</a></h2>
<h3 id="exceptions"><a class="header" href="#exceptions">Exceptions</a></h3>
<p>Tout programme en exécution peut être sujet à des erreurs pour lesquelles des stratégies de détection et de réparation sont
possibles. Ces erreurs ne sont pas des bugs mais des conditions exceptionnelles dans le déroulement normal d'une partie d'un
programme.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle-6"><a class="header" href="#structures-de-contrôle-6">Structures de contrôle</a></h2>
<h3 id="programmation-multitâche"><a class="header" href="#programmation-multitâche">Programmation multitâche</a></h3>
<p>Dans un système multitâche, plusieurs flots d'exécutions, appelés processus légers, s'exécutent simultanément.</p>
<p>Il est alors nécessaire d'assurer la synchronisation de ces flots d'exécution. Dans la plupart des langages, cela est réalisé
via des bibliothèques externes ; certains d'entre eux intègrent néanmoins des structures de contrôle permettant d'agir sur des
tâches concourantes.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-contrôle-7"><a class="header" href="#structures-de-contrôle-7">Structures de contrôle</a></h2>
<h3 id="programmation-événementielle"><a class="header" href="#programmation-événementielle">Programmation événementielle</a></h3>
<p>La programmation évènementielle est une autre façon de contrôler le flot d'exécution d'un programme. Il s'agit de créer des
gestionnaires qui viendront s'abonner à une boucle mère, chargée d'aiguiller les évènements qui affectent le logiciel.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algorithmes-de-tri"><a class="header" href="#algorithmes-de-tri">Algorithmes de tri</a></h2>
<p>Un algorithme de tri est, en informatique ou en mathématiques, un algorithme qui permet d'organiser une collection d'objets
selon une relation d'ordre déterminée. Les objets à trier sont des éléments d'un ensemble muni d'un ordre total. Il est par
exemple fréquent de trier des entiers selon la relation d'ordre usuelle &quot;est inférieur ou égal à&quot;. Les algorithmes de tris sont
utilisés dans de très nombreuses situations. Ils sont en particulier utiles à de nombreux algorithmes plus complexes dont
certains algorithmes de recherche, comme la recherche dichotomique. Ils peuvent également servir pour mettre des données sous
forme canonique ou les rendre plus lisibles pour l'utilisateur.</p>
<p>La collection à trier est souvent donnée sous forme de tableau, afin de permettre l'accès direct aux différents éléments de la
collection, ou sous forme de liste, ce qui peut se révéler être plus adapté à certains algorithmes et l'usage de la
programmation fonctionnelle.</p>
<p>Bon nombre d'algorithmes de tri procèdent par comparaisons successives, et peuvent donc être définis indépendamment de
l'ensemble auquel appartiennent les éléments de la relation d'ordre associée. Un même algorithme peut par exemple être utilisé
pour trier les réels selon la relation d'ordre usuelle &quot;est inférieur ou égal à&quot; et des chaînes de caractères selon l'ordre
lexicographique. Ces algorithmes se prêtent naturellement à une implémentation polymorphe (différents types).</p>
<p>Les algorithmes de tri sont souvent étudiés dans les cours d'algorithmique pour introduire des notions comme la complexité
algorithmique ou la terminaison.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algorithmes-de-tri-1"><a class="header" href="#algorithmes-de-tri-1">Algorithmes de tri</a></h2>
<h3 id="critère-de-classification"><a class="header" href="#critère-de-classification">Critère de classification</a></h3>
<p>La classification des algorithmes de tri est très importante, car elle permet de choisir l'algorithme le plus adapté au problème
traité, tout en tenant compte des contraintes imposées par celui-ci. Les principales caractéristiques qui permettent de
différencier les algorithmes de tri, outre leur principe de fonctionnement, sont la complexité temporelle, la complexité
spatiale et le caractère stable.</p>
<p>La complexité temporelle (en moyenne ou dans le pire des cas) mesure le nombre d'opérations élémentaires effectuées pour trier
une collection d'éléments. C'est un critère majeur pour comparer les algorithmes de tri, puisque c'est une estimation directe du
temps d'exécution de l'algorithme. Dans le cas des algorithmes de tri par comparaison, la complexité en temps est le plus
souvent assimilable au nombre de comparaisons effectuées, la comparaison et l'échange éventuel de deux valeurs s'effectuant en
temps constant.</p>
<p>La complexité spatiale (en moyenne ou dans le pire des cas) représente, quant à elle, la quantité de mémoire dont va avoir
besoin l'algorithme pour s'exécuter. Celle-ci peut dépendre, comme le temps d'exécution, de la taille de l'entrée. Il est
fréquent que les complexités spatiales en moyenne et dans le pire des cas soient identiques. C'est souvent le cas lorsqu'une
complexité est donnée sans indication supplémentaire.</p>
<p>Un tri est dit <em>en place</em> s'il n'utilise qu'un nombre très limité de variables et qu'il modifie directement la structure qu'il
est en train de trier. Ceci nécessite l'utilisation d'une structure de donnée adaptée (un tableau par exemple). Ce caractère
peut être très important si on ne dispose pas de beaucoup de mémoire.</p>
<p>Toutefois, on ne déplace pas, en général, les données elles-mêmes, mais on modifie seulement des références (ou pointeurs) vers
ces dernières.</p>
<p>Un tri est dit <em>stable</em> s'il préserve l'ordonnancement initial des éléments que l'ordre considère comme égaux (tri à bulles, tri
par insertion et le tri par fusion).</p>
<p>Un tri <em>interne</em> s'effectue entièrement en mémoire centrale tandis qu'un tris <em>externe</em> utilise des fichiers sur une mémoire de
masse pour trier des volumes trop importants pour pouvoir tenir en mémoire centrale.</p>
<p>Certains algorithmes permettent d'exploiter les capacités multitâches de la machine. Notons également, que certains algorithmes,
notamment ceux qui fonctionnent par insertion, peuvent être lancés sans connaître l'intégralité des données à trier; on peut
alors trier et produire les données à trier en parallèle.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algorithmes-de-tri-2"><a class="header" href="#algorithmes-de-tri-2">Algorithmes de tri</a></h2>
<h3 id="exemples-dalgorithmes-de-tri"><a class="header" href="#exemples-dalgorithmes-de-tri">Exemples d'algorithmes de tri</a></h3>
<h4 id="algorithmes-rapides-tnonlog-n"><a class="header" href="#algorithmes-rapides-tnonlog-n">Algorithmes rapides <em>T(n)=O(n.log n)</em></a></h4>
<ul>
<li><strong>Tri fusion</strong> (<em>merge sort</em>) : Pour une entrée donnée, l'algorithme la divise en deux parties de tailles similaires, trie
chacune d'elles en utilisant le même algorithme, puis fusionne les deux parties triées. Il se prête aussi bien à des
implémentations sur listes que sur tableaux.</li>
<li><strong>Tri rapide</strong> (<em>quick sort</em>) : Une valeur est choisie comme pivot et les éléments plus petits que le pivot sont dissociés,
par échanges successifs, des éléments plus grands que le pivot ; chacun de ces deux sous-ensembles est ensuite trié de la même
manière. On peut rendre la complexité quasiment indépendante des données en utilisant un pivot aléatoire ou en appliquant au
tableau une permutation aléatoire avant de le trier.</li>
<li><strong>Tri par tas</strong> (<em>heap sort</em>) : Il s'agit d'une amélioration du tri par sélection. L'idée est la même (insérer les élément un
à un dans une structure déjà triée) mais l'algorithme utilise une structure de tas, souvent implémentée au moyen d'un tableau.</li>
<li><strong>Tri introspectif</strong> (<em>Introspective sort</em>) : Il s'agit d'un hybride du tri rapide et du tri par tas. Par rapport au tri
rapide, il présente l'avantage d'avoir une complexité <em>O(n.log n)</em> dans le pire cas.</li>
<li><strong>Tri arborescent</strong> (<em>tree sort</em>): L'idée est d'insérer les éléments un à un dans l'arbre binaire de recherche, puis de lire
l'arbre selon un parcours en profondeur. Un arbre binaire de recherche(ABR) est un arbre binaire dans lequel chaque noeud
possède une clé, telle que chaque noeud du sous-arbre <em>gauche</em> ait une clé inférieure ou égale à celle du noeud considéré, et
que chaque noeud du sous-arbre <em>droit</em> possède une clé supérieure ou égale à celle-ci.</li>
<li><strong>Tri doux</strong> (<em>smoothsort</em>) : La première étape consiste à transformer le tableau en arbre binaire. Le premier élément est
déjà trivialement bien ordonné, puis on ajoute un à un les éléments suivants. On réordonne chaque fois un peu les éléments si
nécessaire pour qu'ils correspondent aux critères :
<ul>
<li>Chaque noeud ne peut être supérieur à son noeud parent.</li>
<li>Le premier noeud enfant ne peut être supérieur au deuxième noeud enfant.</li>
</ul>
</li>
</ul>
<p>La deuxième étape consiste à retransformer l'arbre binaire en tableau trié. Chaque élément en partant de la droite est laissé
tel quel car il s'agit de la racine de l'arbre qui est déjà le plus grand élément, et l'arbre restant est réordonné si
nécessaire. On fait ceci jusqu'à arriver à un tableau trié.</p>
<h4 id="algorithmes-moyennement-rapides"><a class="header" href="#algorithmes-moyennement-rapides">Algorithmes moyennement rapides</a></h4>
<ul>
<li><strong>Tri de Shell</strong> (<em>shell sort</em>) : Ce tri repose sur le tri par insertion des sous-suites de l'entrée obtenues en prenant les
éléments espacés d'un pas constant, pour une suite de pas prédéfinie. La complexité varie selon le choix de cette suite.</li>
<li><strong>Tri à peigne</strong> (<em>comb sort</em>) : Il s'agit d'une variante plus efficace du tri à bulles, ne comparant pas uniquement des
éléments consécutifs. On peut dire qu'il est au tri à bulles ce que le tri de Shell est au tri par insertion.</li>
<li><strong>Tri par insertion</strong> (<em>insertion sort</em>): Ce tri souvent utilisé naturellement pour trier des cartes à jouer. Les valeurs sont
insérées les unes après les autres dans une liste triée (initialement vide). C'est souvent le plus rapide et le plus utilisé
pour trier les entrées de petite taille. Il est également efficace pour des entrées déjà presque triées.</li>
<li><strong>Tri à bulles</strong> (<em>bubble sort</em>) : L'algorithme consiste à parcourir l'entrée du début à la fin et pour chaque couple
d'éléments consécutifs, à les intervertir s'ils sont mal ordonnés. Cette opération est répétée jusqu'à ce que la structure soit
triée (aucune intervention lors du dernier passage). Cet algorithme est peu efficace et rarement utilisé en pratique ; son
intérêt est principalement pédagogique.</li>
<li><strong>Tri cocktail</strong> (<em>cocktail sort</em>) : Il s'agit d'une variante du tri à bulles dans laquelle l'entrée est alternativement
parcourue dans les deux sens. S'il permet de traiter de manière plus efficace quelques cas problématiques pour le tri à bulles,
il reste essentiellement similaire à ce dernier et l'intérêt est encore une fois principalement pédagogique.</li>
<li><strong>Tri pair-impair</strong> (<em>odd-even sort</em>) : Il s'agit d'une variante du tri à bulles, qui procède en comparant successivement tous
les éléments d'index pairs avec les éléments d'index impairs qui les suivent, puis inversement. On va ainsi commencer en
comparant le premier élément au second, le troisième au quatrième, etc., puis l'on comparera le second élément au troisième, le
quatrième au cinquième. L'opération est répétée jusqu'à ce que la structure soit triée.</li>
</ul>
<h4 id="algorithmes-lents"><a class="header" href="#algorithmes-lents">Algorithmes lents</a></h4>
<ul>
<li><strong>Tri par selection</strong> (<em>selection sort</em>) : Sur un tableau de <em>n</em> éléments on recherche l'élément le plus petit du tableau et
on l'échange avec l'élément d'indice 0. Puis on recherche le deuxième plus petit et on l'échange avec l'élément d'indice 1.
L'opération est répétée jusqu'à ce que la structure soit triée.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données"><a class="header" href="#structures-de-données">Structures de données</a></h2>
<p>Une structure de données est une manière d'organiser les données pour les traiter plus facilement. C'est une mise en oeuvre
concrète d'un type abstrait.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-1"><a class="header" href="#structures-de-données-1">Structures de données</a></h2>
<h3 id="pile"><a class="header" href="#pile">Pile</a></h3>
<p>Une pile est une structure de données fondée sur le principe &quot;dernier entré, premier sorti&quot; (LIFO), ce qui veut dire qu'en
général, le dernier élément ajouté à la pile, sera le premier à en sortir.</p>
<p>La plupart des microprocesseurs gèrent nativement une pile. Elle correspond alors à une zone de la mémoire, et le processeur
retient l'adresse du dernier élément.</p>
<p>Voici les primitives communément utilisées pour manipuler les piles. Il n'existe pas de normalisation pour les primitives de
manipulation de pile. Leurs noms sont donc indiqués de manière informelle. Seules les trois premières sont réellement
indispensables, les autres pouvant s'en déduire :</p>
<ul>
<li>Empiler (<em>Push</em>) : ajoute un élément sur la pile.</li>
<li>Dépiler (<em>Pull</em>) : enlève un élément de la pile et le renvoie.</li>
<li>&quot;La pile est-elle vide ?&quot; (<em>IsNull</em>) : renvoie vrai si la pile est vide, faux sinon.</li>
<li>&quot;Nombre d'éléments de la pile&quot; (<em>Length</em>): renvoie le nombre d'élément de la pile.</li>
<li>&quot;Quel est l'élément de tête ?&quot; (<em>Peek</em> ou <em>Top</em>) : renvoie l'élément de tête sans le dépiler.</li>
<li>&quot;Vider la liste&quot; (<em>Clear</em>) : dépiler tous les éléments.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-2"><a class="header" href="#structures-de-données-2">Structures de données</a></h2>
<h3 id="file"><a class="header" href="#file">File</a></h3>
<p>Une file est une structure de donnée basée sur le principe de &quot;premier entré, premier sorti&quot; (FIFO), les premiers éléments
ajoutés à la file seront les premiers à en être retirés.</p>
<p>Les files servent à organiser le traitement séquentiel des blocs de données d'origines diverses.</p>
<p>La théorie des files d'attente, élaborée pour le dimensionnement des réseaux téléphoniques, relie le nombre d'usagers, le nombre
de canaux disponibles, le temps d'occupation moyen du canal, et le temps d'attente à prévoir (Loi de Poisson).</p>
<p>Cette structure est utilisée :</p>
<ul>
<li>en général, pour mémoriser temporairement des transactions qui doivent attendre pour être traitées ;</li>
<li>les serveurs d'impression, qui traitent ainsi les requêtes dans l'ordre dans lequel elles arrivent, et les insèrent dans une
file d'attente (spool) ; certains moteurs multitâches, dans les systèmes d'exploitation, qui doivent accorder du temps machine à
chaque tâche, sans en privilégier aucune ;</li>
<li>un algorithme de parcours en largeur utilise une file pour mémoriser les noeuds visités ;</li>
<li>pour créer toutes sortes de mémoires tampons (<em>buffers</em>) ;</li>
<li>En gestion des stocks les algorithmes doivent respecter la gestion physique des stocks pour assurer la cohérence
physique/valorisation.</li>
</ul>
<p>Voici les primitives communément utilisées pour manipuler les files. Il n'existe pas de normalisation pour les primitives de
manipulation de file. Leurs noms sont donc indiqués de manière informelle :</p>
<ul>
<li>Enfiler (<em>Enqueue</em>) : ajouter un élément dans la file.</li>
<li>Defiler (<em>Dequeue</em>) : renvoie le prochain élément de la file, et le retire de la file.</li>
<li>&quot;La file est-elle vide ?&quot; (<em>IsNull</em>) : renvoie &quot;vrai&quot; si la file est vide, &quot;faux&quot; sinon.</li>
<li>&quot;Nombre d'élément dans la file&quot; (<em>Length</em>) : renvoie le nombre d'élément dans la file.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-3"><a class="header" href="#structures-de-données-3">Structures de données</a></h2>
<h3 id="liste"><a class="header" href="#liste">Liste</a></h3>
<p>Une liste est une structure de données permettant de regrouper des données de manière à pouvoir y accéder librement
(contrairement aux files et aux piles).</p>
<p>Voici les primitives communément utilisées pour manipuler des listes ; il n'existe pas de normalisation pour les primitives de
manipulation de listes, leurs noms respectifs sont donc indiqués de manière informelle.</p>
<p>Primitives de base :</p>
<ul>
<li>Insérer (<em>Add</em>) : ajoute un élément dans la liste ;</li>
<li>Retirer (<em>Remove</em>) : retire un élément de la liste ;</li>
<li>&quot;La liste est-elle vide ?&quot; (<em>IsNull</em>) : renvoie &quot;vrai&quot; si la liste est vide, &quot;faux&quot; sinon ;</li>
<li>&quot;Nombre d'éléments dans la liste&quot; (<em>Length</em>) : renvoie le nombre d'éléments dans la liste.</li>
</ul>
<p>Primitives auxiliaires fréquemment rencontrées :</p>
<ul>
<li>Premier (<em>First</em>) : retourne le premier élément dans la liste ;</li>
<li>Dernier (<em>Last</em>) : retourne le dernier élément dans la liste ;</li>
<li>Prochain (<em>Next</em>) : retourne le prochain élément dans la liste ;</li>
<li>Précédent (<em>Previous</em>) : retourne l'élément qui précède dans la liste ;</li>
<li>Cherche (<em>find</em>) : cherche si un élément précis est contenu dans la liste et retourne sa position.</li>
</ul>
<p>Une liste est un conteneur d'éléments, où chaque élément contient la donnée, ainsi que d'autres informations permettant la
récupération des données au sein de la liste. La nature (les types) de ces informations caractérise un type différent de liste.</p>
<p>On peut distinguer, de manière générale, deux types de liste :</p>
<ul>
<li>les tableaux ;</li>
<li>les listes chaînées.</li>
</ul>
<p>Dans un tableau, l'accès à un élément se fait à l'aide d'un index qui représente l'emplacement de l'élément dans la structure.</p>
<p>Les données présentes dans un tableau sont contiguës en mémoire. Cela induit une taille de tableau fixe. Cependant certains
langages de haut niveau fournissent des tableaux qui modifient leur taille en fonction de leur utilisation : on parle alors de
tableau à taille dynamique. Mais leur implémentation utilise le principe des listes chaînées. Les tableaux peuvent également
avoir plusieurs dimensions, représentées par une séquence d'indices.</p>
<p>Contrairement à un tableau, la taille d'une liste chaînée n'a pas de limite autre que celle de la mémoire disponible. Cette
limitation est franchie par le fait que chaque élément peut pointer, suivant le type de liste chaînée, vers un ou plusieurs
éléments de la liste en utilisant une définition récursive. Ainsi, pour augmenter la taille d'une liste chaînée, il suffit de
créer un nouvel élément et de faire pointer certains éléments, déjà présents au sein de la liste, vers le nouvel élément.</p>
<p>Il existe deux grand types de liste chainée :</p>
<ul>
<li><strong>les listes simplement chaînées</strong> : chaque élément dispose d'un pointeur sur l'élément suivant (ou successeur) de la liste. Le
parcours se fait dans un seul sens ;</li>
<li><strong>les listes doublement chaînées</strong> : chaque élément dispose de deux pointeurs, respectivement sur l'élément suivant (ou
successeur) et sur l'élément précédent (ou prédécesseur). Le parcours peut alors se faire dans deux sens, mutuellement opposés :
de successeur en successeur, ou de prédécesseur en prédécesseur.</li>
</ul>
<p>A cela on peut ajouter une propriété : le cycle. Cette fois ci, la liste chaînée forme une boucle. Dès qu'on atteint la &quot;fin&quot; de
la liste et qu'on désire continuer, on se retrouve sur le &quot;premier&quot; élément de la liste. Dans ce cas, la notion de début ou de
fin de chaîne n'a plus de raison d'être.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-4"><a class="header" href="#structures-de-données-4">Structures de données</a></h2>
<h3 id="arbre-enraciné"><a class="header" href="#arbre-enraciné">Arbre enraciné</a></h3>
<p>En théorie de graphes, un arbre enraciné ou une arborescence est un graphe acyclique orienté possédant une unique racine, et tel
que tous les noeuds sauf la racine ont un unique parent.</p>
<p>Dans un arbre, on distingue deux catégories d'éléments :</p>
<ul>
<li>les <em>feuilles</em> (ou noeuds externes), éléments ne possédant pas de fils dans l'arbre ;</li>
<li>les <em>noeuds</em> interne, éléments possédant des fils (sous-branches).</li>
</ul>
<p>La <em>racine</em> de l'arbre est l'unique noeud ne possédant pas de parent. Les noeuds (les pères avec leurs fils) sont reliés entre
eux par une <em>arête</em>. Selon le contexte, un noeud peut désigner un noeud interne ou externe (feuille) de l'arbre.</p>
<p>La <em>profondeur</em> d'un noeud est la distance, i.e. le nombre d'arêtes, de la racine au noeud. La <em>hauteur</em> d'une arbre est la plus
grande profondeur d'une feuille de l'arbre. La <em>taille</em> d'un arbre est son nombre de noeuds (en comptant les feuilles ou non),
la longueur de cheminement est la somme des profondeurs de chacune des feuilles.</p>
<p>Les arbres peuvent être étiquetés. Dans ce cas, chaque noeud possède une <em>étiquette</em>, qui est en quelque sorte le &quot;contenu&quot; du
noeud. L'étiquette peut être très simple : un nombre entier, par exemple. Elle peut également être aussi complexe que l'on veut
: un objet, une instance d'une structure de donnée, un pointeur, etc. Il est presque toujours obligatoire de pouvoir comparer
les étiquettes selon une relation d'ordre total, afin d'implanter les algorithmes sur les arbres.</p>
<p>Les fichiers et dossiers dans un système de fichiers sont généralement organisés sous forme arborescente.</p>
<p>Les arbres sont en fait rarement utilisés en tant que tels, mais de nombreux types d'arbres avec une structure plus restrictive
existent et sont couramment utilisés en algorithmique, notamment pour gérer des bases de données, ou pour l'indexation de
fichiers. Ils permettent alors des recherches rapides et efficaces. Par exemple :</p>
<ul>
<li>Les arbres binaires dont chaque noeud a au plus deux fils : ils sont en fait utilisés sous forme d'arbres binaires de
recherche, de tas, ou encore d'arbres rouge-noir. Le dernier exemple est un cas particulier d'arbre équilibré, c'est à dire dont
les sous-branches ont presque la même hauteur.</li>
<li>Les arbres n-aires qui sont une généralisation des arbres binaires : chaque noeud a au plus <em>n</em> fils. Les arbres 2-3-4 et les
arbres B en sont des exemples d'utilisation et sont eux aussi des arbres équilibrés.</li>
</ul>
<p>Pour construire un arbre à partir de cases ne contenant que des informations, on peut procéder de l'une des trois façons
suivantes :</p>
<ol>
<li>Créer une structure de données composée de :
<ul>
<li>l'étiquette (la valeur contenue dans le noeud),</li>
<li>un lien vers <em>chaque</em> noeud fils,</li>
<li>un arbre particulier, l'arbre vide, qui permet de caractériser les feuilles. Une feuille a pour fils des arbres vides
uniquement.</li>
</ul>
</li>
<li>Créer une structure de données composée de :
<ul>
<li>l'étiquette (la valeur contenue dans le noeud),</li>
<li>un lien vers le &quot;premier&quot; noeud fils (noeud fils gauche le cas échéant),</li>
<li>un autre lien vers le noeud frère (le &quot;premier&quot; noeud frère sur la droite le cas échéant).</li>
</ul>
</li>
<li>Créer une structure de données composée de :
<ul>
<li>l'étiquette (la valeur contenue dans le noeud),</li>
<li>un lien vers le noeud père.</li>
</ul>
</li>
</ol>
<p>On note qu'il existe d'autres types de représentation propres à des cas particuliers d'arbres. Par exemple, le tas est
représenté par un tableau d'étiquettes.</p>
<p>Les parcours d'arbre sont des processus de visites des sommets d'un arbre, par exemple pour trouver une valeur.</p>
<p>Le <strong>parcours en largeur</strong> correspond à un parcours par niveau de noeuds de l'arbre. Un niveau est un ensemble de noeuds
internes ou de feuilles situés à la même profondeur - on parle aussi de noeud ou de feuille de même hauteur dans l'arbre
considéré. L'ordre de parcours d'un niveau donné est habituellement conféré, de manière récursive, par l'ordre de parcours des
noeuds parents - noeuds de niveau immédiatement supérieur.</p>
<p>Le <strong>parcours en profondeur</strong> est un parcours récursif sur un arbre. Dans le cas général, deux ordres sont possibles :</p>
<ul>
<li>Parcours en profondeur préfixe : dans ce mode de parcours, le noeud courant est traité avant ses descendants.</li>
<li>Parcours en profondeur suffixe : dans ce mode de parcours, le noeud courant est traité après ses descendants.</li>
</ul>
<p>Pour les arbres binaires, on peut également faire un <em>parcours infixe</em>, c'est à dire traiter le noeud courant entre les noeuds
gauche et droit.</p>
<p><em>Parcours préfixe</em> :</p>
<pre><code class="language-code ignore">    visiterPréfixe(Arbre A) :
        visiter (A)
        Si nonVide (gauche(A))
            visiterPréfixe(gauche(A))
        Si nonVide (droite(A))
            visiterPréfixe(droite(A))
</code></pre>
<p><em>Parcours suffixe</em> :</p>
<pre><code class="language-code ignore">    visiterSuffixe(Arbre A) :
        Si nonVide(gauche(A))
            visiterSuffixe(gauche(A))
        Si nonVide(droite(A))
            visiterSuffixe(droite(A))
        visiter(A)
</code></pre>
<p><em>Parcours infixe</em> :</p>
<pre><code class="language-code ignore">    visiterInfixe(Arbre A) :
        Si nonVide(gauche(A))
            visiterInfixe(gauche(A))
        visiter(A)
        Si nonVide(droite(A))
            visiterInfixe(droite(A))
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-5"><a class="header" href="#structures-de-données-5">Structures de données</a></h2>
<h3 id="arbre-binaire-de-recherche"><a class="header" href="#arbre-binaire-de-recherche">Arbre binaire de recherche</a></h3>
<p>Un arbre binaire de recherche ou ABR (en anglais, binary search tree ou BST) est une structure de données représentant un
ensemble ou un tableau associatif dont les clefs appartiennent à un ensemble totalement ordonné. Un arbre binaire de recherche
permet des opérations rapides pour rechercher une clé, insérer ou supprimer une clé.</p>
<p>Un arbre binaire de recherche est un arbre binaire dans lequel chaque noeud possède une clé, telle que chaque noeud du
sous-arbre <em>gauche</em> ait une clé inférieure ou égale à celle du noeud considéré, et que chaque noeud du sous-arbre <em>droit</em>
possède une clé supérieure ou égale à celle-ci - selon la mise en oeuvre de l'ABR, on pourra interdire ou non des clés de valeur
égale. Les noeuds que l'on ajoute deviennent des feuilles de l'arbre.</p>
<p>La recherche dans un arbre binaire d'un noeud ayant une clé particulière est un procédé récursif. On commence par examiner la
racine. Si la clé est la clé recherchée, l'algorithme se termine et renvoie la racine. Si elle est strictement inférieure, alors
elle est dans le sous-arbre gauche, sur lequel on effectue alors récursivement la recherche. De même si la clé recherchée est
strictement supérieure à la clé de la racine, la recherche continue dans le sous-arbre droit. Si on atteint une feuille dont la
clé n'est pas celle recherchée, on sait alors que la clé recherchée n'appartient à aucun noeud, elle ne figure donc pas dans
l'arbre de recherche. On peut comparer l'exploration d'un arbre binaire de recherche avec la recherche par dichotomie qui
procède à peu près de la même manière sauf qu'elle accède directement à chaque élément d'un tableau au lieu de suivre les liens.
La différence entre les deux algorithmes est que, dans la recherche dichotomique, on suppose avoir un critère de découpage de
l'espace en deux parties que l'on n'a pas dans la recherche dans un arbre.</p>
<p>Cette opération requiert un temps en <em>O(log n)</em> dans le cas moyen, mais <em>O(n)</em> dans le cas critique où l'arbre est complètement
déséquilibré et ressemble à une liste chaînée. Ce problème est écarté si l'arbre est équilibré par rotation au fur et à mesure
des insertions pouvant créer des listes trop longues.</p>
<p>L'insertion d'un noeud commence par une recherche : on cherche la clé du noeud à insérer ; lorsqu'on arrive à une feuille, on
ajoute le noeud comme fils de la feuille en comparant sa clé à celle de la feuille : si elle est inférieure, le nouveau noeud
sera à gauche ; sinon il sera à droite.</p>
<p>Sa complexité est la même que pour la recherche.</p>
<p>Il est aussi possible d'écrire une procédure d'ajout d'élément à la racine d'un arbre binaire. Cette opération requiert la même
complexité mais est meilleure en terme d'accès aux éléments.</p>
<p>Pour la suppression, on commence par rechercher la clé du noeud à supprimer dans l'arbre. Plusieurs cas sont à considérer, une
fois que le noeud à supprimer a été trouvé à partir de sa clé :</p>
<ul>
<li><em>Suppression d'une feuille</em> : Il suffit de l'enlever de l'arbre puisqu'elle n'a pas de fils.</li>
<li><em>Suppression de noeud avec un enfant</em> : Il faut l'enlever de l'arbre en le remplaçant par son fils.</li>
<li><em>Suppression d'un noeud avec deux enfants</em> : Supposons que le noeud à supprimer soit appelé N. On échange le noeud N avec son
successeur le plus proche (le noeud le plus à gauche du sous-arbre droit) ou son plus proche prédécesseur (le noeud le plus à
droite du sous-arbre gauche). Cela permet de garder à la fin de l'opération une structure d'arbre binaire de recherche. Puis on
applique à nouveau la procédure de suppression à N, qui est maintenant une feuille ou un noeud avec un seul fils.</li>
</ul>
<p>Ce choix d'implémentation peut contribuer à déséquilibrer l'arbre. En effet, puisque ce sont toujours des feuilles du sous-arbre
gauche qui sont supprimées, une utilisation fréquente de cette fonction amènera à un arbre plus lourd à droite qu'à gauche. On
peut remédier à cela en alternant successivement la suppression du minimum du fils droit avec celle maximum du fils gauche,
plutôt que toujours choisir ce dernier. Il est par exemple possible d'utiliser un facteur aléatoire : le programme aura une
chance sur deux de choisir le fils droit et une chance sur deux de choisir le fils gauche.</p>
<p>Dans tous les cas cette opération requiert de parcourir l'arbre de la racine jusqu'à une feuille : le temps d'exécution est donc
proportionnel à la profondeur de l'arbre qui vaut n dans le pire des cas, d'où une complexité maximale <em>O(n)</em>.</p>
<p>On peut récupérer les clés d'un arbre binaire de recherche dans l'ordre croissant en réalisant un parcours infixe. Il faut
concaténer dans cet ordre la liste triée obtenue récursivement par parcours du fils gauche à la racine puis à celle obtenue
récursivement par parcours du fils droit. Il est possible de le faire dans l'ordre inverse en commençant par le sous-arbre
droit. Le parcours de l'arbre se fait en temps linéaire, puisqu'il doit passer par chaque noeud une seule fois.</p>
<p>On peut dès lors créer un algorithme de tri simple mais peu efficace, en insérant toutes les clés que l'on veut trier dans un
nouvel arbre binaire de recherche puis en parcourant de manière ordonnée cet arbre comme ci-dessus.</p>
<p>Les arbres binaires de recherche peuvent servir d'implémentation au type abstrait de file de priorité. En effet, les opérations
d'insertion d'une clé et de test au vide se font avec des complexités avantageuses (respectivement en <em>O(log n)</em> et en <em>O(1)</em>).
Pour l'opération de suppression de la plus grande clé, il suffit de parcourir l'arbre depuis sa racine en choisissant le fils
droit de chaque noeud, et de supprimer la feuille terminale. Cela demande un nombre d'opérations égal à la hauteur de l'arbre,
donc une complexité logarithmique. L'avantage notoire de cette représentation d'une file de priorité est qu'avec un processus
similaire, on dispose d'une opération de suppression de la plus petite clé en temps logarithmique également.</p>
<p>L'insertion et la suppression s'exécutent en <em>O(h)</em> où <em>h</em> est la hauteur de l'arbre. Cela s'avère particulièrement coûteux
quand l'arbre est très déséquilibré (un arbre peigne par exemple, dont la hauteur est linéaire en le nombre de clés), et on
gagne donc en efficacité à équilibrer les arbres au cours de leur utilisation. Il existe des techniques pour obtenir des arbres
équilibrés, c'est à dire une hauteur logarithmique en nombre d'éléments :</p>
<ul>
<li><strong>les arbres rouge-noir</strong></li>
<li><strong>les B-arbres</strong></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-6"><a class="header" href="#structures-de-données-6">Structures de données</a></h2>
<h3 id="arbre-b"><a class="header" href="#arbre-b">Arbre B</a></h3>
<p>Un arbre B est une structure de données en arbre équilibré. Les arbres B sont principalement mis en oeuvre dans les mécanismes
de gestion de bases de données et de systèmes de fichiers. Ils stockent les données sous une forme triée et permettent une
exécution des opérations d'insertion et de suppression en temps toujours logarithmique.</p>
<p>Le principe est de permettre aux noeuds parents de posséder plus de deux noeuds enfants : c'est une généralisation de l'arbre
binaire de recherche. Ce principe minimise la taille de l'arbre et réduit le nombre d'opérations d'équilibrage. De plus un
B-arbre grandit à partir de la racine, contrairement à un arbre binaire de recherche qui croît à partir des feuilles.</p>
<p>Un <em>arbre étiqueté</em> est un arbre tel qu'à chaque noeud on associe une étiquette ou clé (ou bien plusieurs étiquettes ou clés
dans le cas des arbres B) prise(s) dans un ensemble donné. Donc formellement un arbre étiqueté est un couple formé d'un graphe
orienté, acyclique et connexe et d'une fonction d'étiquetage des arbres qui attribue à chaque noeud une étiquette ou une clé.
Parmi les arbres étiquetés, un <em>arbre B</em> possède quelques propriétés spécifiques supplémentaires.</p>
<p>Soit <em>L</em> et <em>U</em> deux entiers naturels non nuls tels que <em>L≤U</em>. En toute généralité, on définit alors un <em>L-U arbre B</em> de
la manière suivante : chaque noeud, sauf la racine, possède un minimum de <em>L-1</em> clés (appelées aussi éléments), un maximum de
<em>U-1</em> clés et au plus <em>U</em> fils. Pour chaque noeud interne -- noeud qui n'est pas une feuille --, le nombre de fils est toujours
égal au nombre de clés augmenté d'une unité. Si <em>n</em> est le nombre de fils, alors on parle de <em>n</em>-noeud. Un <em>L-U</em> arbre B ne
contient que des <em>n</em>-noeuds avec L≤n≤U. Souvent on choisit la configuration <em>L=t</em> et <em>U=2.t</em> : <em>t</em> est appelé le
<em>degré minimal</em> de l'arbre B.</p>
<p>De plus, la construction des arbres B garantit qu'un arbre B est toujours équilibré. Chaque clé d'un noeud interne est en fait
une borne qui distingue les sous-arbres de ce noeud.</p>
<p>Un arbre B est implémenté par un arbre enraciné. Un noeud <em>x</em> est étiqueté par :</p>
<ul>
<li>Un entier <em>n</em> qui correspond au nombre de clefs contenues dans e noeud <em>x</em></li>
<li><em>n</em> clefs notées <em>c₁,...,cₙ</em>.</li>
<li>Un booléen indiquant si <em>x</em> est une feuille ou non.</li>
<li><em>n+1</em> pointeurs notés <em>p₁,...,pₙ₊₁</em> associés aux fils <em>f₁,...,fₙ₊₁</em> de <em>x</em>.
Une feuille ne contient pas de pointeurs.</li>
</ul>
<p>De plus, un arbre B vérifie ces propriétés :</p>
<ul>
<li>
<p>Toutes les feuilles ont la même profondeur, à savoir la hauteur <em>h</em> de l'arbre.</p>
</li>
<li>
<p>Si <em>x</em> n'est pas une feuille :</p>
<ul>
<li>pour <em>2≤i≤n</em>, pour toute clef <em>k</em> du fils <em>fᵢ</em> : <em>cᵢ₋₁≤k≤cᵢ</em>.</li>
<li>pour toute clef <em>k</em> du fils <em>f₁</em> : <em>k≤c₁</em>.</li>
<li>pour toute clef <em>k</em> du fils <em>fₙ₊₁</em> : <em>cₙ≤k</em>.</li>
</ul>
</li>
<li>
<p>Si <em>x</em> n'est ni une feuille, ni la racine, <em>n</em> est compris entre L-1 et U-1.</p>
</li>
</ul>
<p>La plupart du temps, la configuration est telle que <em>U = 2L</em>. On parle alors d'arbre B d'ordre <em>L</em>.
Un arbre B d'ordre <em>t</em> est défini alors plus simplement par un arbre qui satisfait les propriétés suivantes :</p>
<ul>
<li>Chaque noeud a au plus <em>2t-1</em> clés.</li>
<li>Chaque noeud qui n'est ni racine ni feuille possède au moins <em>t-1</em> clés.</li>
<li>Si l'arbre est non vide, la racine est aussi non vide.</li>
<li>Un noeud qui possède <em>k</em> fils contient <em>k-1</em> clefs.</li>
<li>Toutes les feuilles se situent à la même hauteur.</li>
</ul>
<p>Comme on le verra par la suite, la hauteur d'un B-arbre est logarithmique en le nombre d'éléments. Ainsi, les opérations de
recherche, insertion et suppression sont implémentables en <em>O(log n)</em> dans le pire des cas, où <em>n</em> est le nombre d'éléments.</p>
<p>La recherche est effectué de la même manière que dans un arbre binaire de recherche. Partant de la racine, on parcourt
récursivement l'arbre ; à chaque noeud, on choisit le sous-arbre fils dont les clés sont comprises entre les même bornes que
celles de la clé recherchée grâce à une recherche dichotomique.</p>
<p>L'insertion nécessite tout d'abord de chercher le noeud où la nouvelle clé devrait être insérée, et l'insérer. La suite se
déroule récursivement, selon qu'un noeud ait ou non trop de clés : s'il possède un nombre acceptable de clés, on ne fait rien ;
autrement on le transforme en deux noeuds, chacun possédant un nombre minimum de clés, puis on fait &quot;remonter&quot; la clé du milieu
qui est alors insérée dans le noeud père. Ce dernier peut du coup se retrouver avec un nombre excessif de fils ; le procédé se
poursuit ainsi jusqu'à ce qu'on atteigne la racine. Si celle-ci doit être divisée, on fait &quot;remonter&quot; la clé du milieu dans une
nouvelle racine, laquelle génèrera comme noeuds fils les deux noeuds créés à partir de l'ancienne racine, à l'instar de l'étape
précédente. Pour que l'opération soit possible, on remarque qu'il faut que U ≥ 2L ; sinon les nouveaux noeuds ne
possèderont pas suffisamment de clés.</p>
<p>Une variante consiste à éclater préventivement chaque noeud &quot;plein&quot; (possédant un nombre maximal de clés) rencontré lors de la
recherche du noeud où se réalisera l'insertion. De cette manière on évite une remontée dans l'arbre, puisque l'on s'assure que
le père d'un noeud à scinder en deux peut accueillir une clé supplémentaire. La contrepartie en est une légère augmentation de
la hauteur moyenne de l'arbre.</p>
<p>Pour la suppression, on doit d'abord chercher la clé à supprimer et la supprimer du noeud qui la contient.</p>
<ul>
<li>Si le noeud est interne, on procède de manière similaire aux arbres binaires de recherche en cherchant la clé <em>k</em> la plus à
gauche dans le sous-arbre droit de la clé à supprimer ou la plus à droite dans le sous-arbre gauche. Cette clé <em>k</em> appartient à
une feuille. On peut la permuter avec la clé à supprimer, que l'on supprime ensuite. Comme elle appartient à une feuille, on se
ramène au cas suivant.</li>
<li>Si le noeud est une feuille, soit il possède encore suffisamment de clés et l'algorithme se termine, soit il dispose de moins
de <em>L-1</em> clés et on se trouve dans l'une des deux situations suivantes :
<ul>
<li>soit un de ses frères à droite ou à gauche possède suffisamment de clés pour pouvoir en &quot;passer&quot; une à la feuille en
question : dans ce cas cette clé remplace la clé qui sépare les deux sous-arbres dans l'arbre père, qui va elle-même dans la
feuille en question ;</li>
<li>soit aucun de ses frères n'a suffisamment de clés : dans ce cas, le père fait passer une de ses clés dans un des deux (ou
le seul) frère pour permettre à la feuille de fusionner avec celui-ci. Ceci peut cependant conduire le père à ne plus avoir
suffisamment de clés. On réitère alors l'algorithme : si le noeud a un frère avec suffisamment de clés, la clé la plus
proche va être échangée avec la clé du père, puis la clé du père et ses nouveaux descendants sont ramenés dans le noeud qui
a besoin d'une clé ; sinon, on effectue une fusion à l'aide d'une clé du père et ainsi de suite. Si l'on arrive à la racine
et qu'elle possède moins de L éléments, on fusionne ses deux fils pour donner une nouvelle racine.</li>
</ul>
</li>
</ul>
<p>Notamment après une suppression, l'arbre peut être rééquilibré. Cette opération consiste à répartir équitablement les valeurs
dans les différents noeuds de l'arbre et à rétablir les propriétés de remplissage minimum des noeuds.</p>
<p>Le rééquilibrage commence au niveau des feuilles et progresse vers la racine, jusqu'à celle-ci. La redistribution consiste à
transférer un élément d'un noeud voisin qui possède suffisamment de valeurs vers le noeud qui en manque. Cette redistribution
est appelée <strong>rotation</strong>. Si aucun voisin ne peut fournir de valeur sans être lui même sous la limite, le noeud déficient doit
être <strong>fusionné</strong> avec un voisin. Cette opération provoque la perte d'un séparateur dans le noeud parent, celui-ci peut alors
être en déficit et a besoin d'être équilibré. La fusion et redistribution se propage jusqu'à la racine, seul élément où la
déficience en valeurs est tolérée.</p>
<p>Un algorithme d'équilibrage simple consiste à :</p>
<ul>
<li>Si le noeud voisin gauche existe et dispose de suffisamment de valeurs pour pouvoir en offrir une, réaliser une rotation
gauche.</li>
<li>Sinon, si le noeud voisin droite existe et dispose de suffisamment d'éléments, réaliser une rotation droite.</li>
<li>Sinon, le noeud déficient doit être fusionné avec un de ses voisins tel que la somme du nombre de leurs clés plus <em>1</em> soit
inférieure ou égale à la capacité maximale (<em>taille_gauche</em>+<em>taille_droite</em>+1≤<em>U-1</em>). La valeur supplémentaire correspond
au séparateur présent dans le parent. Cette opération est toujours possible si <em>U-1</em>≥<em>2L</em> avec <em>taille_gauche</em>=<em>L-2</em> et
<em>taille_droite</em>=<em>L-1</em> ou le contraire, soit un noeud immédiatement sous la limite de <em>L-1</em> clés et un noeud exactement à la
limite.</li>
</ul>
<ol>
<li>Copier le séparateur à la fin du noeud de gauche.</li>
<li>Ajouter tous les éléments du noeud de droite à la fin du noeud de gauche.</li>
<li>Effacer le noeud de droite et effacer le séparateur du parent puis vérifier qu'il contient assez d'éléments. Si ce n'est pas
le cas, rééquilibrer le parent avec ses voisins.</li>
</ol>
<p>La rotation à gauche d'un cran entre deux noeuds voisins se fait en :</p>
<ol>
<li>déplaçant le séparateur, présent dans le parent, à la fin du noeud gauche.</li>
<li>déplaçant le premier élément du noeud de droite en tant que séparateur dans le parent.</li>
</ol>
<p>Ce genre d'opération peut être également utilisé pour compresser l'arbre : un arbre destiné à la lecture seule peut être vidé
d'un maximum de cases mémoires inutilisées en remplissant au maximum un minimum de noeuds.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-7"><a class="header" href="#structures-de-données-7">Structures de données</a></h2>
<h3 id="arbre-rouge-noir"><a class="header" href="#arbre-rouge-noir">Arbre rouge-noir</a></h3>
<p>Un <strong>arbre bicolore</strong>, ou <strong>arbre rouge-noir</strong> ou <strong>arbre rouge et noir</strong> est un type particulier d'arbre binaire de recherche
équilibré. Chaque noeud de l'arbre possède en plus de ses données propres un attribut binaire qui est souvent interprété comme
sa &quot;couleur&quot; (rouge ou noir). Cet attribut permet de garantir l'équilibre de l'arbre : lors de l'insertion ou de la suppression
d'éléments, certaines propriétés sur les relations entre les noeuds et les couleurs doivent être maintenues, ce qui empêche
l'arbre de devenir trop déséquilibré, y compris dans le pire des cas. Durant une insertion ou une suppression, les noeuds sont
parfois réarrangés ou changent leur couleur afin que ces propriétés soient conservées.</p>
<p>Le principal intérêt des arbres bicolores réside dans le fait que malgré les potentiels réarrangements ou coloriages des noeuds,
la complexité (en le nombre d'éléments) des opérations d'insertion, de recherche et de suppression est logarithmique. De plus,
cette structure est économe en mémoire puisqu'elle ne requiert qu'un bit supplémentaire d'information par élément par rapport à
un arbre binaire classique.</p>
<p>Un arbre bicolore est un cas particulier d'arbre binaire, une structure de donnée couramment utilisée en informatique pour
organiser des données pouvant être comparées, par exemple des nombres ou des chaines de caractères.</p>
<p>Les feuilles de l'arbre, c'est-à-dire les noeuds terminaux, ne contiennent aucune donnée. Elles peuvent être simplement
représentées sans coût mémoire par des éléments nuls (pointeurs nul en C, valeur NIL, etc.) dans le noeud parent (indiquant que
le noeud enfant est une feuille). Il peut être toutefois utile pour simplifier la mise en oeuvre de certains algorithmes que les
feuilles soient explicitement représentées soit en les instanciant séparément, soit en utilisant une sentinelle (valeur
signifiant la fin de la donnée).</p>
<p>Comme tous les arbres binaires de recherche, les arbres bicolores peuvent être parcourus très efficacement en ordre infixe (ou
ordre gauche - racine - droite), ce qui permet de lister les éléments dans l'ordre. La recherche d'un élément se fait en temps
logarithmique <em>O(log n)</em>, <em>n</em> étant le nombre d'éléments de l'arbre, y compris dans le pire des cas.</p>
<p>Un arbre bicolore est un arbre binaire de recherche dans lequel chaque noeud a un attribut supplémentaire : sa couleur, qui est
soit <strong>rouge</strong> soit <strong>noire</strong>. En plus des restrictions imposées aux arbres binaires de recherche, les règles suivantes sont
utilisées :</p>
<ol>
<li>Un noeud est soit rouge soit noir ;</li>
<li>La racine est noire ;</li>
<li>Les enfants d'un noeud rouge sont noirs ;</li>
<li>Tous les noeuds ont 2 enfants. Ce sont d'autres noeuds ou des feuilles <strong>NIL</strong>, qui ne possèdent pas de valeurs et qui sont
les seuls noeuds sans enfants. Leur couleur est toujours <strong>noire</strong> et rentre donc en compte lors du calcul de la hauteur noire.</li>
<li>Le chemin de la racine à n'importe quelle feuille (<strong>NIL</strong>) contient le même nombre de noeuds noirs. On peut appeler ce
nombre de noeuds noirs la <strong>hauteur noire</strong>.</li>
</ol>
<p>Ces contraintes impliquent une propriété importante des arbres bicolores : le chemin le plus long possible d'une racine à une
feuille (sa hauteur) ne peut être que deux fois plus long que le plus petit possible : dans le cas le plus déséquilibré, le plus
court des chemins ne comporte que des noeuds noirs, et le plus long alterne les noeuds rouges et noirs. Un arbre vérifiant ces
propriétés est ainsi presque équilibré. Comme les opérations d'insertion, de recherche et de suppression requièrent dans le pire
des cas un temps proportionnel à la hauteur de l'arbre, les arbres bicolores restent efficaces, contrairement aux arbres
binaires de recherche ordinaires.</p>
<p>Pour comprendre comment ces contraintes garantissent la propriété ci-dessus, il suffit de s'apercevoir qu'aucun chemin ne peut
avoir deux noeuds rouges consécutifs à cause de la propriété 3. Le plus petit chemin théorique de la racine à une feuille ne
contient alors que des noeuds noirs tandis que le plus grand alterne entre les noeuds rouges et noirs. Et comme d'après la
propriété chacun de ces chemins contient le même nombre de noeuds noirs, le plus grand chemin ne peut être deux fois plus grand
que le plus petit.</p>
<p>La propriété 2 n'est pas nécessaire. Les seuls cas où la racine pourrait devenir rouge étant les deux cas où sa couleur n'a pas
d'importance : soit la racine est le seul noeud, soit elle possède deux fils noirs. Cette propriété est ajouté uniquement pour
visualiser plus rapidement l'isomorphisme avec les arbres 2-3-4 : chaque noeud noir et ses éventuels fils rouges représente un
noeud d'arbre 2-3-4.</p>
<p>Les arbres bicolores, offrent la meilleure garantie sur le temps d'insertion, de suppression et de recherche dans les cas
défavorables. Ceci leur permet non seulement d'être alors utilisables dans des applications en temps réel, mais aussi de servir
comme fondement d'autres structures de données à temps d'exécution garanti dans les cas défavorables, par exemple en géométrie
algorithmique. L'ordonnanceur du noyau Linux, le Completely Fair Scheduler utilise également un arbre rouge-noir.</p>
<p>Les arbres rouge-noir sont également très utile en programmation fonctionnelle : c'est l'exemple le plus couramment utilisé de
structure de données persistante qui peut être utilisée pour construire des tableaux associatifs capables de garder en mémoires
les versions précédentes après un changement. Les versions persistantes des arbres rouge-noir requièrent <em>O(log n)</em> en mémoire
supplémentaire pour chaque insertion ou suppressions.</p>
<p>La recherche sur un arbre bicolore s'effectue exactement comme dans les arbres binaires de recherche. Cependant, après une
insertion ou une suppression, les propriétés de l'arbre bicolore peuvent être violées. La restauration de ces propriétés
requiert un petit nombre <em>O(log n)</em> de modifications des couleurs (qui sont très rapides en pratique) et pas plus de trois
rotations (deux pour l'insertion). Ceci permet d'avoir une insertion et une suppression en <em>O(log n)</em> mais rend l'implémentation
plus complexe à cause du grand nombre de cas particuliers à traiter.</p>
<p>La recherche d'un élément se déroule de la même façon que pour un arbre binaire de recherche : en partant de la racine, on
compare la valeur recherchée à celle du noeud courant de l'arbre. Si ces valeurs sont égales, la recherche est terminée et on
renvoie le noeud courant. Sinon, on choisit de descendre vers le noeud enfant gauche ou droit selon que la valeur recherchée est
inférieure ou supérieure. Si une feuille est atteinte, la valeur recherchée ne se trouve pas dans l'arbre.</p>
<p>La couleur des noeuds de l'arbre n'intervient pas directement dans la recherche. Toutefois à la différence d'un arbre binaire de
recherche normal, les arbres rouge-noir garantissent par construction un temps d'exécution de la recherche en <em>O(log n)</em> y
compris dans le pire des cas. En effet, un arbre binaire de recherche peut devenir déséquilibré dans les cas défavorables (par
exemple si les éléments sont insérés dans l'ordre croissant, l'arbre binaire de recherche dégénère en une liste chainée. La
complexité de l'opération dans le pire des cas est donc <em>O(n)</em> pour un arbre binaire potentiellement non équilibré. Au
contraire, pour l'arbre rouge-noir, les propriétés bicolores vues ci-dessus garantissent que l'on atteindra un noeud en au plus
<em>2.log n</em> comparaisons, donc en <em>O(log n)</em> opérations.</p>
<p>L'insertion commence de la même manière que sur un arbre binaire classique : en partant de la racine, on compare la valeur
insérée à celle d'un noeud courant de l'arbre, et on choisit de descendre vers le noeud enfant gauche ou droit selon que la
valeur insérée est inférieure ou supérieure. Le nouveau noeud est inséré lorsque l'on ne peut plus descendre, c'est-à-dire quand
le noeud courant est une feuille de l'arbre. Cette feuille est remplacée par le nouveau noeud.</p>
<p>Une fois le nouveau noeud ajouté à l'arbre, il faut vérifier que les propriétés de l'arbre bicolore sont bien respectées et,
dans le cas contraire, effectuer des opérations de changement de couleur et des rotations pour les établir. Le noeud inséré est
initialement colorié en <em>rouge</em>. Il y a ensuite plusieurs cas possibles pour rétablir les propriétés de l'arbre, à partir du
noeud inséré.</p>
<ol>
<li>Le noeud inséré n'a pas de parent : il est en fait à la racine de l'arbre. La seule correction à apporter consiste à le
colorier en <strong>noir</strong> pour respecter la propriété 2.</li>
<li>Le noeud du parent inséré est <strong>noir</strong>, alors, l'arbre est valide : la propriété 3 et vérifiée, et la hauteur noire de
l'arbre est inchangée puisque le nouveau noeud est <strong>rouge</strong>. Il n'y a donc rien d'autre à faire.</li>
<li>Le parent du noeud inséré est <strong>rouge</strong>, alors la propriété 3 est invalide. L'action à effectuer dépend de la couleur de
<em>l'oncle</em> du noeud inséré, c'est à dire le &quot;frère&quot; du parent du noeud inséré. En d'autres termes : en partant du noeud inséré
(N), on considère son noeud parent (P), puis le noeud parent de P, ou grand parent (G), et enfin l'oncle (U) qui est le fils de
G qui n'est pas P. Si l'oncle est <strong>rouge</strong>, alors le parent et l'oncle sont coloriés en <strong>noir</strong>, et le grand parent (qui était
nécessairement noir) est colorié en <strong>rouge</strong>. Ce changement de couleur a pu toutefois créer une nouvelle violation des
propriétés bicolores plus haut dans l'arbre. Il faut maintenant recommencer la même analyse de cas mais cette fois <em>en partant
du noeud grand parent ainsi colorié en rouge</em>.</li>
<li>Dans le cas où l'oncle est <strong>noir</strong>, il faut effectuer des rotations qui dépendent de la configuration du noeud inséré autour
de son parent et de son grand parent, afin de ramener l'équilibre dans l'arbre. Le parent vient prendre la place du grand
parent, et le grand parent celle de l'oncle. Le parent devient <strong>noir</strong> et le grand parent <strong>rouge</strong> et l'arbre respecte alors
les propriétés bicolores.</li>
</ol>
<p>Le seul cas où la correction ne se termine pas immédiatement est le cas 3, dans lequel on change le grand parent de noir à
rouge, ce qui oblige à effectuer une nouvelle vérification du grand parent. Cependant, il est aisé de vérifier que la fonction
se termine toujours. Puisque le noeud à vérifier est toujours strictement plus haut que le précédent, on finira inévitablement
par se retrouver dans l'un des cas non récursifs (dans le pire des cas, on remontera jusqu'à atteindre la racine de l'arbre,
c'est à dire le cas 1). Il y aura donc au plus deux rotations, et un nombre de changements de couleurs inférieur à la moitié de
la hauteur de l'arbre, c'est à dire en <em>O(log n)</em>. En pratique la probabilité de tomber plusieurs fois de suite sur le cas 3 est
exponentiellement décroissante ; en moyenne le coût de la correction des propriétés est donc presque constant.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-8"><a class="header" href="#structures-de-données-8">Structures de données</a></h2>
<h3 id="tas"><a class="header" href="#tas">Tas</a></h3>
<p>Un tas est une structure de données de type arbre tel que pour tous noeuds A et B de l'arbre tels que B soit un fils de A :
clé(A)≥clé(B) (ou inversement). Les primitives du tas sont : enfiler et defiler.</p>
<p>Pour enfiler un élément, on le place comme feuille, puis on fait &quot;remonter&quot; l'élément pour maintenir la priorité du tas.
L'opération peut être réalisée en <em>O(log n)</em>.</p>
<p>Quand on défile un élément d'un tas, c'est toujours celui de priorité maximale. Il correspond donc à la racine du tas.
L'opération peut conserver la structure de tas, avec une complexité de <em>O(log n)</em> ; en effet, il ne reste alors qu'à réordonner
l'arbre privé de sa racine pour en faire un nouveau tas.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="structures-de-données-9"><a class="header" href="#structures-de-données-9">Structures de données</a></h2>
<h3 id="table-de-hachage"><a class="header" href="#table-de-hachage">Table de hachage</a></h3>
<p>Une table de hachage est une structure de données qui implémente un type abstrait de tableau associatif. Une table de hachage
utilise une fonction de hachage afin de calculer l'index d'un tableau d'emplacements desquels la valeur attendue peut être
trouvée. Pendant la recherche, la clef est hachée et le hash résultant indique l'emplacement de la valeur correspondante.</p>
<p>Idéalement, la fonction de hachage assignera chaque clef à un réceptacle unique, mais la plupart des tables de hachage utilisent
des fonctions de hachages imparfaites, qui peuvent causer des collisions quand la fonction de hachage attribue un même index
pour plus d'une clef. Ces collisions sont alors traitées de diverses manières.</p>
<p>Dans une table de hachage bien dimensionnée, le coût moyen (nombre d'instructions) pour chaque recherche est indépendant du
nombre d'élément stockés dans la table. Beaucoup de tables de hachages permettent également des insertions et des suppressions
arbitraires de paires clef-valeur, à un coût (amorti) moyen constant par opération.</p>
<p>Dans de nombreuses situations, les tables de hachage sont en moyenne plus efficaces que des arbres de recherche ou de n'importe
quelle autre structure de table de recherche. C'est pour cette raison, qu'elles sont largement utilisé dans un large panel de
logiciels informatiques, particulièrement les tableaux associatifs, l'indexation des bases de données, les caches, et les
ensembles.</p>
<p>L'idée du hachage est de distribuer les entrées (paires clefs/valeurs) à travers un tableau de réceptacles. Étant donné une
clef, l'algorithme calcule un index qui suggère où l'entrée peut se trouver :</p>
<pre><code class="language-code ignore">    index = f(clef, taille_tableau)
</code></pre>
<p>Souvent cette opération est réalisée en deux étapes :</p>
<pre><code class="language-code ignore">    hash = hashfunc(key)
    index = hash % array_size
</code></pre>
<p>Avec cette méthode, le hash est indépendant de la taille du tableau, et est réduit à postériori à un index (un nombre entre <em>0</em>
et <em>taille_tableau - 1</em>) à l'aide de l'opérateur modulo (<em>%</em>).</p>
<p>Dans le cas où la taille du tableau est une puissance de 2, l'opération de reste est réduite à un masquage, ce qui améliore la
performance, mais aussi fait croître le nombre de problèmes si la fonction de hachage est mauvaise.</p>
<p>Une condition basique pour la fonction est de fournir une distribution uniforme des valeurs de hash. Une distribution
non-uniforme augmente le nombre de collision est le coût pour les résoudre. L'uniformité est quelques fois difficile à garantir,
mais elle peut être évaluée de manière empirique via des tests statistiques.</p>
<p>La distribution doit être uniforme uniquement pour les tailles de tables de l'application. Si l'application utilise un
redimensionnement dynamique de la table avec un doublement ou une division par deux de la taille, alors la fonction de hachage
doit être uniforme uniquement lorsque la taille est une puissance de deux. Ici l'index peut être calculé comme un intervalle de
bits de la fonction de hachage. D'un autre côté, des algorithmes de hachage préfèrent avoir une taille exprimé à l'aide d'un
nombre premier. L'opération modulo peut fournir un petit mélange additionnel ; ceci est appréciable notamment pour une mauvaise
fonction de hachage.</p>
<p>Pour les schémas d'adressage ouvert, la fonction de hachage doit également éviter le <em>clustering</em>, l'adressage de deux ou de
plusieurs clefs à des emplacements consécutifs. Un tel regroupement peut être la cause d'une envolée du coût de recherche, même
si le facteur de charge est bas et que les collisions sont rares.</p>
<p>Les fonctions de hachages cryptographiques seraient capable de fournir de bonnes fonctions de hachages quelque soit la taille de
la table, soit par réduction modulo ou par masquage de bit. Elles peuvent également être utiles si il existe un risque
d'utilisateurs malveillants essayant de saboter un service réseau en envoyant des requêtes destinées à générées un grand nombre
de collisions dans les tables de hachage du serveur. Néanmoins, le risque de sabotage peut également être évité par des méthodes
moins coûteuses (tels qu'appliquer un sel secret à la donnée, ou utiliser une fonction de hachage universelle). Un inconvénient
des fonctions de hachages cryptographiques est qu'elles sont souvent plus lentes à être calculées, ce qui veut dire que dans
certains cas où l'uniformité pour n'importe quelle taille n'est pas nécessaire, une fonction de hachage non-cryptographique peut
être préférable.</p>
<p>Un hachage k-indépendant offre un moyen de prouver qu'une fonction de hachage n'a pas de mauvais ensembles de clefs pour un type
de table de hachage donné. De nombreux résultats de ce type sont connus pour des schémas de résolution de collision.</p>
<p>Si toutes les clefs sont connues à l'avance, une fonction de hachage parfaite peut être utilisée pour créer une table de hachage
parfaite sans aucune collision. Si un hachage parfait minimal est utilisé, chaque emplacement dans la table de hachage peut
également être utilisé.</p>
<p>Un hachage parfait permet un temps de recherche constant dans tout les cas. Ceci se détache de la majorité des méthodes de
chaînage et d'adressage ouvert, où le temps de recherche est bas en moyenne, mais peut être très grand, <em>O(n)</em>, par exemple
lorsque toutes les clefs sont hachées vers trop peu de valeurs.</p>
<p>Une statistique critique pour une table de hachage est le facteur de charge, défini comme :</p>
<p>Facteur de charge = n/k, où</p>
<ul>
<li><em>n</em> est le nombre des entrées occupées dans la table de hachage,</li>
<li><em>k</em> est le nombre d'emplacements.</li>
</ul>
<p>Quand le facteur de charge augmente, la table de hachage devient plus lente, et peut même cesser de fonctionner (en fonction de
la méthode utilisée). Le propriété attendue de temps constant pour une table de hachage suppose que le facteur de charge soit
gardé en deçà d'une certaine limite. Pour un nombre d'emplacement fixe, le temps pour une recherche augmente avec le nombre
d'entrées, par conséquent, le temps constant désiré n'est pas atteint. Dans plusieurs implémentations, la solution est de faire
croître automatiquement (généralement, doubler) la taille de la table lorsque la limite du facteur de charge est atteinte,
forçant de fait, un nouveau hachage de l'ensemble des entrées.</p>
<p>Après le facteur de charge, on peut examiner la variance du nombre d'entrées par emplacement.</p>
<p>Un facteur de charge bas n'est pas forcément bénéfique. Quand le facteur de charge approche 0, la proportion des aires
inutilisées dans la table de hachage augmente, mais il n'y a pas nécessairement une réduction dans le coût de recherche.</p>
<p>Les collision de hash sont pratiquement inévitables quand on hache un sous-ensemble aléatoire d'un large ensemble de clefs
possibles.</p>
<p>Par conséquent, presque toutes les implémentations de tables de hachages ont des stratégies de résolution de collisions afin de
gérer celles-ci. Toutes ces méthodes nécessitent que les clefs soient stockées dans la table, ensemble avec leurs valeurs
associées.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algorithmes-de-chiffrements"><a class="header" href="#algorithmes-de-chiffrements">Algorithmes de chiffrements</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algorithmes-de-chiffrements-1"><a class="header" href="#algorithmes-de-chiffrements-1">Algorithmes de chiffrements</a></h2>
<h3 id="chiffrement-symétrique-aes"><a class="header" href="#chiffrement-symétrique-aes">Chiffrement symétrique AES</a></h3>
<p>Le standard de chiffrement avancé (AES), aussi connu sous son nom originel Rijndael, est une spécification pour le chiffrement
des données électroniques établi par l'institut national des standards et technologies (NIST) en 2001.</p>
<p>AES est un sous-ensemble du chiffrement par bloc Rijndael. Rijndael est une famille de chiffres comprenant différentes clefs et
différentes tailles de blocs. Pour AES, NIST a sélectionné trois membres de la famille Rijndael, chacun ayant une taille de bloc
de 128 bits, mais trois longueurs de clefs différentes : 128, 192 et 256 bits.</p>
<p>AES est basé sur un principe simple connu sous le nom de réseau de substitution-permutation, et est efficace tant au niveau
logiciel que matériel.</p>
<p>AES opère sur un tableau de bits ordonné 4 x 4. La plupart des calculs AES sont effectués dans un champ fini particulier.</p>
<p>La taille de clef utilisée pour un chiffre AES spécifie le nombre de rondes de transformations qui convertissent l'entrée, appelée
texte en clair, à la sortie finale, appelée texte chiffré. Les nombres de rondes sont les suivants :</p>
<ul>
<li>10 rondes pour des clefs de 128 bits.</li>
<li>12 rondes pour des clefs de 192 bits.</li>
<li>14 rondes pour des clefs de 256 bits.</li>
</ul>
<p>Chaque ronde consiste en plusieurs étapes de calculs, incluant une étape qui dépend de la clef de chiffrement elle même. Un
ensemble de rondes inversées sont appliquées pour retransformer le texte chiffré en son texte original en clair à l'aide
de la même clef de chiffrement.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algorithmes-de-chiffrements-2"><a class="header" href="#algorithmes-de-chiffrements-2">Algorithmes de chiffrements</a></h2>
<h3 id="chiffrement-asymétrique-rsa"><a class="header" href="#chiffrement-asymétrique-rsa">Chiffrement asymétrique RSA</a></h3>
<p>Dans un système de chiffrement à clef publique, la clef de chiffrement est publique et distincte de la clef de déchiffrement,
qui est gardée secrète (privée). Un utilisateur RSA créé et publie une clef publique sur la base de deux grand nombres premiers,
ainsi qu'une valeur auxiliaire. Les nombres premiers sont gardés secret. Les messages peuvent être chiffrés par n'importe qui,
via la clef publique, mais peut uniquement être décodé par quelqu'un connaissant les nombres premiers.</p>
<p>La sécurité du RSA repose sur la difficulté pratique à factoriser le produit de deux grands nombres premiers, le &quot;problème de
factorisation&quot;.</p>
<p>RSA est un algorithme relativement lent. De ce fait, il n'est généralement pas directement utilisé pour chiffrer les données des
utilisateurs. Il est plus souvent utilisé pour transmettre des clefs partagées pour un chiffrement à clef symétrique, qui est
ensuite utilisé pour le chiffrement et déchiffrement des données.</p>
<p>La taille des clefs pour le chiffrement RSA varie entre 1024 et 4096 bits avec récemment une recommandation minimale de 2048
bits.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="programmation-orientée-objet"><a class="header" href="#programmation-orientée-objet">Programmation orientée objet</a></h2>
<p>La programmation orientée objet (POO), ou programmation par objet, est un paradigme de programmation informatique basé sur le
concept <em>d'objets</em>, qui peuvent contenir du code et des données : les données sous la forme de champs (attributs ou propriétés),
et le code sous la forme de procédures (méthodes).</p>
<p>Une capacité des objets est que ses procédures peuvent accéder et souvent modifier ses propres champs de données (<em>this</em> ou
<em>self</em>). En POO, les programmes informatiques sont créés de façon à pouvoir interagir les uns avec les autres. Les langages de
POO peuvent être très divers, mais les plus populaires sont basés sur la notion de classe, cela signifie que les objets sont des
instances de classes, qui déterminent également leurs types.</p>
<p>Une <em>classe</em> regroupe des membres, méthodes et propriétés (attributs) communs à un ensemble d'objets. La classe déclare, d'une
part, des attributs représentant l'état des objets et, d'autres part, des méthodes représentant leur comportement.</p>
<p>Il est possible de restreindre l'ensemble d'objets représenté par une classe A grâce à un mécanisme <em>d'héritage</em>. Dans ce cas,
on crée une nouvelle classe B liée à la classe A et qui ajoute de nouvelles propriétés.</p>
<p>Dans la programmation par objets, chaque objet est typé. Le type définit la syntaxe et la sémantique des messages auxquels peut
répondre un objet. Il correspond donc, à peu de chose près, à l'interface de l'objet.</p>
<p>Un objet peut appartenir à plus d'un type, c'est le <em>polymorphisme</em>, cela permet d'utiliser des objets de types différents là où
est attendu un objet d'un certain type.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="compilation"><a class="header" href="#compilation">Compilation</a></h2>
<p>Un compilateur est un programme qui transforme un code <em>source</em> en code <em>objet</em>. Généralement, le code source est écrit dans un
langage de programmation (le langage source), il est de haut niveau d'abstraction, et facilement compréhensible par l'humain. Le
code objet est généralement écrit en langage de plus bas niveau (appelé langage cible), par exemple un langage d'assemblage ou
langage machine, afin de créer un programme exécutable par une machine.</p>
<p>Un compilateur effectue les opérations suivantes : analyse lexicale, pré traitement (préprocesseur), analyse syntaxique
(parsing), analyse sémantique, et génération de code optimisé. La compilation est souvent suivie d'une étape d'édition de liens,
pour générer un fichier exécutable.</p>
<p>On distingue deux options de compilation :</p>
<ul>
<li>Ahead-of-time (AOT), où il faut compiler le programme avant de lancer l'application : la situation traditionnelle.</li>
<li>Compilation à la volée (just-in-time, en abrégé JIT) : cette faculté est apparue dans les années 1980 (par exemple Tcl/Tk)</li>
</ul>
<p>La tache principale d'un compilateur est de produire un code objet correct qui s'exécutera sur un ordinateur. La plupart des
compilateurs permettent d'optimiser le code, c'est-à-dire qu'ils vont chercher à améliorer la vitesse d'exécution, ou réduire
l'occupation mémoire du programme.</p>
<p>Un compilateur fonctionne par analyse-synthèse : au lieu de remplacer chaque construction du langage source par une suite
équivalente de constructions du langage cible, il commence par analyser le texte source pour en construire une <em>représentation
intermédiaire</em> qu'il traduit à son tour en langage cible.</p>
<p>On sépare le compilateur en au moins deux parties : une partie avant (ou frontale), parfois appelée &quot;souche&quot;, qui lit le texte
source et produit la représentation intermédiaire ; et la partie arrière (ou finale), qui parcours cette représentation pour
produire le texte cible. Dans un compilateur idéal, la partie avant est indépendante du langage cible, tandis que la partie
arrière est indépendante du langage source (voir <em>Low Level Virtual Machine</em>).</p>
<p>L'implémentation d'un langage de programmation peut être interprétée ou compilée. Cette réalisation est un compilateur ou un
interpréteur, et un langage de programmation peut avoir une implémentation compilée, et une autre interprétée.</p>
<p>On parle de compilation si la traduction est faite avant l'exécution, et d'interprétation si la traduction est finie pas à pas,
durant l'exécution.</p>
<p>Les premiers compilateurs ont été écrits directement en langage assembleur, un langage symbolique élémentaire correspondant aux
instructions du processeur cible et quelques structures de contrôle légèrement plus évoluées. Ce langage symbolique doit être
assemblé (et non compilé) et lié pour obtenir une version exécutable. En raison de sa simplicité, un programme simple suffit à
le convertir en instruction machines.</p>
<p>Les compilateurs actuels sont généralement écrits dans le langage qu'ils doivent compiler : il ne dépend alors plus d'un autre
langage pour être produit.</p>
<p>Dans ce cas, il est complexe de détecter un bogue de compilateur. Le <em>bootstrap</em> oblige donc les programmeurs de compilateurs à
contourner les bugs des compilateurs existants.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="api"><a class="header" href="#api">API</a></h2>
<p>Une Interface de Programmation d'Application (API) est une interface qui définit des interactions entre des applications
logicielles diverses. Elle définit le type d'appels ou de requêtes pouvant être exécutés, comment les faire, les formats de
données qui doivent être utilisés, les conventions qui en découlent, etc. Elle peut également fournir des mécanismes d'extension
de façon à ce que les utilisateurs puissent étendre les fonctionnalités existantes de plusieurs manières et à des degrés variés.
Une API peut être entièrement personnalisée, spécifique à un composant, ou construite à partir d'un standard afin de garantir
l'interopérabilité. À travers le masquage d'information, les APIs présentent une approche modulaire et permettent aux
utilisateurs d'accéder à l'interface indépendamment de son implémentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="api-1"><a class="header" href="#api-1">API</a></h2>
<h3 id="soap"><a class="header" href="#soap">SOAP</a></h3>
<p>SOAP (<em>Simple Object Access Protocol</em>) est une spécification de protocole de messages pour des échanges d'information structurée
dans l'implémentation de webs services à travers un réseau informatique. Son objectif est de fournir extensibilité, neutralité,
verbosité et indépendance. Elle utilise un ensemble d'information XML pour son format de message, et s'appuie sur des protocoles
de la couche application, la plupart du temps HTTP, bien que certains anciens systèmes communiquent via SMTP, pour la
négociation et la transmission de messages.</p>
<p>SOAP permet aux développeurs d'invoquer des processus s'exécutant sur des systèmes d'exploitation disparates d'authentifier,
d'autoriser, et de communiquer à l'aide du langage de balisage extensible (XML). Puisque les protocoles webs tels que HTTP sont
installés et actifs sur tous les systèmes d'exploitation, SOAP permet aux clients d'invoquer des services webs et de recevoir
des réponses indépendantes du langage et des plateformes.</p>
<p>SOAP fournit la couche de protocole de messages de la pile de protocoles des webs services. C'est un protocole basé sur le
langage XML qui consiste en trois parties :</p>
<ul>
<li>Une enveloppe, qui définit la structure du message et la façon de le traiter.</li>
<li>Un ensemble de règles d'encodage afin d'exprimer des instances de types de données définis par application.</li>
<li>Une convention pour représenter les appels de procédures et leurs réponses.</li>
</ul>
<p>SOAP a trois caractéristiques majeures :</p>
<ol>
<li>l'extensibilité</li>
<li>la neutralité (SOAP peut opérer à travers des protocoles tels que HTTP, SMTP, TCP, UDP)</li>
<li>l'indépendance (SOAP ne contraint en aucune façon le modèle de programmation)</li>
</ol>
<p>L'architecture SOAP consiste en plusieurs couches de spécifications pour :</p>
<ul>
<li>le format de message</li>
<li>les motifs d'échange de message (MEP)</li>
<li>les liens au protocole de transport sous-jacent</li>
<li>les modèles de traitement de messages</li>
<li>l'extensibilité du protocole</li>
</ul>
<p>SOAP a évolué en tant que successeur de XML-RPC, bien qu'il emprunte son transport et la neutralité d'interaction de l'adressage
des webs services et l'enveloppe/entête/corps d'autres modèles.</p>
<p>La spécification SOAP peut être grossièrement définie comme étant constituée des 3 composants conceptuels suivants : les
concepts de protocole, les concepts d'encapsulation et les concepts de réseau.</p>
<p><strong>SOAP</strong> est un ensemble de règles qui formalisent et gouvernent le format et les règles de traitement pour l'information
échangé entre l'émetteur et le receveur SOAP.</p>
<p><strong>Les noeuds SOAP</strong> sont des machines physiques/logiques avec des unités de traitement utilisées pour transmettre/relayer,
recevoir et traiter les messages SOAP. Ils sont analogues aux noeuds d'un réseau.</p>
<p><strong>Les rôles SOAP</strong> sont les rôles spécifiques qu'assument chacun des noeuds, à travers le chemin d'un message SOAP. Le rôle du
noeud définit l'action que le noeud doit effectuer sur le message qu'il reçoit. Par exemple, un rôle <em>none</em> signifie qu'aucun
noeud ne traitera l'entête SOAP en aucune façon et transmettra simplement le message le long de son chemin.</p>
<p><strong>Les liens aux protocoles SOAP</strong> sont les interactions du message SOAP travaillant en conjonction des autres protocoles afin de
transférer un message SOAP à travers le réseau. Par exemple, un message SOAP peut utiliser TCP comme sous-couche protocolaire
pour le transfert de messages. Ces liens sont définis dans le cadre des liens aux protocoles sous-jacent SOAP.</p>
<p><strong>Les fonctionnalités SOAP</strong> permettent d'étendre le cadre de message SOAP pour ajouter des fonctions telles que la fiabilité,
la sécurité etc. Il existe des règles à suivre lors de l'ajout de fonctionnalités au cadre SOAP.</p>
<p><strong>Les modules SOAP</strong> sont une collection de spécifications concernant la sémantique des entêtes SOAP pour décrire une nouvelle
fonctionnalité étendue s'ajoutant à SOAP. Un module requiert zéro ou plusieurs fonctionnalités. SOAP a besoin des modules pour
adhérer au règles prescrites.</p>
<p><strong>Le message SOAP</strong> représente l'information échangée entre 2 noeuds SOAP.</p>
<p><strong>L'enveloppe SOAP</strong> est l'ensemble des éléments délimiteurs d'un message XML qui l'identifie comme étant un message SOAP.</p>
<p><strong>Le bloc d'entête SOAP</strong> est un bloc de traitement discret contenu dans l'entête qui elle peut en contenir plusieurs. En
général, l'information du rôle SOAP est utilisée pour cibler des noeuds du chemin. Un bloc d'entête est dit être ciblé sur un
noeud SOAP si le rôle SOAP du bloc d'entête est le nom d'un rôle dans lequel le noeud SOAP opère. Par exemple le bloc d'entête
SOAP avec l'attribut de rôle <em>ultimateReceiver</em> est ciblé seulement au noeud destination qui a ce rôle. Un entête avec un
attribut de rôle <em>next</em> est ciblé pour chaque intermédiaire ainsi que le noeud destination.</p>
<p><strong>L'entête SOAP</strong> est une collection d'un ou de plusieurs blocs d'entêtes ciblés pour chaque receveurs SOAP.</p>
<p><strong>Le corps SOAP</strong> contient le corps du message à l'attention du receveur SOAP. L'interprétation et le traitement du corps SOAP
est défini par le blocs d'entêtes.</p>
<p><strong>L'erreur SOAP</strong> est un élément qui contient l'information d'erreur dans le cas où un noeud SOAP échoue à traiter un message
SOAP. Cet élément est contenu dans le corps SOAP en tant qu'élément enfant.</p>
<p><strong>L'émetteur SOAP</strong> est un noeud qui transmet un message SOAP.</p>
<p><strong>Le receveur SOAP</strong> est un noeud recevant un message SOAP. (Il peut s'agir d'un noeud intermédiaire ou d'un noeud destination)</p>
<p><strong>Le chemin du message SOAP</strong> est l'ensemble des noeuds que le message SOAP a traversé pour atteindre le noeud destination.</p>
<p><strong>L'émetteur initial SOAP</strong> est le noeud à l'origine de message SOAP à transmettre. C'est la racine du chemin du message SOAP.</p>
<p><strong>L'intermédiaire SOAP</strong> est le noeud situé entre l'émetteur initial et la destination SOAP voulue. Il traite les blocs d'entête
ciblés sur lui et agit pour relayer un message SOAP vers son ultime receveur SOAP.</p>
<p><strong>L'ultime receveur SOAP</strong> est le receveur destinataire du message SOAP. Ce noeud est responsable du traitement du corps du
message et des blocs d'entête ciblés sur lui.</p>
<p>La spécification SOAP définit un cadre de messages, qui consiste en :</p>
<ul>
<li>Le <strong>modèle de traitement SOAP</strong>, définissant les règles pour traiter un message SOAP.</li>
<li>Le <strong>modèle d'extensibilité SOAP</strong>, définissant les concepts de fonctionnalités et de modules SOAP.</li>
<li>Le <strong>cadre de liens aux protocoles sous-jacents</strong> décrivant les règles définissant les liens aux protocoles sous-jacents
pouvant être utilisés lors des échanges de messages entre noeuds SOAP.</li>
<li>Le <strong>concept de message SOAP</strong> définissant la structure d'un message SOAP.</li>
</ul>
<p>Un message SOAP est un document XML ordinaire contenant les éléments suivants :</p>
<table>
<tr>
    <th>Élément</th>
    <th>Description</th>
    <th>Requis</th>
</tr>
<tr>
    <td>Enveloppe</td>
    <td>Identifie le document XML en tant que message SOAP</td>
    <td>Oui</td>
</tr>
<tr>
    <td>Entête</td>
    <td>Contient les informations d'entête</td>
    <td>Non</td>
</tr>
<tr>
    <td>Corps</td>
    <td>Contient les informations d'appel et de réponse</td>
    <td>Oui</td>
</tr>
<tr>
    <td>Erreur</td>
    <td>Fournit des informations à propos d'erreurs ayant eu lieu lors du traitement du message</td>
    <td>Non</td>
</tr>
</table>
<p>À la fois SMTP et HTTP sont des protocoles de la couche application valides en tant que transports pour SOAP, mais HTTP est plus
largement utilisé du fait qu'il fonctionne bien avec l'infrastructure internet ; spécifiquement, HTTP fonctionne bien avec les
pare-feu réseaux. SOAP peut également être utilisé par dessus HTTPS (qui est le même protocole qu'HTTP au niveau application,
mais utilise un protocole de transport chiffré en dessous) avec une authentification simple ou mutuelle ; c'est la méthode
utilisée pour fournir une sécurité au niveau des webs services.</p>
<p>L'ensemble des informations XML a été choisi comme format de message standard du fait de son très large usage dans l'industrie
et des efforts de développements open source. Typiquement, l'ensemble des informations XML est sérialisé comme du XML.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="api-2"><a class="header" href="#api-2">API</a></h2>
<h3 id="rest"><a class="header" href="#rest">REST</a></h3>
<p>Le transfert d'état de représentations (REST) est un style d'architecture logicielle qui utilise un sous-ensemble d'HTTP. Il est
communément utilisé pour créer des applications interactives qui utilisent des services webs. Un service web qui suit ces lignes
directrices est appelé RESTful. Un tel service web doit fournir ses ressources webs dans une représentation textuelle et
permettre de les lire et de les modifier à l'aide d'un protocole sans état et d'un ensemble d'opérations prédéfinies. Cette
approche permet l'interopérabilité entre les systèmes informatiques sur l'Internet qui fournissent ces services. REST est une
alternative par exemple au protocole SOAP qui permet d'accéder à un service web.</p>
<p>Des <em>ressources webs</em> étaient définis premièrement sur le web comme étant des documents ou des fichiers identifiés par leur
URLs. Aujourd'hui, la définition est bien plus générique et abstraite, et inclut chaque chose, entité, ou action pouvant être
identifiée, nommée, adressée, gérée ou exécutée, de quelque manière que ce soit sur le Web. Dans un service web RESTful, les
requêtes effectuées à une URI de ressource obtiennent une réponse avec un chargement formaté en HTML, XML, JSON, ou quelque
autre format. Par exemple, la réponse peut confirmer que l'état de la ressource a changé. La réponse peut également inclure des
liens hypertextes vers des ressources liées. Le protocole le plus commun pour ces requêtes et ces réponses est HTTP. Il fournit
des opérations (méthodes HTTP) telles que GET, POST, PUT, et DELETE. En utilisant des protocoles sans état et des opérations
standards, les systèmes RESTful essaient de tendre vers la performance, la fiabilité et la capacité à s'étendre en réutilisant
des composants pouvant être gérés et mis à jours sans affecter le système dans son entièreté, même en cours d'exécution.</p>
<p>Le but de REST est d'améliorer la performance, la mise à l'échelle, la simplicité, l'adaptabilité, la visibilité, la portabilité,
et la fiabilité. Ceci est réalisé à travers le respect des principes de REST tels que l'architecture client-serveur, l'absence
d'états, la possibilité de mise en cache, l'utilisation de systèmes multi-couches, le support de code à la demande, et l'usage
d'interfaces uniformisées. Ces principes doivent être suivis pour qu'un système soit classifié en tant que système REST.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="api-3"><a class="header" href="#api-3">API</a></h2>
<h3 id="graphql"><a class="header" href="#graphql">GraphQL</a></h3>
<p>GraphQL est un langage de requêtage et de manipulation de données pour APIs, ainsi qu'un environnement d'exécution permettant de
répondre aux requêtes à l'aide de données existantes.</p>
<p>Il fournit une approche au développement d'APIs webs et est souvent comparé à REST et autres architectures de services webs. Il
permet aux clients de définir une structure de la donnée requise, et cette même structure de la donnée est retournée par le
serveur, prévenant ainsi le retour d'une trop grande quantité de données, mais ceci a des implications sur l'efficacité de la
mise en cache web des résultats de requêtes. La flexibilité et la richesse du langage de requêtage ajoute également une complexité
qui n'est pas forcément nécessaire pour des APIs simples. Malgré le nom, GraphQL ne fournit pas la richesse des opérations de
graphe que l'on peut trouver dans les bases de données orientées graphes tels que Neo4j, ou même certains dialectes de SQL qui
supportent les fermetures transitives. Par exemple, une interface GraphQL qui rapporte les parents d'un individu ne peut pas
retourner en une seule requête, l'ensemble de ses ancêtres.</p>
<p>GraphQL consiste en un système de types, un langage de requêtage et une sémantique d'exécution, une validation statique et une
introspection de type. Il supporte la lecture, l'écriture (mutation), et la souscription à des modifications de la donnée (mis à
jour en temps réel -- implémentée le plus souvent à l'aide de websockets). Les serveurs GraphQL sont disponibles pour de
nombreux langages de programmations.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="api-4"><a class="header" href="#api-4">API</a></h2>
<h3 id="grpc"><a class="header" href="#grpc">gRPC</a></h3>
<p>gRPC est un système d'appel de procédures distantes. Il utilise HTTP/2 pour le transport, et protobuf en tant que langage de
description d'interface, et fournit des fonctionnalités telles que l'authentification, le streaming bidirectionnel et le
contrôle de flux, les liaisons bloquantes ou non bloquantes, l'annulation et les dépassements de délais. Il génère des liaisons
entre les clients multi-plateformes et le serveur pour de nombreux langages. Les usages généraux incluent l'interconnexion de
services dans un style architectural microservices, ou la connexion de clients mobiles à des services backend.</p>
<p>gRPC supporte l'usage de TLS et d'une authentification basée token. Il y a deux types de certificats : les certificats de
canaux et les certificats d'appels.</p>
<p>gRPC utilise protobuf pour encoder la donnée. Contrairement aux APIs HTTP avec JSON, elles obéissent à une spécification
stricte.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="système"><a class="header" href="#système">Système</a></h1>
<h4 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h4>
<p>Ce chapitre traite de la partie système du programme PSE.</p>
<p>J'ai essayé de présenter à peu près logiquement et de manière globale mais loin d'être exhaustive, les éléments d'un système
d'exploitation (Linux). Pour aller plus loin sur l'ensemble des sujets évoqués on peut aller retrouver <a href="https://www.kernel.org/doc/html/latest/">la documentation du
noyau Linux</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication"><a class="header" href="#processus-et-mécanismes-de-communication">Processus et mécanismes de communication</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-1"><a class="header" href="#processus-et-mécanismes-de-communication-1">Processus et mécanismes de communication</a></h2>
<h3 id="multitâche-coopératif"><a class="header" href="#multitâche-coopératif">Multitâche coopératif</a></h3>
<p>Le multitâche coopératif est une forme simple de multitâche où chaque tâche doit explicitement permettre aux autres tâches de
s'exécuter. Cette approche simplifie l'architecture du système mais présente plusieurs inconvénients :</p>
<ul>
<li>Le multitâche coopératif est une forme de couplage fort. Si un des processus ne redonne pas la main à un autre processus, par
exemple si le processus est buggé, le système entier peut s'arrêter.</li>
<li>Le partage de ressources (temps CPU, mémoire, accès disque, etc.) peut être inefficace.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-2"><a class="header" href="#processus-et-mécanismes-de-communication-2">Processus et mécanismes de communication</a></h2>
<h3 id="multitâche-préemptif"><a class="header" href="#multitâche-préemptif">Multitâche préemptif</a></h3>
<p>Le multitâche préemptif désigne la capacité d'un système d'exploitation à exécuter ou arrêter une tâche planifiée en cours.</p>
<p>Un ordonnanceur préemptif présente l'avantage d'une meilleure réactivité du système et de son évolution, mais l'inconvénient
vient des situations de compétition (lorsque le processus d'exécution accède à la même ressource avant qu'un autre processus
(préempté) ait terminé son utilisation).</p>
<p>Dans un système d'exploitation multitâche préemptif, les processus ne sont pas autorisés à prendre un temps non défini pour
s'exécuter dans le processeur. Une quantité de temps définie est attribuée à chaque processus ; si la tâche n'est pas accomplie
avant la limite fixée, le processus est renvoyé dans la pile pour laisser place au processus suivant dans la file d'attente, qui
est alors exécuté par le processeur. Ce droit de préemption peut tout aussi bien survenir avec des interruptions matérielles.</p>
<p>Certaines tâches peuvent être affectées d'une priorité ; une tâche pouvant être spécifiée comme &quot;préemptible&quot; ou &quot;non
préemptible&quot;. Une tâche préemptible peut être suspendue (mise à l'état &quot;ready&quot;) au profit d'une tâche de priorité plus élevée ou
d'une interruption. Une tâche non préemptible ne peut être suspendue qu'au profit d'une interruption. Le temps qui lui est
accordé est plus long, et l'attente dans la file d'attente plus courte.</p>
<p>Au fur et à mesure de l'évolution des systèmes d'exploitation, les concepteurs ont quitté la logique binaire &quot;préemptible/non
préemptible&quot; au profit de systèmes plus fins de priorités multiples. Le principe est conservé, mais les priorités des programmes
sont échelonnées.</p>
<p>Pendant la préemption, l'état du processus (drapeaux, registres et pointeurs d'instruction) est sauvé dans la mémoire. Il doit
être rechargé dans le processeur pour que le code soit exécuté à nouveau : c'est la commutation de contexte.</p>
<p>Un système d'exploitation préemptif conserve en permanence la haute main sur les tâches exécutées par le processeur,
contrairement à un système d'exploitation non préemptif, ou collaboratif, dans lequel c'est le processus en cours d'exécution
qui prend la main et décide seul du moment où il la rend. L'avantage le plus évident d'un système préemptif est qu'il peut en
permanence décider d'interrompre un processus, principalement si celui-ci échoue et provoque l'instabilité du système.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-3"><a class="header" href="#processus-et-mécanismes-de-communication-3">Processus et mécanismes de communication</a></h2>
<h3 id="algorithmes-dordonnancement"><a class="header" href="#algorithmes-dordonnancement">Algorithmes d'ordonnancement</a></h3>
<p>L'ordonnanceur désigne le composant du noyau du système d'exploitation choisissant l'ordre d'exécution des processus sur les
processeurs d'un ordinateur.</p>
<p>Un processus a besoin de la ressource processeur pour exécuter des calculs ; il l'abandonne quand se produit une interruption,
etc. De nombreux anciens processeurs ne peuvent effectuer qu'un traitement à la fois. Pour les autres, un ordonnanceur reste
nécessaire pour déterminer quel processus sera exécuté sur quel processeur (c'est la notion d'affinité, très importante pour ne
pas dégrader les performances). Au-delà des classiques processeurs multicoeurs, la notion d'hyperthreading rend la question de
l'ordonnancement encore un peu plus complexe.</p>
<p>A un instant donné, il y a souvent davantage de processus à exécuter que de processeurs.</p>
<p>Un des rôles de système d'exploitation et plus précisément de l'ordonnanceur du noyau, est de permettre à tous ces processus de
s'exécuter à un moment ou un autre et d'utiliser au mieux le processeur pour l'utilisateur. Pour que chaque tâche s'exécute sans
se préoccuper des autres et/ou aussi pour exécuter les tâches selon les contraintes imposées au système, l'ordonnanceur du noyau
du système effectue des commutations de contexte de celui-ci.</p>
<p>A intervalles réguliers, le système appelle une procédure d'ordonnancement qui <em>élit</em> le prochain processus à exécuter. Si le
nouveau processus est différent de l'ancien, un changement de contexte (opération consistant à sauvegarder le contexte
d'exécution de l'ancienne tâche comme les registres du processeur) a lieu. Cette structure de données est généralement appelée
PCB (process control block). Le système d'exploitation restaure l'ancien PCB de la tâche élue, qui s'exécute alors en reprenant
là où elle s'était arrêtée précédemment.</p>
<p>Du choix de l'algorithme d'ordonnancement dépend le comportement du système. Il existe deux grandes classes d'ordonnancement :</p>
<ul>
<li><strong>L'ordonnancement en temps partagé</strong> présent sur la plupart des ordinateurs &quot;classiques&quot;. Par exemple l'ordonnancement
&quot;decay&quot; ; qui est celui par défaut sous Unix. Il consiste en un système de priorités adaptatives, par exemple il privilégie les
tâches interactives pour que leur temps de réponse soit bon. Une sous-classe de l'ordonnancement en temps partagé sont les
ordonnanceurs dits &quot;proportional share&quot;, eux sont plus destinés aux stations de calcul et permettent une gestion rigoureuse des
ressources. On peut citer notamment &quot;lottery&quot; et &quot;stride&quot;.</li>
<li><strong>L'ordonnancement en temps réel</strong> qui assure qu'une certaine tâche sera terminée dans un délai donné. Cela est indispensable
dans les systèmes embarqués. Un ordonnanceur temps réel est dit optimal pour un système de tâches s'il trouve une solution
d'ordonnancement du système lorsque cette solution existe. S'il ne trouve pas de solution à ce système, alors aucun autre
ordonnanceur ne peut en trouver une.</li>
</ul>
<p>Algorithmes d'ordonnancement :</p>
<ul>
<li><strong>Round-robin (ou méthode du tourniquet)</strong> : Une petite unité de temps appelé quantum de temps est définie. La file d'attente
est gérée comme une file circulaire. L'ordonnanceur parcourt cette file et alloue un temps processeur à chacun des processus
pour un intervalle de temps de l'ordre d'un quantum au maximum. La performance de round-robin dépend fortement du choix du
quantum de base.</li>
<li><strong>Rate-monotonic scheduling (RMS)</strong> : L'ordonnancement à taux monotone est un algorithme d'ordonnancement temps réel en ligne
à priorité constante (statique). Il attribue la priorité la plus forte à la tâche qui possède la plus petite période. RMS est
optimal dans le cadre d'un système de tâches périodiques, synchrones, indépendantes et à échéance sur requête avec un
ordonnanceur préemptif. De ce fait, il n'est généralement utilisé que pour ordonnancer des tâches vérifiant ces propriétés.</li>
<li><strong>Earliest deadline first scheduling (EDF)</strong> : C'est un algorithme d'ordonnancement préemptif à priorité dynamique, utilisé
dans les systèmes temps réels. Il attribue une priorité à chaque requête en fonction de l'échéance de cette dernière selon la
règle : Plus l'échéance d'une tâche est proche, plus sa priorité est grande. De cette manière, au plus vite le travail doit être
réalisé, au plus il a des chances d'être exécuté.</li>
<li><strong>FIFO</strong> : Les premiers processus ajoutés à la file seront les premières à être exécutés.</li>
<li><strong>Shortest job first (SJF, ou SJN-Shortest Job Next)</strong> : Le choix se fait en fonction du temps d'exécution estimé du
processus. Ainsi l'ordonnanceur va laisser passer en priorité le plus court des processus de la file d'attente.</li>
<li><strong>Completely Fair Scheduler (CFS)</strong> : L'ordonnanceur des tâches pour le noyau Linux. Il gère l'allocation de ressource
processeur pour l'exécution des processus, en maximisant l'utilisation globale CPU tout en optimisant l'interactivité. CFS
utilise un arbre rouge-noir implémentant une chronologie des futures exécutions des tâches. En effet, l'arbre trie les processus
selon une valeur representative du manque de ces processus en temps d'allocation du processeur, par rapport au temps qu'aurait
alloué un processeur dit multitâche idéal. De plus, l'ordonnanceur utilise une granularité temporelle à la nanoseconde, rendant
redondante la notion de tranche de temps, les unités atomiques utilisées pour le partage du CPU entre processus. Cette
connaissance précise signifie également qu'aucune heuristique (basée sur la statistique, donc pouvant commettre des erreurs)
n'est requise pour déterminer l'interactivité d'un processus.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-4"><a class="header" href="#processus-et-mécanismes-de-communication-4">Processus et mécanismes de communication</a></h2>
<h3 id="synchronisation"><a class="header" href="#synchronisation">Synchronisation</a></h3>
<p>En programmation concurrente, la synchronisation se réfère à deux concepts distincts mais liés : la synchronisation de processus
et la synchronisation des données. La synchronisation de processus est un mécanisme qui vise à bloquer l'exécution de certains
processus à des points précis de leur flux d'exécution, de manière que tous les processus se rejoignent à des étapes relais
données, tel que prévu par le programmeur. La synchronisation de données, elle, est un mécanisme qui vise à conserver la
cohérence des données telles que vues par différents processus, dans un environnement multitâche. Initialement, la notion de
synchronisation est apparue pour la synchronisation de données.</p>
<p>Ces problèmes dits &quot;de synchronisation&quot; et même plus généralement ceux de communication inter-processus dont ils dépendent
rendent pratiquement toujours la programmation concurrente plus difficile. Certaines méthodes de programmation, appelées
synchronisation non-blocante, cherchent à éviter d'utiliser des verrous, mais elles sont encore plus difficiles à mettre en
oeuvre et nécessitent la mise en place de structure de données particulières. La mémoire transactionnelle logicielle en est une.</p>
<p>La synchronisation de processus cherche par exemple à empêcher des programmes d'exécuter la même partie de code en même temps,
ou au contraire forcer l'exécution de deux partie de code en même temps. Dans la première hypothèse, le premier processus bloque
l'accès à la section critique avant d'y entrer et libère l'accès après y être sorti. Ce mécanisme peut être implémenté de
multiples manières.</p>
<p>Ces mécanismes sont par exemple la barrière de synchronisation, l'usage conjoint des sémaphores et des verrous, les spinlock, le
moniteur.</p>
<ul>
<li><strong>Barrière de synchronisation</strong> : Permet de garantir qu'un certain nombre de tâches aient passé un point spécifique. Ainsi,
chaque tâche qui arrivera sur cette barrière devra attendre jusqu'à ce que le nombre spécifié de tâches soient arrivées à cette
barrière.</li>
<li><strong>Sémaphore</strong> : Variable partagée par différents &quot;acteurs&quot; qui garantit que ceux-ci ne peuvent accéder de façon séquentielle à
travers des opérations atomiques, et constitue la méthode utilisée couramment pour restreindre l'accès à des ressources
partagées et synchroniser les processus dans un environnement de programmation concurrente.</li>
<li><strong>Verrous</strong> : Permet d'assurer qu'un seul processus accède à une ressource à un instant donné. Un verrou peut être posé pour
protéger un accès en lecture et permettra à plusieurs processus de lire, mais aucun d'écrire. On dit alors que c'est un verrou
partagé. Un verrou est dit exclusif lorsqu'il interdit toute écriture et toute lecture en dehors du processus qui l'a posé. La
granularité d'un verrou constitue l'étendue des éléments qu'il protège. Par exemple dans les bases de données, un verrou peut
être posé sur une ligne, un lot de ligne, une table etc.</li>
<li><strong>Spinlocks</strong> : Mécanisme simple de synchronisation basé sur l'attente active.</li>
<li><strong>Moniteur</strong> : Mécanisme de synchronisation qui permet à plusieurs threads de bénéficier de l'exclusion mutuelle et la
possibilités d'attendre (<em>block</em>) l'invalidation d'une condition. Les moniteurs ont également un mécanisme qui permet aux autres
threads de signaler que leur condition est validé. Il est constitué d'un mutex et de variables conditionnelles.</li>
</ul>
<p>La connaissance des dépendances entre les données est fondamentale dans la mise en oeuvre d'algorithmes parallèles, d'autant
qu'un calcul peut dépendre de plusieurs calculs préalables. Les <em>conditions de Bernstein</em> permettent de déterminer les
conditions sur les données lorsque deux parties de programme peuvent être exécutées en parallèle.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-5"><a class="header" href="#processus-et-mécanismes-de-communication-5">Processus et mécanismes de communication</a></h2>
<h3 id="signaux"><a class="header" href="#signaux">Signaux</a></h3>
<p>Un signal est une forme de communication entre processus utilisée par les systèmes de type Unix et ceux respectant les standards
POSIX. Il s'agit d'une notification asynchrone envoyée à un processus pour lui signaler l'apparition d'un événement. Quand un
signal est envoyé à un processus, le système d'exploitation interrompt l'exécution normale de celui-ci. Si le processus possède
une routine de traitement pour le signal reçu, il lance son exécution. Dans le cas contraire, il exécute la routine des signaux
par défaut.</p>
<p>La norme POSIX (et la documentation de Linux) limite les fonctions directement ou indirectement appelables depuis cette routine
de traitements des signaux. Cette norme donne une liste exhaustive de fonctions primitives dites <em>async-signal safe</em> (en
pratique les appels systèmes) qui sont les seules à pouvoir être appelées depuis une routine de traitement de signal sans avoir
un comportement indéfini. Il est donc suggéré d'avoir une routine de traitement de signal qui positionne simplement un drapeau
déclaré <em>volatile sig_atomic_t</em> qui serait testé ailleurs dans le programme.</p>
<p>L'appel système kill(2) permet d'envoyer, si cela est permis, un signal à un processus. La commande kill(1) utilise cet appel
système pour faire de même depuis le shell. La fonction raise(3) permet d'envoyer un signal au processus courant.</p>
<p>Les exceptions comme les erreurs de segmentation ou les divisions par zéro génèrent des signaux. Ici les signaux générés seront
respectivement SIGSEGV et SIGFPE. Un processus recevant ces signaux se terminera et générera un core dump par défaut.</p>
<p>Le noyau peut générer des signaux pour notifier les processus que quelque chose s'est passé. Par exemple, SIGPIPE est envoyé à
un processus qui essaye d'écrire dans un pipe qui a été fermé par celui qui lit. Par défaut, le programme se termine alors. Ce
comportement rend la construction de pipeline en shell aisée.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-6"><a class="header" href="#processus-et-mécanismes-de-communication-6">Processus et mécanismes de communication</a></h2>
<h3 id="socket-réseau"><a class="header" href="#socket-réseau">Socket réseau</a></h3>
<p>Une socket réseau est une structure logicielle comprise dans un noeud réseau qui sert de point d'arrivée pour les données
envoyées et reçues à travers le réseau. La structure et les propriétés d'une socket sont définies par une interface de
programmation (API) de l'architecture réseau. Les sockets sont créées uniquement durant l'intervalle de temps d'un processus
d'une application s'exécutant dans le noeud.</p>
<p>Du fait de la standardisation des protocoles TCP/IP au cours du développement d'Internet, le terme <em>socket réseau</em> est plus
communément utilisé dans le contexte de la <em>Suite des protocoles Internets</em>. On parle alors aussi de socket internet. Dans ce
contexte, une socket est identifiée extérieurement par les autres machines par son <em>adresse socket</em>, qui est la triade du
protocole de transfert, de l'adresse IP et du numéro de port.</p>
<p>Une pile de protocole, habituellement fournie par le système d'exploitation est un ensemble de services permettant aux processus
de communiquer à travers un réseau utilisant les protocoles que la pile implémente. Le système d'exploitation fait passer les
données utiles des paquets IP entrants à l'application correspondante en lisant l'information de l'adresse socket des entêtes
des protocoles IP et transport et en enlevant ces entêtes des données applications.</p>
<p>L'interface de programmation que les programmes utilisent pour communiquer avec la pile de protocole, utilisant les sockets
réseaux, est appelée <strong>socket API</strong>. Les API sockets internet sont généralement basées sur le standard socket de Berkeley. Dans
le standard socket de Berkeley, les socket sont une forme de descripteur de fichier (<em>read, write, open, close</em>).</p>
<p>Dans les protocoles internet standards TCP et UDP, une adresse socket est la combinaison d'une adresse IP et d'un numéro de
port. Les sockets n'ont pas besoin d'adresse source, mais si un programme lie la socket à une adresse source, la socket peut
être utilisée pour recevoir et envoyer des données à cette adresse. Basé sur cette adresse, les sockets internet délivrent les
paquets applicatifs entrants au processus applicatif approprié.</p>
<p>Plusieurs types de sockets internet sont disponibles :</p>
<ul>
<li><strong>Datagram</strong> : Des sockets non connectées, qui utilisent le protocole UDP (<em>User Datagram Protocol</em>). Chaque paquet envoyé ou
reçu avec un socket datagramme est adressé et routé individuellement. L'ordre ainsi que la fiabilité ne sont pas garantis, par
conséquent plusieurs paquets envoyés depuis un processus à un autre peuvent arriver dans n'importe quel ordre ou bien ne pas
arriver du tout. Certaines configurations spéciales peuvent être requises pour envoyer en broadcast un socket datagramme.</li>
<li><strong>Stream</strong> : Des socket connectés, qui utilisent les protocoles TCP (<em>Transmission Control Protocol</em>), SCTP (<em>Stream Control
Transmission Protocol</em>) ou DCCP (<em>Datagram Congestion Control Protocol</em>). Un socket flux fournit un flot de données sans
erreurs, séquencé, unique et ininterrompu avec des mécanismes prédéfinis pour créer et détruire des connexions et rapporter des
erreurs. Un socket flux transmet des données de manière fiable, ordonnée sans requérir l'établissement préalable d'un canal de
communication.</li>
<li><strong>Raw</strong> : Permet l'envoie et la réception de paquets IP sans aucun formatage spécifique à un protocole de la couche transport.
Avec les autres types de socket, la donnée est automatiquement encapsulée selon le protocole de la couche transport choisi (TCP,
UDP etc.), et l'utilisateur du socket n'a pas connaissance de l'existence des entêtes du protocole. Quand on lit d'un socket
brut, les entêtes sont généralement inclus. Lorsqu'on transmet des paquets depuis un socket brut, l'addition automatique d'une
entête est optionnelle.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-7"><a class="header" href="#processus-et-mécanismes-de-communication-7">Processus et mécanismes de communication</a></h2>
<h3 id="socket-ipc"><a class="header" href="#socket-ipc">Socket IPC</a></h3>
<p>Un socket de domaine Unix ou socket IPC (<em>inter-process communication</em>) et un point d'arrivée des données de communications qui
permet d'échanger des données entre des processus s'exécutant sur le même système d'exploitation hôte. Les types de socket
valides dans le domaine UNIX sont :</p>
<ul>
<li><strong>SOCK_STREAM</strong> (à comparer au TCP) - pour un socket orienté flux</li>
<li><strong>SOCK_DGRAM</strong> (à comparer à UDP) - pour un socket orienté datagramme qui préserve les limites des messages (comme la plupart
des implémentations UNIX, les socket de domaine UNIX datagram sont toujours fiables et ne réordonnent pas les datagrammes)</li>
<li><strong>SOCK_SEQPACKET</strong> (à comparer à SCTP) - pour un socket à paquets séquencés orienté connexion, qui préserve les limites des
messages, et livre les paquets dans l'ordre d'envoi.</li>
</ul>
<p>Les sockets de domaine Unix sont une composante standard des systèmes d'exploitation POSIX.</p>
<p>Les interfaces de programmation (API) pour les sockets de domaine Unix sont similaires à celles des sockets internet, mais au
lieu d'utiliser un protocole réseau sous-jacent, toutes les communications se placent à l'intérieur du noyau du système
d'exploitation. Les socket de domaine Unix peuvent utiliser le système de fichiers comme adresse d'espace de noms. (Certains
systèmes d'exploitation, comme Linux, offrent des espaces de noms additionnels.) Les processus référencent les sockets de
domaine Unix comme des inodes du système de fichier, ainsi 2 processus peuvent communiquer en ouvrant la même socket.</p>
<p>En plus de permettre l'envoi de données, les processus peuvent envoyer des descripteurs de fichiers à travers une connexion de
socket de domaine Unix en utilisant les appels systèmes sendmsg() et recvmsg(). Ceci permet au processus qui envoie d'autoriser
le processus qui reçoit à accéder au descripteur de fichier auquel autrement le processus qui reçoit n'a pas accès. Ceci permet
d'implémenter une forme rudimentaire de sécurité basée sur l'accessibilité.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-8"><a class="header" href="#processus-et-mécanismes-de-communication-8">Processus et mécanismes de communication</a></h2>
<h3 id="socket-netlink"><a class="header" href="#socket-netlink">Socket Netlink</a></h3>
<p>La famille de socket Netlink est une interface du noyau Linux utilisée pour des communications inter-processus entre les
processus de l'espace utilisateur et du noyau et entre différents processus utilisateurs. La différence entre les sockets
Netlink et les socket IPC et qu'au lieu d'utiliser l'espace de noms du système de fichiers, les processus Netlink sont
généralement désignés par leurs PIDs.</p>
<p>Netlink fournit une interface socket standard pour les processus utilisateurs, et une API côté noyau pour un usage interne par
les modules du noyau.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-9"><a class="header" href="#processus-et-mécanismes-de-communication-9">Processus et mécanismes de communication</a></h2>
<h3 id="tube-anonyme"><a class="header" href="#tube-anonyme">Tube anonyme</a></h3>
<p>Un tube anonyme est un mécanisme de gestion de flux de donnée. Ce mécanisme inventé pour UNIX est principalement utilisé dans la
communication inter-processus. Ouvrir un tube anonyme permet de créer un flux de donnée unidirectionnel FIFO entre un processus
et un autre. Ces tubes sont détruits lorsque le processus qui les a créés disparaît, contrairement aux tubes nommés qui sont
liés au système d'exploitation et qui doivent être explicitement détruits.</p>
<p>Ce mécanisme permet la création de filtres.</p>
<p>Pour les système d'exploitation de type Unix, un tube anonyme est créé grâce à un appel système qui retourne un descripteur de
fichier à la suite de la création d'un Fork qui permet d'assigner à chacun des processus son rôle de récepteur ou d'émetteur.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-10"><a class="header" href="#processus-et-mécanismes-de-communication-10">Processus et mécanismes de communication</a></h2>
<h3 id="tube-nommé"><a class="header" href="#tube-nommé">Tube nommé</a></h3>
<p>Comme les tubes anonymes, les tubes nommés sont des zones de données organisées en FIFO mais contrairement à ceux-ci qui sont
détruits lorsque le processus qui les a créés disparait, les tubes nommés sont liés au système d'exploitation et ils doivent
être explicitement détruits.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-11"><a class="header" href="#processus-et-mécanismes-de-communication-11">Processus et mécanismes de communication</a></h2>
<h3 id="passage-de-messages"><a class="header" href="#passage-de-messages">Passage de messages</a></h3>
<p>Le modèle de passage de messages et une technique permettant de demander l'exécution d'un programme. Le passage de message
utilise un modèle objet afin de distinguer la fonction générale de ses implémentations spécifiques. Le programme appelant envoie
un message et se fie à l'objet afin de sélectionner et d'exécuter le code approprié. L'utilisation d'une couche intermédiaire,
est justifiée par des besoins de distribution et d'encapsulation.</p>
<p>L'encapsulation suit l'idée que les objets logiciels devraient être capables d'invoquer les services d'autres objets sans avoir
aucune connaissance spécifique de leurs implémentations. L'encapsulation permet de réduire les lignes de codes ainsi qu'une plus
grande maintenabilité des systèmes.</p>
<p>Le passage de messages distribué permet au développeur, à l'aide d'une couche fournissant les services de base de construire des
systèmes constitués de sous-systèmes s'exécutant sur des ordinateurs disparates, à différents endroit et à des horaires
différents. Lorsqu'un objet distribué envoie un message, la couche message s'occupe de :</p>
<ul>
<li>Trouver d'où et de quel processus le message est issu.</li>
<li>Sauvegarder le message dans une file si l'objet approprié au traitement du message n'est pas en cours d'exécution et s'occuper
de l'envoyer dès que l'objet est disponible. Ainsi que de stocker le résultat si besoin, jusqu'à ce que l'objet qui a envoyé le
message est prêt à le recevoir.</li>
<li>Contrôler diverses dépendances transactionnelles pour les transactions distribuées.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="processus-et-mécanismes-de-communication-12"><a class="header" href="#processus-et-mécanismes-de-communication-12">Processus et mécanismes de communication</a></h2>
<h3 id="d-bus"><a class="header" href="#d-bus">D-Bus</a></h3>
<p>D-Bus est un système de bus de message et un mécanisme de communication inter-processus.</p>
<p>D-Bus fournit à la fois un daemon système et un daemon par-session-de-connexion-utilisateur (pour les IPCs généraux entre
applications utilisateurs).</p>
<p>D-Bus permet à des programmes clients de s'enregistrer auprès de lui, afin d'offrir leurs services aux autres programmes. Il
leur permet également de savoir quels services sont disponibles. Les programmes peuvent aussi s'enregistrer afin d'être informés
d'événements signalés par le noyau, comme le branchement d'un nouveau périphérique.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-de-la-mémoire-centrale"><a class="header" href="#gestion-de-la-mémoire-centrale">Gestion de la mémoire centrale</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-de-la-mémoire-centrale-1"><a class="header" href="#gestion-de-la-mémoire-centrale-1">Gestion de la mémoire centrale</a></h2>
<h3 id="fichier-mappé-en-mémoire"><a class="header" href="#fichier-mappé-en-mémoire">Fichier mappé en mémoire</a></h3>
<p>Un fichier mappé en mémoire est un segment de mémoire virtuelle qui est la copie d'une portion de fichier ou d'une ressource de
type fichier. Cette ressource est typiquement un fichier présent sur le disque, mais cela peut également être un périphérique,
un objet en mémoire partagée, ou toute autre ressource que le système d'exploitation peut référencer à l'aide d'un descripteur
de fichier. Une fois présente en mémoire, cette corrélation entre le fichier et l'espace mémoire permet aux applications de
traiter la partie mappée comme s'il s'agissait de la mémoire primaire.</p>
<p>Le bénéfice d'utiliser le mappage en mémoire est d'augmenter les performances d'entrée/sortie notamment sur les fichiers de gros
volume. Pour les petits fichiers, les fichiers mappés peuvent engendrer des problèmes de fragmentation interne du fait que les
maps mémoires sont toujours aligné sur la taille de la page (généralement 4Ko). Par conséquent, un fichier de 5Ko allouera 8Ko
et gâchera 3Ko. Accéder aux fichiers mappés en mémoire est plus rapide que d'utiliser des opérations de lecture et d'écriture
directement pour 2 raisons. Premièrement, un appel système est bien plus lent qu'un accès vers la mémoire locale du programme.
Deuxièmement, dans la plupart des systèmes d'exploitation la région mémoire mappée est la page cache du noyau, c'est à dire que
cela ne nécessite aucune copie en espace utilisateur.</p>
<p>Le processus de mapping mémoire est géré par le gestionnaire de mémoire virtuelle, qui est le même sous-système responsable de
la pagination. Les fichiers mappés sont chargés une page entière à la fois. La taille de la page est choisi par le système
d'exploitation pour un maximum de performance. Sachant que la pagination est un élément critique du gestionnaire de mémoire
virtuelle, le chargement des portions de la taille d'une page d'un fichier en mémoire physique est généralement une fonction
système très optimisée.</p>
<p>L'usage le plus commun de fichier mappé en mémoire est le chargement de processus. Lors de la création d'un processus, le
système d'exploitation utilise un fichier mappé en mémoire pour faire apparaître le fichier exécutable ainsi que tous les
modules chargeable en mémoire pour exécution. La technique la plus utilisée est la demande de pages, le fichier est chargé en
mémoire physique par section (chacune d'une page), et seulement quand cette page est référencée. Dans le cas spécifique des
exécutables, cela permet à l'OS de charger de manière sélective uniquement les portions de l'image processus qui nécessitent
réellement une exécution.</p>
<p>Un autre usage répandu pour les fichiers mappés en mémoire est le partage de fichiers entre processus multiples. Ceci permet
d'éviter les fautes de pages ainsi que les violations de segmentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-de-la-mémoire-centrale-2"><a class="header" href="#gestion-de-la-mémoire-centrale-2">Gestion de la mémoire centrale</a></h2>
<h3 id="mémoire-virtuelle"><a class="header" href="#mémoire-virtuelle">Mémoire virtuelle</a></h3>
<p>Le principe de mémoire virtuelle repose sur l'utilisation de traduction à la volée des adresses virtuelles vue du logiciel, en
adresses physiques de mémoire vive. La mémoire virtuelle permet :</p>
<ul>
<li>d'utiliser de la mémoire de masse comme extension de la mémoire vive ;</li>
<li>d'augmenter le taux de multiprogrammation ;</li>
<li>de mettre en place des mécanismes de protection de la mémoire ;</li>
<li>de partager la mémoire entre processus.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-de-la-mémoire-centrale-3"><a class="header" href="#gestion-de-la-mémoire-centrale-3">Gestion de la mémoire centrale</a></h2>
<h3 id="pagination"><a class="header" href="#pagination">Pagination</a></h3>
<p>Les adresses mémoires émises par le processeur sont des adresses virtuelles, indiquant la position d'un mot dans la mémoire
virtuelle. Cette mémoire virtuelle est formée de zones de même taille, appelées pages. Une adresse virtuelle est donc un couple
(numéro de page, déplacement dans la page). La taille des pages est une puissance entière de deux, de façon à déterminer sans
calcul le déplacement (10 bits de poids faible de l'adresse virtuelle pour des pages de 1024 mots), et le numéro de page (les
autres bits). La mémoire vive est également composées de zones de même taille, appelées cadres (<em>frames</em>), dans lesquelles
prennent place les pages (un cadre contient une page : taille d'un cadre = taille d'une page). La taille de l'ensemble des
cadres en mémoire vive utilisés par un processus est appelé <em>Resident set size</em>. Un mécanisme de traduction (<em>translation</em>)
assure la conversion des adresses virtuelles en adresses physiques, en consultant une table des pages (<em>page table</em>) pour
connaître le numéro du cadre qui contient la page recherchée. L'adresse physique obtenue est le couple (numéro de cadre,
déplacement). Il peut y avoir plus de pages que de cadres (c'est là tout l'intérêt) : les pages qui ne sont pas en mémoire sont
stockées sur un autre support (disque), elle seront ramenées dans un cadre quand on en aura besoin.</p>
<p>La table des pages est indexée par le numéro de page. Chaque ligne est appelée &quot;entrée dans la table des pages (<em>pages table
entry</em> PTE), et contient le numéro de cadre. La table des pages pouvant être située n'importe où en mémoire, un registre spécial
(PTBR pour <em>Page Table Base Register</em>) conserve son adresse.</p>
<p>En pratique, le mécanisme de traduction fait partie d'un circuit électronique appelé MMU (<em>memory management unit</em>) qui contient
également une partie de la table des pages, stockée dans une mémoire associative formée de registres rapides. Ceci évite d'avoir
à consulter la table des pages (en mémoire) pour chaque accès mémoire.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-de-la-mémoire-centrale-4"><a class="header" href="#gestion-de-la-mémoire-centrale-4">Gestion de la mémoire centrale</a></h2>
<h3 id="segmentation"><a class="header" href="#segmentation">Segmentation</a></h3>
<p>La segmentation est une technique de découpage de la mémoire. Elle est gérée par l'unité de segmentation de l'unité de gestion
mémoire (<em>MMU</em>), utilisée sur les systèmes d'exploitation modernes, qui divise la mémoire physique (dans le cas de la
segmentation pure) ou la mémoire virtuelle (dans le cas de la segmentation avec pagination) en segments caractérisés par leur
adresse de début et leur taille (<em>décalage</em>).</p>
<p>La segmentation permet la séparation des données du programme (entre autres segments) dans des espaces logiquement indépendants
facilitant alors la programmation, l'édition de liens et le partage inter-processus. La segmentation permet également d'offrir
une plus grande protection grâce au niveau de privilège de chaque segment.</p>
<p>Lorsque l'unité de gestion mémoire (MMU) doit traduire une adresse logique en adresse linéaire, l'unité de segmentation doit
dans un premier temps utiliser la première partie de l'adresse, c'est à dire le sélecteur de segment, pour retrouver les
caractéristiques du segment (base, limit, DPL, etc.) dans la table de descripteurs (GDT ou LDT). Puis il utilise la valeur de
décalage qui référence l'adresse à l'intérieur du segment.</p>
<p>Il existe sur la majorité des processeurs actuels, des registres de segments (CS, DS, SS, etc.) qui contiennent le sélecteur de
segment dernièrement utilisé par le processeur qui sont utilisés pour accélérer l'accès à ces sélecteurs.</p>
<p>Sur les processeurs récents, il existe également des registres associés à chaque registre de segment qui contiennent le
descripteur de segment associé pour un accès plus rapide aux descripteurs.</p>
<p>Un segment mémoire est un espace d'adressage indépendant défini par deux valeurs :</p>
<ul>
<li>L'adresse où il commence (aussi appelée <em>base</em>, ou <em>adresse de base</em>)</li>
<li>Sa taille ou son <em>décalage</em> (aussi appelée <em>limite</em> ou <em>offset</em>)</li>
</ul>
<p>Un segment constitue donc dans la mémoire principale un plage d'adresse continue. Les segments se chevauchent. On peut donc
adresser la même zone mémoire avec plusieurs couples segment/offset.</p>
<p>Il existe différents types de segment :</p>
<ul>
<li>Les segments de données statiques</li>
<li>Les segments de données globales</li>
<li>Les segments de code</li>
<li>Les segments d'état de tâche</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-des-périphériques"><a class="header" href="#gestion-des-périphériques">Gestion des périphériques</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-des-périphériques-1"><a class="header" href="#gestion-des-périphériques-1">Gestion des périphériques</a></h2>
<h3 id="pilotes"><a class="header" href="#pilotes">Pilotes</a></h3>
<p>Un pilote est un programme qui opère et contrôle un périphérique. Un pilote fournit une interface logicielle au matériel,
permettant au système d'exploitation et aux autres programmes d'accéder aux fonctions matérielles sans avoir besoin de connaître
en détail le périphérique à utiliser.</p>
<p>Le pilote communique avec le périphérique via le bus informatique auquel celui-ci est connecté. Lorsqu'un programme appelant
invoque une routine du pilote, celui-ci va envoyer une commande au périphérique. Une fois que le périphérique renvoie des
données au pilote, le pilote peut invoquer des routines du programme à l'origine de l'appel.</p>
<p>Les pilotes sont dépendant du matériel et spécifiques au système d'exploitation. Il fournissent généralement la gestion des
interruptions à n'importe quelle interface matérielle asynchrone nécessaire.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-des-périphériques-2"><a class="header" href="#gestion-des-périphériques-2">Gestion des périphériques</a></h2>
<h3 id="sysfs"><a class="header" href="#sysfs">Sysfs</a></h3>
<p>Sysfs est un système de fichiers virtuel qui permet d'exporter depuis l'espace noyau vers l'espace utilisateur des informations
sur les périphériques du système et leur pilotes, et est également utilisé pour configurer certaines fonctionnalités du noyau.</p>
<p>Pour chaque objet ajouté à l'arbre des modèles de pilotes (pilotes, périphériques, classe de périphériques), un répertoire est
créé dans sysfs. La relation parent/enfant est représentée sous la forme de sous-répertoires dans <em>/sys/devices/</em> (représentant
la couche physique). Le sous-répertoire <em>/sys/bus/</em> est peuplé de liens symboliques, représentant la manière dont chaque
périphérique appartient aux différents bus. <em>/sys/class/</em> montre les périphérique regroupés en classes, comme les périphériques
réseau par exemple, pendant que <em>/sys/block/</em> contient les périphériques de type bloc.</p>
<p>Pour les périphériques et leurs pilotes, des attributs peuvent être créés. Ce sont de simples fichiers, la seule contrainte est
qu'ils ne peuvent contenir chacun qu'une seule valeur et/ou n'autoriser le renseignement que d'une valeur (au contraire de
certains fichiers de procfs, qui nécessitent d'être longuement parcourus). Ces fichiers sont placés dans le sous-répertoire du
pilote correspondant au périphérique. L'utilisation de groupes d'attributs est possible en créant un sous-répertoire peuplé
d'attributs.</p>
<p>Sysfs est utilisé par quelques utilitaires pour accéder aux informations concernant le matériel et ses pilotes (des modules du
noyau comme udev par exemple). Des scripts ont été écrits pour accéder aux informations obtenues précédemment via procfs, et
certains scripts permettent la configuration du matériel et de leur pilote via leurs attributs.</p>
<p>Sysfs s'appuie sur ramfs. Un système de fichiers temporaire très simple monté en RAM.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-des-périphériques-3"><a class="header" href="#gestion-des-périphériques-3">Gestion des périphériques</a></h2>
<h3 id="udev"><a class="header" href="#udev">Udev</a></h3>
<p>Udev est un gestionnaire de périphérique pour le noyau Linux. Udev gère principalement des noeuds périphériques dans le
répertoire <em>/dev/</em>. Udev traite également tous les événements dans l'espace utilisateurs lors de l'ajout ou de la suppression
d'un périphérique, ainsi que du chargement des microgiciels.</p>
<p>Les pilotes font parti du noyau Linux, dans le sens où leurs fonctions principales incluent la découverte de périphérique, la
détection des changements d'états, et autres fonctions matérielles similaires de bas niveau. Après chargement du pilote de
périphérique en mémoire depuis le noyau, les événements détectés sont envoyés au daemon de l'espace utilisateur <em>udevd</em>. C'est
le gestionnaire de périphérique, <em>udevd</em>, qui récupère tout ces événements et qui ensuite décide de la suite à donner. A cette
fin, <em>udevd</em> dispose d'un ensemble de fichiers de configurations, pouvant être ajustés par l'administrateur suivant ses besoins.</p>
<ul>
<li>Dans le cas d'un nouvel appareil de stockage USB, <em>udevd</em> est notifié par le noyau qui lui-même notifie le udisksd-daemon. Ce
daemon pourra alors monter le système de fichiers.</li>
<li>Dans le cas d'une nouvelle connexion de câble Ethernet à la carte d'interface réseau Ethernet (NIC), <em>udevd</em> est notifié par
le noyau qui lui-même notifie le NetworkManager-daemon. Le NetworkManager-daemon pourra alors démarrer le daemon client dhcp
pour cette NIC, ou bien configurer la connexion à l'aide d'une configuration manuelle quelconque.</li>
</ul>
<p>Contrairement aux systèmes traditionnels UNIX, ou les noeuds périphériques contenus dans le répertoire <em>/dev</em> était un ensemble
de fichiers statique, le gestionnaire de périphérique Linux udev fournit dynamiquement, uniquement les noeuds des périphériques
actuellement disponibles au système :</p>
<ul>
<li>udev fournit un nommage de périphérique persistant, qui ne dépend pas de, par exemple, l'ordre de connexion des appareils au
système.</li>
<li>udev s'exécute entièrement en espace utilisateur. Une conséquence est que udev peut exécuter des programmes arbitraires pour
composer un nom pour le périphérique fonction de ses propriétés, avant que le noeud soit créé; d'ailleurs, l'ensemble du
processus de nommage est également interruptible et s'exécute avec une priorité basse.</li>
</ul>
<p>Udev est divisé en trois parties :</p>
<ul>
<li>La bibliothèque <em>libudev</em> qui permet l'accès aux informations des périphériques; qui est maintenant inclue dans <em>systemd</em>.</li>
<li>Le daemon de l'espace utilisateur <em>udevd</em> qui gère <em>/dev</em> virtuel.</li>
<li>L'utilitaire d'administration en ligne de commande <em>udevadm</em> pour des diagnostics.</li>
</ul>
<p>Le système reçoit des appels depuis le noyau via des sockets Netlink.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-des-périphériques-4"><a class="header" href="#gestion-des-périphériques-4">Gestion des périphériques</a></h2>
<h3 id="bus"><a class="header" href="#bus">Bus</a></h3>
<p>Un bus est un système de communication qui permet de transférer des données entre les composants d'un ordinateur ou entre
ordinateurs. Cette expression couvre tous les composants matériels (fils, fibre optique, etc.) et logiciels, protocoles de
communications inclus. Les bus informatiques modernes peuvent à la fois utiliser des connexions parallèles et séries avec hubs.
C'est par exemple le cas de l'USB.</p>
<p>Un bus d'adresses est un bus utilisé pour spécifier une adresse physique. Quand un processeur ou un périphérique bénéficiant
d'un accès direct à la mémoire (<em>DMA-enabled</em>) a besoin de lire ou d'écrire en mémoire, il spécifie en emplacement mémoire sur
le bus d'adresses (la valeur à lire ou à écrire est alors envoyé sur le bus de données). La largeur du bus d'adresse détermine
la quantité de mémoire qu'un système peut adresser.</p>
<p>Accéder un octet individuel requiert généralement d'écrire ou de lire une largeur de bus complète (un mot) à la fois. Dans ce
cas, les bits les moins signifiants du bus d'adresses peuvent même ne pas être implémentés - il revient en effet au contrôleur
d'isoler l'octet individuel demandé du mot complet transmis.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="gestion-des-périphériques-5"><a class="header" href="#gestion-des-périphériques-5">Gestion des périphériques</a></h2>
<h3 id="accès-direct-à-la-mémoire"><a class="header" href="#accès-direct-à-la-mémoire">Accès direct à la mémoire</a></h3>
<p>L'accès direct à la mémoire (<em>DMA</em>) est un procédé informatique où les données circulant de, ou vers un périphérique sont
transférées directement par un contrôleur adapté vers la mémoire principale, sans intervention du microprocesseur si ce n'est
pour lancer et conclure le transfert. La conclusion du transfert ou la disponibilité du périphérique peuvent être signalés par
interruption.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage"><a class="header" href="#Éléments-de-démarrage">Éléments de démarrage</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-1"><a class="header" href="#Éléments-de-démarrage-1">Éléments de démarrage</a></h2>
<h3 id="bios"><a class="header" href="#bios">BIOS</a></h3>
<p>Le <strong>BIOS</strong> est un microgiciel utilisé pour l'initialisation du matériel pendant le processus de démarrage, et pour fournir des
services à l'exécution pour les systèmes d'exploitation et les programmes. Le microgiciel BIOS est préinstallé sur la carte
mère, c'est le premier logiciel à s'exécuter lors de la mise sous tension.</p>
<p>Le BIOS dans les PCs modernes initialise et teste les composants matériels du système, et charge un chargeur d'amorçage depuis
l'appareil de stockage de masse qui initialise un système d'exploitation.</p>
<p>La plupart des implémentations du BIOS sont spécifiques à un modèle de carte mère, en s'interfaçant avec différents appareil et
en particulier le chipset. Anciennement, le microgiciel BIOS était stocké sur une puce ROM de la carte mère. De nos jours, le
contenu du BIOS est stocké sur de la mémoire flash de façon à pouvoir être réécrite sans enlever la puce de la carte mère. Ceci
permet une mise à jour aisée du BIOS, mais également l'infection de l'ordinateur via des rootkits du BIOS. De plus, si une mise
à jour du BIOS échoue cela peut potentiellement rendre la carte mère inutilisable.</p>
<p>L'interface microgicielle extensible unifiée (UEFI) est un successeur du BIOS, il vise à résoudre ses limitations techniques.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-2"><a class="header" href="#Éléments-de-démarrage-2">Éléments de démarrage</a></h2>
<h3 id="uefi"><a class="header" href="#uefi">UEFI</a></h3>
<p><strong>L'interface microgicielle extensible unifiée (UEFI)</strong> est une spécification qui définit une interface logicielle entre un
système d'exploitation et une plateforme microgicielle. UEFI remplace l'ancienne interface microgicielle BIOS dont elle reprend
généralement l'ensemble des services. L'UEFI peut supporter les diagnostics et réparations distants, même sans système
d'exploitation.</p>
<p>L'interface défini par la spécification EFI inclut des tables de données qui contiennent des informations de plateforme, ainsi
que des services de démarrage et d'exécution disponible au chargeur d'amorçage et au système d'exploitation. Le microgiciel
UEFI fournit un certain nombre d'avantages techniques par rapport à un système BIOS traditionnel :</p>
<ul>
<li>La possibilité de démarrer un disque contenant de grandes partitions (plus de 2TB) à l'aide d'une table de partition GUID
(GPT)</li>
<li>Un environnement pre-SE flexible, incluant des capacités réseaux, une interface graphique utilisateur, le multi-langage</li>
<li>Un environnement pre-SE 32 ou 64 bits.</li>
<li>Une programmation en langage C</li>
<li>Une architecture modulaire</li>
<li>Une compatibilité</li>
</ul>
<p>Contrairement au BIOS, UEFI ne s'appuie pas sur des secteurs de démarrage, il définit un gestionnaire de démarrage comme faisant
parti des spécifications UEFI. Quand l'ordinateur est allumé, le gestionnaire de démarrage vérifie la configuration de démarrage
et en fonction de ses paramètres, exécute ensuite le chargeur d'amorçage spécifié ou noyau de système d'exploitation
(généralement chargeur d'amorçage). La configuration de démarrage est définie par des variables stockées en NVRAM, incluant des
variables qui indiquent les chemins du système de fichier vers les chargeurs d'amorçages ou noyaux.</p>
<p>Les chargeurs d'amorçage peuvent également être détectés automatiquement par UEFI grâce à des chemins standardisés contenant des
fichiers au format <em>.efi</em>.</p>
<p>La spécification UEFI spécifie que les exécutables portables (PE) de Microsoft sont le format d'exécutable standard dans les
environnements EFI.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-3"><a class="header" href="#Éléments-de-démarrage-3">Éléments de démarrage</a></h2>
<h3 id="partitionnement-de-la-mémoire"><a class="header" href="#partitionnement-de-la-mémoire">Partitionnement de la mémoire</a></h3>
<p>Le partitionnement de la mémoire est la création d'une ou plusieurs régions dans la mémoire secondaire, telle que chaque région
puisse être gérée séparément. Ces régions sont appelées partitions. C'est généralement la première chose à faire sur un nouveau
disque installé, avant qu'un système de fichier soit créé. Le disque stocke l'information sur le positionnement et la taille des
partitions dans une aire appelée table de partition que le système d'exploitation lit avant toute autre région du disque. Chaque
partition apparait alors comme un disque &quot;logique&quot; du point de vue du système d'exploitation qui fait usage d'une partie du
disque réel. Les administrateurs systèmes utilisent alors un programme appelé éditeur de partitions pour créer, retailler,
supprimer et manipuler les partitions. Le partitionnement permet l'usage de différents systèmes de fichiers afin de stocker tout
types de fichiers. Séparer les données utilisateur des données système permet d'empêcher que la partition système soit pleine ce
qui rendrait le système inutilisable. Le partitionnement permet aussi de simplifier la sauvegarde. Un désavantage du
partitionnement est qu'il peut être difficile d'allouer la taille adéquate à chacune des partitions, ce qui peut avoir pour
conséquence de laisser une partition avec énormément d'espace libre et une autre totalement saturée.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-4"><a class="header" href="#Éléments-de-démarrage-4">Éléments de démarrage</a></h2>
<h3 id="mbr"><a class="header" href="#mbr">MBR</a></h3>
<p>Un <strong>enregistrement de démarrage maître (MBR)</strong> est type spécial de secteur de démarrage situé au commencement d'un périphérique
de stockage informatique partitionné tel qu'un disque dur.</p>
<p>Le MBR contient l'information du comment les partitions logiques, contenant le système de fichiers, sont organisées sur ce
périphérique. Le MBR contient également du code exécutable pour fonctionner comme chargeur pour un système d'exploitation
installé généralement en laissant la main au second étage du chargeur, ou en conjonction avec chacun des enregistrements de
démarrage de volume (VBR). Ce code MBR est généralement désigné comme un chargeur d'amorçage.</p>
<p>L'organisation de la table de partition au niveau du MBR limite le maximum d'espace de stockage adressable d'un disque
partitionné à 2To. Par conséquent, le schema de partitionnement MBR est progressivement remplacé par le schema de table de
partitionnement GUID (GPT).</p>
<p>Le MBR consiste généralement à 512 octets situés sur le premier secteur du disque.</p>
<p>Il peut contenir un(e) ou plusieurs :</p>
<ul>
<li>Table de partition décrivant les partitions sur un périphérique de stockage. Dans ce contexte, le secteur de démarrage peut
également être appelé secteur de partitionnement.</li>
<li>Code de bootstrap : Instructions permettant d'identifier la partition de démarrage configurée, puis charge et exécute son
volume d'enregistrement de démarrage (VBR) en tant que chargeur chaîné.</li>
<li>Horodatage disque 32-bits optionnel</li>
<li>Signature disque 32-bits optionnel</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-5"><a class="header" href="#Éléments-de-démarrage-5">Éléments de démarrage</a></h2>
<h3 id="gpt"><a class="header" href="#gpt">GPT</a></h3>
<p>La <strong>table de partition GUID (GPT)</strong> est un standard pour la disposition de tables de partitions sur un appareil de stockage
informatique, tels que les disques durs ou les SSDs, en utilisant des identifiants uniques universels, aussi connus en tant
qu'identifiants uniques globaux (GUIDs). Ce standard fait parti des standards d'interface microgicielle extensible unifiée
(UEFI), il peut néanmoins être utilisé pour des systèmes BIOS, du fait des limitations des tables de partitions MBR.</p>
<p>Tous les systèmes d'exploitation récents supportent GPT.</p>
<p>De la même façon que MBR, GPT utilise un adressage de blocs logique (LBA) à la place de l'adressage historique
cylindre-tête-secteur (CHS). Le MBR est stocké au niveau de LBA 0, l'entête GPT à LBA 1. L'entête GPT contient un pointeur vers
la table de partition (typiquement situé à LBA 2). Chaque entrée dans la table de partition a une taille de 128 octets. Les
spécifications UEFI stipulent qu'un minimum de 16 384 octets, soit attribué à la table de partition. Ainsi, sur un disque avec
des secteurs de 512 octets, au moins 32 secteurs sont utilisés pour la table de partition, et le premier bloc utilisable est le
LBA 34 ou supérieur.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-6"><a class="header" href="#Éléments-de-démarrage-6">Éléments de démarrage</a></h2>
<h3 id="lvm"><a class="header" href="#lvm">LVM</a></h3>
<p>La gestion de volumes logiques (LVM) utilise la fonctionnalité du composant <em>device-mapper</em> du noyau linux pour fournir un
système de partitions indépendant de l'arrangement des disques sous-jacents. Avec LVM on obtient des <strong>partitions virtuelles</strong>.
Cette abstraction facilite la gestion des volumes de stockage (potentiellement toujours sujette aux limitations du système de
fichier).</p>
<p>Ces partitions virtuelles permettent l'ajout et la suppression sans avoir à ce soucier si l'espace contigu est suffisant sur un
disque en particulier, sans se faire avoir en essayant de formater un disque en cours d'utilisation (et se demander si le noyau
utilise l'ancienne ou la nouvelle table de partition), ou , avoir à déplacer des partitions pour en agrandir une. </p>
<p>Les composants basiques de LVM sont les :</p>
<ul>
<li><strong>Volumes physiques (PV)</strong> : Un noeud de périphérique de bloc Unix, utilisable pour du stockage par LVM. Il accueille une
entête LVM.</li>
<li><strong>Groupes de volumes (VG)</strong> : Groupe de volumes physiques (PVs) qui sert de contenant aux volumes logiques (LVs). Les
extensions physiques (PEs) sont allouées depuis un groupe de volume (VG) pour un volume logique (LV).</li>
<li><strong>Volumes Logiques (LV)</strong> : &quot;Partition virtuelle/logique&quot; résidant dans un groupe de volume (VG) et composé d'extensions
physiques (PEs). Les Volumes logiques (LVs) sont des périphériques de blocs Unix analogues à des partitions physiques, c'est à
dire qu'elles peuvent être directement formatées à l'aide d'un système de fichier.</li>
<li><strong>Extentions physiques (PE)</strong> : La plus petite extension contigüe (par défaut 4MiB) dans le volume physique (PV) qui peut être
assigné à un volume logique (LV).</li>
</ul>
<p>LVM permet une plus grande flexibilité comparé à l'utilisation d'une partition de disque dur classique :</p>
<ul>
<li>Utiliser plusieurs disques comme un seul gros disque.</li>
<li>Avoir des volumes logiques étendus sur plusieurs disques.</li>
<li>Créer de petits volumes logiques et les retailler &quot;dynamiquement&quot; quand ils se remplissent.</li>
<li>Redimensionner des volumes logiques quelque soit leur ordre sur le disque.</li>
<li>Capturer une sauvegarde d'une copie gelée du système de fichier, en gardant une forte disponibilité.</li>
<li>Supporter différentes cibles de <em>device-mapper</em>, incluant le chiffrement de systèmes de fichier transparent et la mise en
cache de données fréquemment utilisées. Ceci permet de créer un système avec un ou plusieurs disques physiques (chiffrés avec
LUKS) et LVM par dessus pour permettre de redimensionner et de gérer les volumes séparés sans avoir à entrer une clef de
nombreuses fois au démarrage.</li>
</ul>
<p>Les désavantages étant :</p>
<ul>
<li>Des étapes supplémentaire lors de l'installation du système. Nécessite l'exécution d'un certain nombre de daemons.</li>
<li>Le dual booting avec des SE ne supportant pas LVM (Windows).</li>
<li>Dans le cas de volumes physique qui ne sont pas en RAID-1, RAID-5 ou RAID-6 perdre un disque peut signifier perdre un ou
plusieurs volumes logiques si on étale (ou étend) des volumes logiques sur un ensemble de disques non redondants.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-7"><a class="header" href="#Éléments-de-démarrage-7">Éléments de démarrage</a></h2>
<h3 id="raid"><a class="header" href="#raid">RAID</a></h3>
<p>RAID est une technologie de stockage qui combine plusieurs composants de disques durs (typiquement des disques durs ou leurs
partitions) en une unité logique. Selon l'implémentation du RAID, cette unité logique peut être un système de fichier ou une
couche transparente additionnelle qui détient plusieurs partitions. Les données sont distribuées sur les disques d'une ou
plusieurs manières appelés niveaux de RAID. Le niveau de RAID choisit peut ainsi empêcher des pertes de données dans le cas
d'une perte de disque dur, améliorer la performance ou une combinaison des deux.</p>
<p>Il existe de nombreux niveaux de RAID différents ; ceux listés ci-dessous sont les plus communs :</p>
<ul>
<li><strong>RAID 0</strong> : Entrelacement de disques. Augmente la vitesse de lecture et d'écriture sans redondance.</li>
<li><strong>RAID 1</strong> : Disques en miroir.</li>
<li><strong>RAID 5</strong> : Nécessite au minimum 3 disques et combine la redondance du RAID 1 et les bénéfices de vitesse du RAID 0.</li>
<li><strong>RAID 6</strong> : Nécessite au minimum 4 disques fournit les bénéfices du RAID 5 mais avec la sécurité contre la perte de deux
disques.</li>
<li><strong>RAID 1+0</strong> : RAID imbriqué qui combine deux niveaux standards du RAID pour gagner en performance et redondance
additionnelle.</li>
</ul>
<p>Les périphériques de RAID peuvent être gérés de plusieurs façons :</p>
<ul>
<li><strong>RAID Logiciel</strong> : La grappe est gérée par le système d'exploitation soit par :
<ul>
<li>Une couche d'abstraction (mdadm);</li>
<li>Un gestionnaire de volume logique (LVM);</li>
<li>Un composant du système de fichier (ZFS, Btrfs);</li>
</ul>
</li>
<li><strong>RAID Matériel</strong> : La grappe est directement gérée par une carte matérielle dédiée installée dans le PC auxquels les disques
sont directement connectés. La logique RAID s'exécute sur un processeur embarqué indépendamment du processeur hôte (CPU). Bien
que cette solution soit indépendante du système d'exploitation, cette dernière nécessite un pilote pour fonctionner correctement
avec le contrôleur de RAID matériel. La grappe de RAID peut soit être configurée via une interface microgicielle ou, selon le
fabricant, à l'aide d'application dédiées après installation du système d'exploitation. La configuration est transparente pour
le noyau Linux : il ne voit pas les disques séparément.</li>
<li><strong>FakeRAID</strong> : Ce type de raid est correctement appelé RAID microgiciel. La grappe est gérée par un pseudo contrôleur RAID où
la logique RAID est implémentée dans une partie microgicielle , mais sans toutes les capacité des contrôleurs RAID matériels.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-8"><a class="header" href="#Éléments-de-démarrage-8">Éléments de démarrage</a></h2>
<h3 id="dm-crypt"><a class="header" href="#dm-crypt">Dm-crypt</a></h3>
<p>Dm-crypt est la cible cryptographique du <em>device-mapper</em>. Il s'agit d'un sous-système de chiffrement de disque transparent du
noyau Linux. Il est implémenté en tant que cible du <em>device-mapper</em> et peut être emplilé sur d'autres transformations de
celui-ci. Il peut ainsi chiffrer des disques, des partitions, des volumes logiciels de RAID, des volumes logiques, ainsi que des
fichiers. Il apparaît comme un périphérique de bloc, qui peut être utilisé pour supporter des systèmes de fichiers, du swap ou
un volume physique LVM.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-9"><a class="header" href="#Éléments-de-démarrage-9">Éléments de démarrage</a></h2>
<h3 id="luks"><a class="header" href="#luks">LUKS</a></h3>
<p>LUKS est une spécification de chiffrement de disque. LUKS implémente un format sur disque standard indépendant pour
l'utilisation de divers outils. Cela permet une compatibilité et une interopérabilité parmi différents programmes, mais
assure également qu'ils implémentent une gestion des mots de passe sécurisée et documentée.</p>
<p>LUKS utilise dm-crypt comme backend pour le chiffrement de disque.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-10"><a class="header" href="#Éléments-de-démarrage-10">Éléments de démarrage</a></h2>
<h3 id="chargeur-damorçage"><a class="header" href="#chargeur-damorçage">Chargeur d'amorçage</a></h3>
<p>Un chargeur d'amorçage est un logiciel démarré par le microgiciel (BIOS ou UEFI). Il est responsable du chargement du noyau avec
les paramètres recommandés et du disque RAM initial (initrd) selon  des fichiers de configuration. Dans le cas de l'UEFI, le
noyau lui-même peut directement être lancé par l'EFI boot stub qui permet au microgiciel EFI un chargement du noyau en tant
qu'exécutable EFI. Un chargeur d'amorçage séparé ou gestionnaire de démarrage peut toujours être utilisé afin d'éditer les
paramètres du noyau avant le démarrage.</p>
<p>Un chargeur d'amorçage doit pouvoir accéder au images du noyau et de l'initramfs, autrement le système ne pourra pas démarrer.
Par conséquent, il doit typiquement pouvoir accéder à <strong>/boot</strong>. C'est à dire, qu'il doit pouvoir supporter un ensemble allant
des périphériques de blocs, aux périphériques de blocs empilés (LVM, RAID, dm-crypt; LUKS, etc.) jusqu'au système de fichier sur
lequel réside les images du(des) noyau(x) et de(des) initramfs.</p>
<p>Le chargement du disque RAM initial peut également inclure un microcode processeur du fabricant qui fournit des mises à jours de
sécurité et de stabilité.</p>
<p>Les mises à jour du microcode sont généralement incluses dans le microgiciel de la carte mère et appliquées durant
l'initialisation du microgiciel. Du fait que les fabricants des équipements d'origine ne mettaient pas forcément à jour leur
microgiciel de manière régulière et que les vieux système ne bénéficiaient d'aucune mise à jour, la possibilité d'appliquer ses
mises à jour du microcode processeur a été ajouté au moment du démarrage pour le noyau Linux.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-11"><a class="header" href="#Éléments-de-démarrage-11">Éléments de démarrage</a></h2>
<h3 id="initramfs"><a class="header" href="#initramfs">Initramfs</a></h3>
<p>Une fois que le chargeur d'amorçage a chargé le noyau et les possibles fichiers initramfs et exécute le noyau, le noyau extrait
l'initramfs (système de fichier RAM initial) dans le rootfs (système de fichier racine initial, spécifiquement un ramfs ou
tmpfs) qui était vide jusqu'alors. La premier initramfs extrait a été inclus dans le binaire du noyau lors de la construction de
celui-ci, ensuite de possibles fichiers initramfs externes sont extraits. Par conséquent les initramfs externes surchargent des
fichiers portant le même nom dans l'initramfs inclus. Le noyau execute alors <strong>init</strong> (dans le rootfs) en tant que premier
processus. Les prémisses de l'espace utilisateur démarrent.</p>
<p>Les images externes initramfs peuvent être générées à l'aide de <strong>mkinitcpio</strong>, <strong>dracut</strong> ou <strong>booster</strong>.</p>
<p>Le but de l'initramfs est d'amener le système jusqu'au point où il accède au système de fichier racine. Cela signifie que tout
module requis pour des périphériques tels qu'IDE, SCSI, SATA, USB/FW (si démarrage depuis un disque externe) doit pouvoir être
chargé depuis l'initramfs si il n'est pas inclus dans le noyau ; une fois que les modules sont chargés (soit explicitement via
un programme ou un script, ou implicitement via udev), le processus de démarrage continue. Pour cette raison, l'initramfs a
uniquement besoin des modules nécessaires à l'accès au système de fichier racine. La majorité des modules sera chargé à
postériori par udev, durant le processus d'init (systemd).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-12"><a class="header" href="#Éléments-de-démarrage-12">Éléments de démarrage</a></h2>
<h3 id="noyau"><a class="header" href="#noyau">Noyau</a></h3>
<p>Le noyau est un programme informatique au cœur d'un système d'exploitation informatique et a un contrôle complet sur l'ensemble
du système. Il s'agit de la partie du code du système d'exploitation qui réside en permanence en mémoire, et facilite les
interactions entre composants matériels et logiciels. Un noyau complet contrôle l'ensemble des ressources matérielles (ex. E/S,
mémoire, cryptographie) via des pilotes, arbitre les conflit entre processus a propos de ces ressources, et optimise
l'utilisation des ressources communes ex. CPU &amp; utilisation des caches, systèmes de fichiers, et sockets réseaux. Sur la
majorité des systèmes, le noyau est le premier programme chargé au démarrage (après le chargeur d'amorçage). Il gère le reste du
processus de démarrage ainsi que la mémoire, les périphériques, les requêtes d'entrées/sorties (E/S) du logiciel, en les
traduisant en instructions de traitements de données pour le processeur.</p>
<p>Le code critique du noyau est généralement chargé dans une aire de la mémoire séparée, qui est protégée des accès via les
applications logicielles ou d'autres parties moins critiques d'un système d'exploitation. Le noyau effectue des tâches telles
que, l'exécution de processus, la gestions de périphériques matériels tels que le disque dur, et la gestion des interruptions,
dans l'espace noyau protégé. Par contraste, des programmes applicatifs tels que des navigateurs, des traitements de texte, ou
des lecteurs audio ou vidéo utilisent une aire séparée de la mémoire, l'espace utilisateur. Cette séparation empêche les données
utilisateurs et les données noyau d'interférer l'une avec l'autre causant instabilité et lenteurs, empêchant également des
applications défectueuses d'affecter d'autres applications ou même le système d'exploitation dans son ensemble.</p>
<p>L'interface noyau est une couche d'abstraction de bas niveau. Quand un processus demande un service au noyau, il doit invoquer
un appel système, généralement à travers une fonction englobante.</p>
<p>Il existe différentes architectures de noyau. Les noyaux monolithiques s'exécutent entièrement dans un espace d'adressage unique
avec le processeur en mode supervision, principalement pour des questions de rapidité. Les micro-noyaux exécutent la plupart de
leurs services dans l'espace utilisateur, de la même manière que les processus utilisateurs, principalement pour des
considérations de résilience et de modularité. Le noyau Linux est monolithique, bien qu'également modulaire, puisqu'il peut
insérer et supprimer des module noyaux chargeable à l'exécution.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-13"><a class="header" href="#Éléments-de-démarrage-13">Éléments de démarrage</a></h2>
<h3 id="talon-de-démarrage-uefi-et-image-noyau-unifiée"><a class="header" href="#talon-de-démarrage-uefi-et-image-noyau-unifiée">Talon de démarrage UEFI et Image noyau unifiée</a></h3>
<p>Une image noyau unifiée (UKI) est un exécutable unique qui peut être démarré directement depuis le microgiciel UEFI, ou sourcé
automatiquement par les chargeurs d'amorçage avec une configuration légère voire inexistante.</p>
<p>Une image unifiée permet d'inclure :</p>
<ul>
<li>un talon de démarrage UEFI tel que <em>systemd-stub</em>,</li>
<li>une image noyau,</li>
<li>une image initramfs,</li>
<li>l'interface ligne de commande du noyau,</li>
<li>optionnellement, un écran de démarrage.</li>
</ul>
<p>Grâce au talon, l'exécutable résultant, et par conséquent tous ses éléments, peuvent être facilement signés afin d'utiliser la
fonctionnalité de démarrage sécurisé UEFI (Secure Boot).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-14"><a class="header" href="#Éléments-de-démarrage-14">Éléments de démarrage</a></h2>
<h3 id="cgroups"><a class="header" href="#cgroups">Cgroups</a></h3>
<p>Les cgroups sont une fonctionnalité du noyau Linux qui limite, compte et isole l'utilisation des ressources (CPU, mémoire,
entrée/sortie, réseau, etc.) d'une collection de processus.</p>
<p>Ces groupes de contrôle peuvent être utilisés de multiples façons :</p>
<ul>
<li>En accédant le système de fichier virtuel du cgroup manuellement.</li>
<li>En créant et gérant des groupes à la volée en utilisant des outils tels que <em>cgcreate</em>, <em>cgexec</em> et <em>cgclassify</em>
(<em>libcgroup</em>).</li>
<li>A travers le &quot;daemon moteur de règles&quot; qui peut déplacer les processus de certains utilisateurs, groupes de manière
automatique ou commander aux cgroups comme cela a été spécifié dans sa configuration.</li>
<li>Indirectement à travers d'autres logiciels utilisant les cgroups, tels que Docker, LXC, libvirt, systemd, etc.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-15"><a class="header" href="#Éléments-de-démarrage-15">Éléments de démarrage</a></h2>
<h3 id="espaces-de-noms"><a class="header" href="#espaces-de-noms">Espaces de noms</a></h3>
<p>Un espace de noms encapsule dans une abstraction une ressource système globale qui la fait apparaître aux processus contenus
dans l'espace de noms qui ont leur propre instance isolée de la ressource globale. Les changements de la ressource globale sont
visibles aux autres processus membre de l'espace de noms, mais invisible aux autres processus. Les espaces de noms sont utilisés
pour implémenter les conteneurs.</p>
<p>Les types d'espace de noms disponibles dans Linux sont les suivants : Cgroup, IPC, Network, mount, PID, Time, User, UTS.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-16"><a class="header" href="#Éléments-de-démarrage-16">Éléments de démarrage</a></h2>
<h3 id="systemd"><a class="header" href="#systemd">Systemd</a></h3>
<p>Systemd est un système et un gestionnaire de service pour les systèmes d'exploitation Linux. Lorsqu'il est exécuté en tant que
premier processus au démarrage, il agit comme le système init et met en place et gère les services de l'espace utilisateur. Des
instances séparées sont démarrées pour les utilisateurs connectés afin de démarrer leurs services.</p>
<p>D'habitude, systemd n'est pas invoqué directement par l'utilisateur, mais est installé comme le lien symbolique <em>/sbin/init</em> et
lancé au début du démarrage.</p>
<p>Lorsqu'il est exécuté en tant qu'instance système, systemd interprète le fichier de configuration <em>system.conf</em> et les fichiers
présents dans les répertoires de <em>system.conf.d</em> ; lorsque lancé en tant qu'instance utilisateur, systemd interprète le fichier
de configuration <em>user.conf</em> et les fichiers dans les répertoires <em>user.conf.d</em></p>
<p>Systemd fournit un système de dépendances entre des entités variées appelées &quot;unités&quot; de 11 types différents. Les unités
encapsulent des objets utiles pour le démarrage et la gestion du système. La grande majorité des unités sont configurées dans
des fichiers de configuration d'unité, néanmoins certaines peuvent être créées automatiquement depuis d'autres configurations,
dynamiquement d'un état système ou de façon programmée à l'exécution. Une unité peut être &quot;active&quot; (i.e. démarrée, liée,
connectée, etc. selon le type d'unité), ou &quot;inactive&quot; (i.e. stoppée, déliée, déconnectée, etc.) ou bien dans le processus
d'activation ou de désactivation, c'est à dire entre les deux états. Un état spécial &quot;échoué&quot; est également disponible, très
similaire à &quot;inactive&quot; il se déclenche lorsque le service a échoué d'une certaine façon (le processus a renvoyé un code
d'erreur, ou a crashé, une opération a time out, ou après un nombre trop important de redémarrages). Si l'état apparaît, la
cause sera tracée pour référence ultérieure. Il est à noté que plusieurs types d'unité peuvent avoir un nombre de sous-états
additionnels, qui sont reliés aux 5 états d'unité généraux décrits ici.</p>
<p>Les unités suivantes sont disponibles :</p>
<ol>
<li>Les unités de <strong>services</strong>, qui démarrent et contrôlent des daemons et les processus qui les composent.</li>
<li>Les unités de <strong>sockets</strong>, qui encapsulent des IPC locaux ou des sockets réseaux du système, utiles pour l'activation basée
sur des sockets.</li>
<li>Les unités de <strong>cibles</strong> utilisées afin de grouper des unités, ou de fournir des points de synchronisation connus au
démarrage.</li>
<li>Les unités de <strong>périphériques</strong> qui expose les périphériques de noyau dans systemd et peuvent être utilisées pour de
l'activation basée sur des périphériques.</li>
<li>Les unités de <strong>montages</strong>, pour contrôler les points de montage dans le système de fichiers.</li>
<li>Les unités de <strong>montages automatiques</strong>, afin d'automatiser les opérations de montage à la demande et le démarrage
parallélisé.</li>
<li>Les unités de <strong>timers</strong> afin de déclencher l'activation d'autres unités sur la base de timers.</li>
<li>Les unités de <strong>swap</strong>, très similaires aux unités de montages qui encapsulent les partitions mémoires dédiées au swap ou des
fichiers du système d'exploitation.</li>
<li>Les unités de <strong>chemins</strong> qui peuvent être utilisées afin d'activer d'autres service lorsque les objets du système de
fichiers changent ou sont modifiés.</li>
<li>Les unités de <strong>tranches</strong> qui sont utilisées afin de grouper des unités qui gèrent des processus systèmes dans un arbre
hiérarchique pour des questions de gestion des ressources.</li>
<li>Les unités de <strong>scope</strong> similaires aux unités de services mais pour gérer et démarrer des processus externes. Ils sont créés
de façon programmée en utilisant les interfaces de bus de systemd.</li>
</ol>
<blockquote>
<p>Units : service, socket, target, device, mount, automount, timer, swap, path, slice, scope</p>
</blockquote>
<p>Systemd chargera implicitement et automatiquement les unités depuis le disque - si celles-ci ne sont pas déjà chargées - dès
qu'elles seront requises par des opérations. Ainsi, le fait qu'une unité est chargée ou non est invisible aux clients. On
utilise `systemctl list-units --all pour lister de manière compréhensive les unités actuellement chargées. N'importe quelle
unité pour laquelle aucune de conditions ci-dessus ne s'applique est rapidement déchargée. Il est à noter que quand une unité
est déchargée de la mémoire courante ses données sont également libérées. Néanmoins les données ne sont généralement pas
perdues, du fait qu'un enregistrement dans le journal de log est généré déclarant les ressources consommées à l'arrêt d'une
unité.</p>
<p>Les processus lancés par systemd sont placés dans des cgroups nommés d'après l'unité à laquelle ils appartiennent dans la
hiérarchie privée de systemd. systemd fait usage de cela afin de garder efficacement la trace des processus. L'information du
Control group est gérée par le noyau, et est accessible dans la hiérarchie du système de fichier (sous /sys/fs/cgroup/systemd/),
ou bien dans des outils tels que systemd-cgls.</p>
<p>Systemd contient un système transactionnel minimal : si une unité doit s'activer ou se désactiver, il l'ajoutera avec toutes ses
dépendances dans une transaction temporaire. Il vérifiera alors si la transaction est cohérente (i.e. si l'ordonnancement de
toutes les unités ne contient pas de boucle). Si ce n'est pas le cas, systemd essaiera de résoudre le problème, et supprimera
les jobs non essentiels de la transaction ce qui pourra faire disparaître la boucle. Systemd essaiera également de supprimer les
jobs non essentiels qui arrêteraient un service déjà actif. Enfin il vérifiera si les jobs de la transaction contredisent des
jobs déjà en attente dans la file et optionnellement annulera la transaction. Si tout a marché et que la transaction est
cohérente et minimale dans son impact, elle est fusionnée avec tous les jobs en attente dans la file d'exécution. Cela signifie
qu'avant l'exécution d'une opération demandée, systemd vérifiera en premier lieu qu'elle ait un sens, essaiera de résoudre si
possible, et échouera uniquement s'il n'est pas possible de la faire fonctionner.</p>
<p>Il est à noter que les transactions sont générées indépendamment de l'état des unités à l'exécution, ce qui a pour conséquence
par exemple que si un job de démarrage est requis sur une unité déjà active, il génèrera quand même une transaction et
réveillera toute dépendance inactive (et causera par propagation la demande d'autres jobs tels que définis par leurs relations).
Ceci du fait que le job enfilé est comparé à l'exécution à l'état de l'unité cible et est marqué comme réussi et complet quand
les deux sont satisfaits. Cependant ce job ressort également les autres dépendances du fait de la relation définie et mène donc,
dans notre exemple, à l'enfilage des jobs de démarrage de toutes ces unités inactives.</p>
<p>Systemd contient des implémentation natives de tâches diverses faisant parti du processus de démarrage et ayant besoins d'être
exécutées. Par exemple, il fixe le nom de l'hôte ou configure le périphérique réseau de loopback. Il sert également à mettre en
place et monter plusieurs systèmes de fichiers d'API, tels que /sys/ ou /proc/.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-démarrage-17"><a class="header" href="#Éléments-de-démarrage-17">Éléments de démarrage</a></h2>
<h3 id="shell"><a class="header" href="#shell">Shell</a></h3>
<p>Le Shell est un programme qui permet d'interpréter les commandes de l'utilisateur. C'est l'un des tout premiers moyens
d'interagir avec un ordinateur. Le shell est généralement plus puissant qu'une interface graphique utilisateur (GUI), dans le
sens où il permet d'accéder très efficacement aux fonctionnalités internes du système d'exploitation (OS).</p>
<p>Souvent les outils textuels dont il dispose sont construits de manière à pouvoir être composés. Ainsi de multiples assemblages
permettent à la fois une simplicité dans la décomposition des tâches, et une facilité de mise en oeuvre dans l'automatisation.</p>
<p>Les shells peuvent généralement dépendre des OS, sachant qu'il en existe une quantité pour chacun d'entre eux.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité"><a class="header" href="#Éléments-de-sécurité">Éléments de sécurité</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-1"><a class="header" href="#Éléments-de-sécurité-1">Éléments de sécurité</a></h2>
<h3 id="secure-shell"><a class="header" href="#secure-shell">Secure Shell</a></h3>
<p>Secure Shell (SSH) est un protocole réseau cryptographique pour opérer des services réseaux de manière sécurisé à travers un
réseau non sécurisé. Les application typiques incluent la connexion distante en ligne de commande et l'exécution de commandes
distantes, mais n'importe quel service réseau peut être sécurisé via SSH.</p>
<p>Un serveur SSH, écoute par défaut sur le port 22 TCP. Un programme client SSH est généralement utilisé pour établir la connexion
vers un daemon sshd qui accepte les connexions distantes.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-2"><a class="header" href="#Éléments-de-sécurité-2">Éléments de sécurité</a></h2>
<h3 id="openssh"><a class="header" href="#openssh">OpenSSH</a></h3>
<p>OpenSSH (OpenBSD Secure Shell) est un ensemble de programmes informatiques fournissant des sessions de communications chiffrées
à travers un réseau en utilisant le protocole Secure Shell. Il a été créé en tant qu'alternative open source à la suite
logicielle propriétaire Secure Shell offerte par SSH Communications Security.</p>
<p>On utilise généralement la suite d'outils OpenSSH suivante :</p>
<ul>
<li><strong>ssh-keygen</strong> pour générer une paire clef publique/clef privée.</li>
<li><strong>ssh-add</strong> pour ajouter les identités de clefs privées à l'agent d'authentification <em>ssh-agent</em>.</li>
<li><strong>ssh-agent</strong> en tant que service gestionnaire de clefs.</li>
<li><strong>ssh</strong> en tant que client du protocole.</li>
<li><strong>sshd</strong> en tant que serveur du protocole.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-3"><a class="header" href="#Éléments-de-sécurité-3">Éléments de sécurité</a></h2>
<h3 id="netfilter"><a class="header" href="#netfilter">Netfilter</a></h3>
<p>Netfilter est un framework fournit par le noyau Linux et qui permet diverses opérations en lien avec le réseau pouvant être
implémentées sous la forme de gestionnaires configurables. Netfilter offre plusieurs fonctions et opérations pour le filtrage
des paquets, la traduction d'adresses et de ports réseaux, ce qui fournit la fonctionnalité requise pour diriger les paquets à
travers le réseau et d'interdire à certains l'accès aux lieux sensibles d'un réseau.</p>
<p>Netfilter présente un ensemble de hooks à l'intérieur du noyau Linux, permettant à des modules du noyau spécifiques
d'enregistrer des fonctions de rappel avec la pile réseau du noyau. Ces fonctions s'appliquent généralement au traffic sous
forme de règles de modification et de filtrage qui sont appelées pour chaque paquet qui traverse le hook respectif dans la pile
réseau.</p>
<p>Nftables est un sous-système du noyau Linux et la nouvelle partie de Netfilter qui fournit la classification et le filtrage des
paquets réseaux. Elles sont disponibles depuis le noyau Linux 3.13. Nftables se substitue aux iptables, elles présentent les
avantages d'une moindre réplication du code et d'une plus grande simplicité d'extension pour de nouveaux protocoles. Nftables
est configuré via l'utilitaire d'espace utilisateur <em>nft</em>.</p>
<p>Nftables utilise les blocs de construction de l'infrastructure Netfilter, tels que les hooks existant dans la pile réseau, la
connexion au système de traçage, le composant d'enfilage de l'espace utilisateur, et le sous-système de logs.</p>
<p>Le moteur du noyau nftables ajoute une machine virtuelle simpliste au noyau Linux, capable d'exécuter un bytecode pour inspecter
un paquet réseau et prendre les décisions concernant la gestion de ce paquet. Elle peut obtenir des données de la part du paquet
lui-même, regarder les méta données associées (par exemple l'interface d'entrée), et gérer les données de traçage de
connexions. Les opérateurs de comparaison arithmétiques et bits à bits peuvent être utilisés pour prendre des décisions en
fonction de ces données. La machine virtuelle est aussi capable de réaliser des manipulations sur des ensembles de données
(typiquement des adresses IP), en permettant de remplacer de multiples opérations de comparaisons par un ensemble d'inspections.</p>
<p>Nftables offre une API améliorée côté espace utilisateur qui permet des remplacements atomiques d'une ou plusieurs règles
pare-feu dans une seule transaction Netlink. Ceci accélère les changements de configuration pare-feu pour les installations
ayant de grands ensembles de règles ; cela peut également permettre d'éviter des situations de compétition durant le changement
de règle.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-4"><a class="header" href="#Éléments-de-sécurité-4">Éléments de sécurité</a></h2>
<h3 id="bpf-et-ebpf"><a class="header" href="#bpf-et-ebpf">BPF et eBPF</a></h3>
<p>Le filtre de paquet BSD (BPF) est une architecture de capture de paquets en espace utilisateur. Celle-ci repose sur une machine
virtuelle à registre qui fonctionne dans le noyau et permet d'évaluer les règles de filtrage sans recopies des paquets. Ce
mécanisme est utilisé par des outils standards comme <em>tcpdump</em> pour sélectionner les paquets à capturer.</p>
<p>Récemment ce mécanisme à évolué vers une version étendue (eBPF) qui est la version moderne d'architecture utilisée : </p>
<ul>
<li>passage de 2 registres 32 bits à 10 registres 64 bits</li>
<li>possibilité d'appeler certaines fonctions du noyau</li>
</ul>
<p>eBPF permet d'exécuter des programmes contrôlés (absence de boucles, pointeurs vérifiés etc.) dans l'espace noyau à l'aide d'un
compilateur JIT qui transforme le programme BPF en code natif.</p>
<p>Les programmes eBPF peuvent être utilisés pour implémenter des fonctionnalités de supervision, de sécurité et de réseautage
hautes performances.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-5"><a class="header" href="#Éléments-de-sécurité-5">Éléments de sécurité</a></h2>
<h3 id="ids"><a class="header" href="#ids">IDS</a></h3>
<p>Un système de détection d'intrusion (IDS) est un appareil ou une application logicielle qui surveille un réseau ou des systèmes
afin de cibler et de détecter des activités malveillantes ou des violations de la politique de sécurité. Chaque activité
d'intrusion ou de violation est généralement rapportée soit à un administrateur ou centralisée dans un système de gestion
d'événement et d'information de sécurité (SIEM). Un système SIEM combine les sorties de sources multiples et utilise des
techniques de filtrage d'alarme afin de distinguer une activité malveillante d'une fausse alarme.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-6"><a class="header" href="#Éléments-de-sécurité-6">Éléments de sécurité</a></h2>
<h3 id="contrôle-daccès-discrétionnaire-et-droits"><a class="header" href="#contrôle-daccès-discrétionnaire-et-droits">Contrôle d'accès discrétionnaire et droits</a></h3>
<p>Le contrôle d'accès discrétionnaire (DAC) est un moyen de limiter l'accès aux objets basés sur l'identité des sujets ou des
groupes auxquels ils appartiennent. Le contrôle est discrétionnaire car un sujet avec une certaine autorisation d'accès est
capable de transmettre cette permission à n'importe quel autre sujet (sauf restriction du contrôle d'accès obligatoire).</p>
<p>Sous linux, les acteurs sont :</p>
<ul>
<li>l'utilisateur propriétaire (<em>user</em>)</li>
<li>le groupe principal de l'utilisateur (<em>group</em>)</li>
<li>les autres (<em>others</em>)</li>
</ul>
<p>Les droits usuels s'organisent ainsi :</p>
<ul>
<li>pour les fichiers :
<ul>
<li>r autorise à lire le contenu du fichier</li>
<li>w autorise à modifier le contenu du fichier</li>
<li>x autorise l'exécution du fichier.</li>
</ul>
</li>
<li>pour les répertoires :
<ul>
<li>r autorise à lister le contenu d'un répertoire</li>
<li>w autorise la création, renommage et suppression de fichier</li>
<li>x autorise à traverser (entrer) dans le répertoire.</li>
</ul>
</li>
</ul>
<p>D'autres droits existent notamment :
- t le sticky bit principalement utilisé sur les répertoires et qui permet d'éviter la suppression du répertoire par
d'autres utilisateurs bien qu'ils puissent avoir des droits en écriture sur le contenu de ce même répertoire.
- s le setuid et setgid qui permettent d'exécuter un fichier avec les mêmes permissions que son propriétaire ou
respectivement son groupe. Setgid permet également de modifier le comportement d'un répertoire en fixant le groupe d'un
fichier à sa création.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-7"><a class="header" href="#Éléments-de-sécurité-7">Éléments de sécurité</a></h2>
<h3 id="listes-de-contrôle-daccès-acl"><a class="header" href="#listes-de-contrôle-daccès-acl">Listes de contrôle d'accès ACL</a></h3>
<p>Les listes de contrôle d'accès sont une extension du contrôle d'accès discrétionnaire et des droits usuels.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-8"><a class="header" href="#Éléments-de-sécurité-8">Éléments de sécurité</a></h2>
<h3 id="selinux"><a class="header" href="#selinux">SELinux</a></h3>
<p>SELinux (<em>Security Enhanced Linux</em>) est un module de sécurité du noyau Linux qui fournit des politiques de sécurité de contrôle
d'accès, dont le contrôle d'accès obligatoire (MAC) en addition au contrôle d'accès discrétionnaire existant (DAC). SELinux
répond fondamentalement aux questions telles que :</p>
<p>&quot;Est-ce que <strong>le sujet</strong> peut faire cette <strong>action</strong> à cet <strong>objet</strong> ?&quot; e.g : &quot;Est-ce qu'un serveur web peut accéder aux
fichiers dans le répertoire home des utilisateurs ?&quot;</p>
<p>Un noyau Linux intégrant SELinux impose des politiques de contrôles d'accès obligatoire qui confinent les programmes
utilisateurs et les services systèmes, ainsi que les accès aux fichiers et aux ressources réseaux. Limiter les privilèges au
minimum requis pour fonctionner réduit ou élimine les capacités de ces programmes et daemons à causer des dommages si ceux-ci
sont compromis ou défaillants (par exemple via des dépassements de tampons ou des mauvaises configurations). Ce mécanisme de
confinement fonctionne indépendamment des mécanismes de contrôle d'accès discrétionnaire traditionnels de Linux. Le concept de
super utilisateur n'existe pas, et ne partage pas les raccourcis bien connus des mécanismes de sécurité traditionnels, tel
qu'une dépendance aux binaires setuid/setgid.</p>
<p>Lorsqu'une application ou un processus, reconnu comme un sujet, effectue une requête d'accès à un objet, tel qu'un fichier,
SELinux vérifie à l'aide d'un cache de vecteur d'accès (AVC), où les permissions des sujets et des objets sont mises en cache.</p>
<p>Si SELinux ne trouve pas matière à trancher à propos de cet accès dans le cache, il envoie une requête au serveur de sécurité.
Le serveur de sécurité vérifie le contexte de sécurité de l'application ou du processus et du fichier. Le contexte de sécurité
est appliqué depuis la base de données de politiques SELinux. La permission est donnée ou refusée.</p>
<p>Si la permission est refusée, un message &quot;avc: denied&quot; sera visible dans <em>/var/log.messages</em>.</p>
<p>Chaque processus et ressource système a une étiquette spéciale de sécurité appelée contexte SELinux. Un contexte SELinux est un
identifiant qui s'abstrait des détails du systèmes et se concentre sur les propriétés de sécurité de l'objet. Cela permet un
référencement des objets cohérent dans la politique SELinux mais supprime également toute ambigüité que l'on peut retrouver avec
d'autres méthodes d'identification ; par exemple, un fichier peut avoir plusieurs noms de chemins valides sur un système qui
utilise des montages liés.</p>
<p>La politique SELinux utilise ces contextes dans une série de règles qui définissent comment un processus peut interagir avec les
autres ainsi que les différentes ressources systèmes. Par défaut, la politique ne permet aucune interaction à moins qu'une règle
explicite en permette l'accès.</p>
<p>Le contexte SELinux contient plusieurs champs : utilisateur, role, type, et niveau de sécurité. L'information du type SELinux
est sans doute la plus importante quand il s'agit de la politique SELinux, du fait que la règle la plus commune de la politique
SELinux qui définit les interactions autorisées entre les processus et les ressources systèmes utilise les types SELinux et non
le contexte en entier. Le type SELinux finit habituellement par <em>_t</em> (e.g. <em>httpd_t</em>).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-9"><a class="header" href="#Éléments-de-sécurité-9">Éléments de sécurité</a></h2>
<h3 id="pam"><a class="header" href="#pam">PAM</a></h3>
<p>Les modules d'authentification attachables Linux (PAM) fournissent un cadriciel pour une authentification de l'utilisateur sur
l'ensemble du système. Cela permet de développer des programmes indépendants du schéma d'authentification. Ces programmes ont
besoin que des &quot;modules d'authentification&quot; leurs soient attachés à l'exécution pour fonctionner. Le module d'authentification
attaché au programme est à la discrétion de l'administrateur système et dépend de l'installation locale.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-10"><a class="header" href="#Éléments-de-sécurité-10">Éléments de sécurité</a></h2>
<h3 id="sudo"><a class="header" href="#sudo">Sudo</a></h3>
<p>Sudo permet à un administrateur système de déléguer une autorité pour permettre certains à utilisateurs -- ou groupes
d'utilisateurs -- de passer des commandes en tant que superutilisateur tout en fournissant une piste d'audit des commandes et de
leurs arguments.</p>
<p>Sudo accorde une élévation de privilège temporaire à une commande unique.</p>
<p>Sudo peut également être utilisée pour exécuter des commandes en tant qu'autres utilisateurs ; de plus, sudo trace toutes les
commandes et les tentatives d'accès échouées dans des logs pour auditions de sécurité.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="Éléments-de-sécurité-11"><a class="header" href="#Éléments-de-sécurité-11">Éléments de sécurité</a></h2>
<h3 id="auditd"><a class="header" href="#auditd">Auditd</a></h3>
<p>Le cadriciel d'audit Linux fournit un profil de protection d'accès contrôlés (CAPP) qui collecte de manière fiable des
informations concernant des évènements pouvant être pertinent (mais pas forcément) pour la sécurité du système.</p>
<p>L'audit Linux permet de sécuriser le système en fournissant les moyens d'analyser ce qui se passe de façon très détaillé.
Néanmoins, il ne fournit pas de sécurité additionnelle en soit et ne protège pas le système de bogues ou de failles. Audit est
en revanche utile pour repérer ce genre de problèmes et ainsi d'aider à prendre les mesures de sécurité additionnelles pour les
prévenir.</p>
<p>Le cadriciel d'audit fonctionne en écoutant les évènements rapportés par le noyau et en les notant dans un fichier de log.</p>
<p>La commande <em>auditctl</em> permet de définir des règles permettant d'auditer les accès et les appels systèmes (ex. <em>chmod</em>). La
recherche et la détection d'anomalies se fait via les commandes <em>ausearch</em> et <em>aureport</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation"><a class="header" href="#virtualisation-et-conteneurisation">Virtualisation et conteneurisation</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation-1"><a class="header" href="#virtualisation-et-conteneurisation-1">Virtualisation et conteneurisation</a></h2>
<h3 id="chroot"><a class="header" href="#chroot">Chroot</a></h3>
<p>Chroot est une opération qui modifie le répertoire racine apparent pour le processus en cours d'exécution et pour ses enfants.
Un programme qui s'exécute dans ce genre d'environnement modifié ne peut pas accéder les fichiers et les commandes en dehors de
cet arbre de répertoire environnemental. Cet environnement modifié s'appelle une <em>prison chroot</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation-2"><a class="header" href="#virtualisation-et-conteneurisation-2">Virtualisation et conteneurisation</a></h2>
<h3 id="systemd-nspawn"><a class="header" href="#systemd-nspawn">Systemd-nspawn</a></h3>
<p>Systemd-nspawn peut être utilisé pour exécuter une commande ou un OS dans un conteneur léger d'espace de noms. Il est plus
puissant que <em>chroot</em> puisqu'il virtualise la hiérarchie du système de fichiers, mais aussi l'arbre des processus, les
différents sous-systèmes IPC ainsi que le nom de l'hôte et du domaine.</p>
<p>Systemd-nspawn limite l'accès en lecture seule à différentes interfaces du noyau dans le conteneur, telles que <strong>/sys</strong>,
<strong>/proc/sys</strong> ou <strong>/sys/fs/selinux</strong>. Les interfaces réseaux et l'horloge système ne peuvent pas être modifiées depuis
l'intérieur du conteneur. Les fichiers spéciaux ou fichiers de périphérique ne peuvent  pas non plus être créés. Le système hôte
ne peut pas être redémarré et des modules du noyau ne peuvent pas être chargés depuis le conteneur.</p>
<p>Les conteneurs ainsi créés peuvent être gérés à l'aide de la commande <em>machinectl</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation-3"><a class="header" href="#virtualisation-et-conteneurisation-3">Virtualisation et conteneurisation</a></h2>
<h3 id="conteneurisation-lxc"><a class="header" href="#conteneurisation-lxc">Conteneurisation LXC</a></h3>
<p>LXC est une méthode de virtualisation au niveau du système d'exploitation permettant d'exécuter plusieurs systèmes isolés Linux
sur un système hôte de contrôle en utilisant un unique noyau Linux.</p>
<p>Le noyau Linux fournit la fonctionnalité des cgroups qui permet une limitation et une priorisation des ressources (CPU, mémoire,
entrées/sorties, réseau, etc.) sans besoin d'aucune machine virtuelle, ainsi que la fonction d'isolation par espace de noms qui
permet l'isolation complète d'une application du point de vue de l'environnement opérant, incluant l'arbre des processus, la
configuration réseau, les identifiants utilisateurs et les systèmes de fichiers montés.</p>
<p>LXC combine les cgroups du noyau et inclut l'isolation des espaces de nom pour fournir un environnement isolé à des
applications.</p>
<p>LXC permet d'exécuter des conteneurs en tant que simple utilisateur sur l'hôte à l'aide des conteneurs dits &quot;non-privilégiés&quot;.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation-4"><a class="header" href="#virtualisation-et-conteneurisation-4">Virtualisation et conteneurisation</a></h2>
<h3 id="conteneurisation-docker"><a class="header" href="#conteneurisation-docker">Conteneurisation Docker</a></h3>
<p>Docker est un ensemble de produits de Plateforme en tant que Service qui utilise la virtualisation au niveau du système
d'exploitation pour livrer des logiciels dans des paquets appelé conteneurs. Les conteneurs sont isolés les uns des autres et
embarquent leurs propres logiciels, bibliothèques et fichiers de configuration ; ils peuvent communiquer entre eux à travers des
canaux bien définis. Tous les conteneurs sont exécuté par un noyau de système d'exploitation unique et par conséquent utilisent
moins de ressources que des machines virtuelles.</p>
<p>Docker peut empaqueter une application et ses dépendances dans un conteneur virtuel qui peut s'exécuter sur n'importe quel
ordinateur Linux, Windows, ou macOS. Ceci permet à l'application de s'exécuter dans toute une variété d'environnement, par
exemple, sur sa propre machine, dans un cloud public ou privé. Quand il s'exécute sur Linux, Docker utilise les mécanismes
d'isolation fournis par le noyau (tels que les cgroups et les espaces de noms) et les systèmes de fichiers capables de montage
en union, pour permettre aux conteneurs de s'exécuter sur une instance Linux unique, évitant la surcharge du démarrage et de la
maintenance de machines virtuelles.</p>
<p>Le support des espaces de nom du noyau Linux permet d'isoler l'environnement système de la vue de l'application comme l'arbre
des processus, le réseau, les identifiants utilisateurs et les systèmes de fichiers montés, tandis que les cgroups fournissent
la limitation de ressources mémoire et CPU. Docker inclut également sa propre bibliothèque <em>libcontainer</em> permettant d'accéder
directement les fonctions de virtualisation fournies par le noyau Linux en plus de l'utilisation d'interfaces de virtualisation
telles que <em>libvirt</em>, <em>LXC</em> et <em>systemd-nspawn</em>.</p>
<p>Docker implémente une API de haut niveau pour fournir des conteneurs légers exécutant des processus isolés.</p>
<p>Le logiciel Docker en tant qu'offre de services consiste en trois composants :</p>
<ul>
<li><strong>Le Logiciel</strong> : Le daemon Docker, <em>dockerd</em>, est un processus persistant qui gère les conteneurs Docker ainsi que les objets
du conteneur. Le daemon est à l'écoute des requêtes envoyés via l'API du Docker Engine. Et le programme client <em>docker</em> fournit
une interface de ligne de commande qui permet d'interagir avec le daemon.</li>
<li><strong>Les objets</strong> : Les objets docker sont des entités diverses utilisées pour assembler une application dans Docker. Les classes
principales des objets Dockers sont les images, les conteneurs et les services.
<ul>
<li>Un conteneur Docker est un environnement encapsulé, standardisé qui exécute des applications. Un conteneur est géré à
travers l'API Docker ou la ligne de commande.</li>
<li>Une image Docker est un modèle en lecture seule utilisée pour construire des conteneurs. Les images sont utilisées pour
stocker et envoyer des applications.</li>
<li>Un service Docker permet une mise à l'échelle des conteneurs sur de multiples daemons. Ceci étant appelé une nuée
(<em>swarm</em>), un ensemble de daemon coopérant, communiquant à travers l'API Docker.</li>
</ul>
</li>
<li><strong>Les registres</strong> : Un registre Docker est un dépôt d'image Docker. Les clients Docker se connectent aux registres pour cloner
(<em>pull</em>) des images à utiliser ou déposer (<em>push</em>) des images qu'ils ont construites. Les dépôts peuvent être publics ou privés.
Les deux principaux dépôts publics sont Docker Hub et Docker Cloud. Docker Hub est le registre par défaut ou Docker recherche
des images. Des registres Docker permettent également la création de notifications basée sur des évènements.</li>
</ul>
<p>Le logiciel Docker dispose également d'outils :</p>
<ul>
<li><strong>Docker Compose</strong> qui est un outil qui permet de définir et d'exécuter des applications Docker multi-conteneurs. Il utilise
des fichier YAML pour configurer les services de l'application et créé et démarre les processus de tous les conteneurs à l'aide
d'une seule commande. L'interface en ligne de commande <em>docker-compose</em> permet aux utilisateurs de passer des commandes sur des
ensembles de conteneurs, par exemple pour construire des images, déployer des conteneurs, redémarrer des conteneurs, etc. Les
commandes liées à la manipulation d'image, ou les options interactives sont inutiles dans Docker Compose car elle s'adressent à
un conteneur unique. Le fichier docker-compose.yml est utiliser pour définir les services de l'application et inclut plusieurs
options de configuration. Par exemple, l'option <em>build</em> définit les options de configuration telles que le chemin du Dockerfile,
l'option <em>command</em> permet de surcharger les commandes Docker par défaut, etc.</li>
<li><strong>Docker Swarm</strong> fournit nativement un fonctionnalité de grappe pour les conteneurs Docker qui transforme un groupe de Docker
engine en un unique Docker engine virtuel. L'interface ligne de commande <em>docker swarm</em> permet aux utilisateurs d'exécuter des
conteneurs Swarm, de créer des mots-clefs, lister les noeuds de la grappe, etc. L'interface ligne de commande <em>docker node</em>
permet aux utilisateurs d'exécuter diverses commandes pour gérer des noeuds dans la nuée, par exemple, lister les noeuds de la
nuée, mettre à jour les noeuds, supprimer les noeuds d'une nuée. Docker gère les nuées en utilisant l'algorithme de consensus
Raft. Selon Raft, pour qu'une mise à jour se fasse, la majorité des noeuds de la nuée doivent s'accorder sur celle-ci.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation-5"><a class="header" href="#virtualisation-et-conteneurisation-5">Virtualisation et conteneurisation</a></h2>
<h3 id="orchestrateur-kubernetes"><a class="header" href="#orchestrateur-kubernetes">Orchestrateur Kubernetes</a></h3>
<p>Kubernetes est un système d'orchestration de conteneurs open source permettant d'automatiser le déploiement, la mise à l'échelle
et la gestion d'applications informatiques.</p>
<p>Beaucoup de services de cloud offrent des plateformes ou infrastructures en tant que service (PaaS, IaaS) basées sur Kubernetes
sur lesquelles Kubernetes peut être déployé comme service fournisseur de plateformes.</p>
<p>Kubernetes définit un ensemble de primitives, qui collectivement fournissent des mécanismes de déploiement, de maintien et de
mise à l'échelle d'applications basé sur les ressources CPU, mémoire et autres métriques personnalisées. Kubernetes est
lâchement couplé et extensible pour s'accorder à différentes charges de travail. Cette extensibilité est fournit en grande
partie par l'API Kubernetes, utilisée par des composants internes ainsi que les extensions et conteneurs exécutés sur
Kubernetes. La plateforme exerce son contrôle sur les ressources de calcul et de stockage et définissant ces ressources comme
objets, ceux-ci pouvant par la suite être gérés comme tels.</p>
<p>Kubernetes suit l'architecture Maître-Esclave. Les composants de Kubernetes peuvent être divisés entre ceux qui gèrent les
noeuds individuels et ceux qui font partie du plan de contrôle.</p>
<p>Le maître Kubernetes est l'unité principale de contrôle du cluster, il gère la charge de travail et dirige les communications à
travers le système. Le plan de contrôle de Kubernetes consiste en divers composants, chacun ayant sa propre tâche, pouvant être
exécuté soit sur un simple noeud maître, soit sur plusieurs maîtres pour des clusters à haute disponibilité. Les différents
composants du plan de contrôle Kubernetes sont les suivants :</p>
<ul>
<li><strong>etcd</strong> : etcd est une base de données clef-valeur, légère, persistante et distribuée qui stocke de manière fiable les
données de configuration du cluster, donnant une représentation de l'état global du cluster à l'instant t. <em>etcd</em> est un système
qui favorise la cohérence à la disponibilité dans l'éventualité d'une partition réseau. Cette cohérence est cruciale pour
ordonnancer correctement les services opérants. Le serveur de l'API Kubernetes utilise l'API de visualisation d'etcd pour
surveiller le cluster et déployer des changements configuration critiques ou simplement restaurer n'importe quelle divergence
d'état du cluster tels qu'il était déclaré par celui qui l'a déployé.</li>
<li><strong>Le serveur d'API</strong> : Le serveur d'API est un composant clé qui sert l'API Kubernetes via des JSON en HTTP, qui fournit à la
fois les interfaces internes et externes à Kubernetes. Le serveur d'API traite et valide les requêtes REST et met à jour l'état
des objets dans etcd, de fait permettant aux clients de configurer les charges de travail et les conteneurs à travers les
noeuds.</li>
<li><strong>L'ordonnanceur</strong> : L'ordonnanceur est un composant qui, sur la base de la disponibilité ressource, sélectionne un noeud sur
lequel s'exécute un pod non ordonnancé (entité de base géré par l'ordonnanceur). L'ordonnanceur suit l'usage ressource sur
chacun des noeuds afin de s'assurer que la charge de travail n'est pas planifiée en excès de la ressource disponible. A cette
fin, l'ordonnanceur doit connaître les conditions et disponibilités de la ressource et autres contraintes définies par
l'utilisateur, les directives politiques telles que la qualité de service, les conditions d'affinité ou de non-affinité, la
localisation des données etc. Le rôle de l'ordonnanceur est d'accorder la ressource disponible à la charge de travail demandée.</li>
<li><strong>Le gestionnaire de contrôle</strong> : Un contrôleur est une boucle de réconciliation qui amène l'état courant du cluster vers
l'état désiré du cluster, en communicant via le serveur d'API pour créer, mettre à jour et supprimer les ressources qu'il gère
(pods, services, extrémités, etc.). Le gestionnaire de contrôle est un processus qui gère un ensemble de contrôleurs du noyau
Kubernetes. Un type de contrôleur est un contrôleur de réplication, qui s'occupe de la réplication et de la mise à l'échelle en
exécutant un nombre de copies de pods spécifiées à travers le cluster. Il s'occupe également de créer des pods de remplacement,
si les noeuds sous-jacents sont en erreur. D'autres contrôleurs qui sont une partie du noyau Kubernetes incluent le contrôleur
DaemonSet pour exécuter exactement un pod sur chaque machine (ou sous-ensemble de machines), et un contrôleur de travail pour
exécuter des pods jusqu'à fin d'exécution par exemple pour des traitements batchs. L'ensemble des pods qu'un contrôleur gère est
déterminé par l'étiquette des sélecteurs faisant partie de la définition du contrôleur.</li>
</ul>
<p>Un noeud, est une machine où des conteneurs (charge de travail) sont déployés. Chaque noeud à l'intérieur du cluster doit
exécuter un environnement d'exécution de conteneurs tel que Docker, ainsi que les composants mentionnés ci-dessous, à des fins
de communication avec le maître pour la configuration réseau de ces conteneurs.</p>
<ul>
<li><strong>Kubelet</strong> : Kubelet est responsable de l'état d'exécution de chaque noeud, il s'assure que tous les conteneurs du noeud sont
sains. Il prend en charge le démarrage, l'arrêt et la maintenance des conteneurs d'application organisés en pods tels que l'a
décidé le plan de contrôle. Kublet surveille l'état d'un pod, s'il n'est pas dans l'état désiré, le pod est redéployé sur le
même noeud. Le statut du noeud est relayé sur une période de quelques secondes via des messages au maître. Si le maître détecte
un échec de noeud, le contrôleur de réplication observe ce changement de statut et lance des pods sur d'autres noeuds sains.</li>
<li><strong>Kube-proxy</strong> : Le Kube-proxy est une implémentation d'un proxy réseau et d'un répartiteur de charge, il prend en charge
l'abstraction de service ainsi que d'autres opérations réseau. Il est responsable du routage du traffic vers le conteneur
approprié basé sur l'adresse IP et le numéro de port de la requête qui arrive.</li>
<li><strong>Environnement</strong> d'exécution de conteneur : Un conteneur réside dans un pod. Le conteneur est le niveau de micro-service le
plus bas, qui contient l'application en cours d'exécution, les bibliothèques et leurs dépendances. Ils peuvent également avoir
une adresse IP externe.</li>
</ul>
<p>L'unité d'ordonnancement de base dans Kubernetes est un pod. Un pod est un groupement de composants conteneurisés. Un pod
consiste en un ou plusieurs conteneurs garantis de se trouver sur le même noeud.</p>
<p>Chaque pod dans Kubernetes est assigné à une adresse IP unique à l'intérieur du cluster, permettant aux applications d'utiliser
des ports sans risques de conflits. A l'intérieur du pod, chaque conteneur peut faire référence à chaque autre sur le localhost,
mais un conteneur à l'intérieur d'un pod n'a aucun moyen de s'adresser directement à un autre conteneur dans un autre pod ; pour
cela, il doit utiliser l'adresse IP du pod.</p>
<p>Un pod peut définir un volume, tel qu'un répertoire du disque local ou un disque réseau, et l'exposer aux conteneurs du pod. Les
pods peuvent être gérés manuellement via l'API Kubernetes, ou leur gestion peut être déléguée à un contrôleur. De tels volumes
sont aussi la base des fonctionnalités Kubernetes de ConfigMaps (pour fournir un accès à la configuration à travers le système
de fichier visible au conteneur) et Secrets (pour fournir les certificats nécessaires à l'accès sécurisé à des ressources
distantes, en donnant uniquement aux conteneurs autorisés, ces certificats sur leur système de fichier visible).</p>
<p>La fonction d'un ReplicaSet est de maintenir un ensemble stable de pods répliqués pouvant être exécutés à tout moment. En tant
que tel, il est souvent utilisé pour garantir la disponibilité d'un nombre de pods identiques spécifique.</p>
<p>Les ReplicaSets est également un mécanisme de rassemblement qui permet à Kubernetes de maintenir pour un pod donné un nombre
d'instance défini à l'avance. La définition d'un ensemble de réplique utilise un sélecteur, dont l'évaluation résulte en
l'évaluation de tous les pods qui lui sont associés.</p>
<p>Un service Kubernetes est un ensemble de pods travaillant de concert, tel une couche d'une application multi-couche. L'ensemble
de pods qui constitue un service sont définis par un sélecteur d'étiquette. Kubernetes fournit deux modes de découverte de
service, en utilisant des variables d'environnement, ou en utilisant le DNS Kubernetes. La découverte de service assigne un
adresse IP fixe et un nom DNS au service, et réparti la charge du traffic en utilisant un DNS round-robin pour les connexions
réseaux à cette adresse IP au milieu des pods vérifiant ce sélecteur (même si des erreurs peuvent amener les pods à passer d'une
machine à une autre). Par défaut un service est exposé à l'intérieur d'un cluster (par exemple les pods back-end peuvent être
groupés en service, recevant des requêtes de la part des pods front-end réparties entre eux), mais un service peut également
être exposé en dehors d'un cluster (par exemple pour que les clients puissent accéder aux pods front-end).</p>
<p>Les systèmes de fichier dans le conteneur Kubernetes fournit par défaut un stockage éphémère. Cela signifie qu'un redémarrage du
pod effacera toute les données sur ces conteneurs, et par conséquent, cette forme de stockage est, excepté dans le cas
d'applications triviales, relativement limitante. Un volume Kubernetes fournit un stockage permanent qui existe pendant la durée
d'existence du pod lui-même. Ce stockage peut également être utilisé comme disque partagé pour les conteneurs du pod. Ces
volumes sont montés à des points de montages spécifique à l'intérieur du conteneur définit par la configuration du pod, et ne
peuvent être montés aux autres volumes ou liés à ceux-ci. Le même volume peut être monté à différent endroits dans l'arbre du
système de fichiers par différents conteneurs.</p>
<p>Kubernetes fournit un partitionnement des ressources qu'il gère dans des ensembles disjoints appelés espace de noms. L'usage de
ces espaces de noms est destiné aux environnements possédant un grand nombre d'utilisateurs répartis dans plusieurs équipes, ou
projets, ou même à séparer des environnements tels que le développement, l'intégration et la production.</p>
<p>Un problème applicatif thématique est de décider ou stocker et gérer les informations de configuration, dont certaines peuvent
contenir des données sensibles. Les données de configuration peuvent être relativement hétérogènes comme de petits fichiers de
configurations individuels ou de grands fichiers de configuration ou des documents JSON/XML. Kubernetes permet de traiter ce
genre de problème à l'aide de deux mécanismes assez proches : &quot;configmaps&quot; et &quot;secrets&quot;, les deux permettent des changements de
configuration sans nécessiter la reconstruction de l'application. Les données de configmaps et de secrets sont accessibles à
chaque objets de l'instance de l'application auxquels ils ont été liés au déploiement. Un secret et/ou un configmaps sont
uniquement envoyé à un noeud si un pod sur ce noeud le demande. Kubernetes le gardera en mémoire sur ce noeud. Un fois que le
pod qui dépend du secret ou de la configmap est supprimé, la copie en mémoire de tous les secrets et configmaps liés est
également supprimée. La donnée est accessible au pod de deux façons : en tant que variables d'environnements (que Kubernetes
créé lors du démarrage du pod) ou disponible dans le système de fichier du conteneur visible dans le pod.</p>
<p>La donnée elle même est stockée sur le maître qui est hautement sécurisé et dont personne ne doit avoir d'accès de connexion. La
plus grande différence entre un secret et une configmap est que le contenu de la donnée dans un secret est encodé en base 64. Il
peut également être chiffré. Les secrets sont souvent utilisés pour stocker des certificats, des mots de passe et des clefs ssh.</p>
<p>Il est très facile de réaliser une mise à l'échelle d'applications sans conditions d'état : Il suffit d'ajouter plus de pods
d'exécution - quelque chose que Kubernetes fait très bien. Les charges de travail avec condition d'état sont bien plus
difficiles, de fait que l'état doit être conservé si un pod est redémarré, et si l'application doit être redimensionnée alors
l'état devra possiblement être redistribué. Les bases de données sont des exemples de charge de travail avec condition d'état.
Lors d'une exécution en mode haute disponibilité, beaucoup de bases de données ont la notion d'instance primaire et
d'instance(s) secondaires. Dans ce cas la notion d'ordonnancement d'instances est important.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation-6"><a class="header" href="#virtualisation-et-conteneurisation-6">Virtualisation et conteneurisation</a></h2>
<h3 id="libvirt"><a class="header" href="#libvirt">Libvirt</a></h3>
<p>Libvirt est une API open-source, ainsi qu'un daemon et un outil de gestion pour gérer des plateformes de virtualisation. Elle
peut être utilisée pour gérer KVM, Xen, VMware, ESXi, QEMU et autres technologies de virtualisation. Ces APIs sont utilisées
très largement au niveau de la couche d'orchestration des hyperviseurs pour le développement de solutions de clouds.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="virtualisation-et-conteneurisation-7"><a class="header" href="#virtualisation-et-conteneurisation-7">Virtualisation et conteneurisation</a></h2>
<h3 id="hyperviseurs"><a class="header" href="#hyperviseurs">Hyperviseurs</a></h3>
<p>Un hyperviseur est un logiciel, microgiciel ou matériel qui créé et exécute des machines virtuelles. Un ordinateur sur lequel un
hyperviseur exécute une ou plusieurs machines virtuelles est appelé hôte, et chaque machine virtuelle est appelée invitée.
L'hyperviseur présente le système d'exploitation invité à l'aide d'une plateforme d'exploitation virtuelle et gère l'exécution
des systèmes d'exploitations invités. Plusieurs instances de divers systèmes d'exploitation peuvent partager les mêmes ressources
matérielles virtualisées. A l'instar des mécanismes de virtualisation implémentés au niveau du système d'exploitation
(conteneurs), les systèmes d'exploitations invités ne doivent pas forcément partager un même noyau.</p>
<p>Il existe deux types d'hyperviseurs :</p>
<ul>
<li><strong>Type-1 natif</strong> : Ces hyperviseurs s'exécutent directement sur le matériel de l'hôte pour contrôler le matériel et gérer les
systèmes d'exploitation invités.</li>
<li><strong>Type-2 hébergés</strong> : Ces hyperviseurs s'exécutent sur un système d'exploitation conventionnel comme n'importe quel autre
programme. Un système d'exploitation invité s'exécute en tant que processus de l'hôte. Les hyperviseurs de type-2 créent une
abstraction pour les systèmes d'exploitation invités depuis le système d'exploitation hôte.</li>
</ul>
<p>Cette distinction entre les deux types n'est pas toujours claire. Par exemple KVM et bhyve sont des modules noyau qui
transforment le système d'exploitation hôte en hyperviseur de type-1. En même temps, les distributions Linux et FreeBSD sont
aussi des systèmes d'exploitations conventionnels, où des applications entrent en concurrence les unes avec les autres pour les
ressources VM et ils peuvent être aussi catégorisés comme des hyperviseurs de type-2.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="données"><a class="header" href="#données">Données</a></h1>
<h4 id="introduction-3"><a class="header" href="#introduction-3">Introduction</a></h4>
<p>Ce chapitre traite de la partie données du programme PSE.</p>
<p>De la gestion des données structurées (Bases de données), semi-structurées et déstructurées (Big data et lacs de données), avec
une approche relativement légère pour deux sujets aussi larges.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="bases-de-données"><a class="header" href="#bases-de-données">Bases de données</a></h2>
<p>Une base de données est une collection organisée de données stockées et accédées de manière électronique depuis un système
informatique. Elles sont généralement développées en utilisant des techniques d'architecture et de modélisation formelles.</p>
<p>Les <strong>système de gestion de bases de données (SGBD)</strong> est le logiciel qui interagit avec l'utilisateur final, les applications,
et la base de données elle-même pour capturer et analyser la donnée. Le logiciel SGBD comprend également les principaux outils
d'administration de bases de données.</p>
<p>On peut classifier les système de gestion de bases de données d'après les modèles de bases de données supportés.</p>
<p>Généralement les modèles logiques de données les plus rencontrés sont :</p>
<ul>
<li><strong>Modèle hiérarchiques</strong> : Modèle dans lequel la donnée est organisée dans une structure de type arbre. La donnée est stockée
en tant qu'enregistrements connectés les uns aux autres par des liens. Un enregistrement est une collection de champs, avec
chaque champs contenant une unique valeur. Le type d'enregistrement définit les champs que l'enregistrement contient.</li>
<li><strong>Modèle réseau</strong> : Modèle conçu comme étant une façon flexible de représenter des objets et leurs relations. Sa
caractéristique principale est que le schéma, vu comme un graphe dans lequel les types d'objets sont des noeuds et les relations
entre types sont des liens, n'est pas restreint à être hiérarchique ou maillé.</li>
<li><strong>Modèle objet</strong> : Modèle dans lequel l'information est représentée sous la forme d'objets et utilisés en programmation
orientée objet. Les bases de données objets sont différentes des bases de données relationnelles qui sont orientées tables.
Les bases de données objet-relationnel sont un hybride des deux approches.</li>
<li><strong>Modèle relationnel</strong> : Modèle dans lequel toute donnée est représentée en terme de liste ordonnée finie, groupée dans des
relations.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="bases-de-données-1"><a class="header" href="#bases-de-données-1">Bases de données</a></h2>
<h3 id="crud"><a class="header" href="#crud">CRUD</a></h3>
<p><strong>Create Read Update Delete (CRUD)</strong> sont quatre opérations basiques de stockage persistant. CRUD est également utilisé quelques
fois pour décrire des conventions d'interface utilisateur permettant l'affichage, la recherche et le changement d'informations à
l'aide de formulaires et de rapports.</p>
<p>L'acronyme CRUD fait référence à des opérations majeure implémentées par les bases de données. Chaque lettre peut être mis en
lien avec une commande SQL standard :</p>
<div class="table-wrapper"><table><thead><tr><th>CRUD</th><th>SQL</th></tr></thead><tbody>
<tr><td>Create</td><td>INSERT</td></tr>
<tr><td>Read</td><td>SELECT</td></tr>
<tr><td>Update</td><td>UPDATE</td></tr>
<tr><td>Delete</td><td>DELETE</td></tr>
</tbody></table>
</div>
<p>L'acronyme CRUD peut également apparaître avec les APIs dites RESTful. Chaque lettre de l'acronyme peut être lié à une méthode
HTTP :</p>
<div class="table-wrapper"><table><thead><tr><th>CRUD</th><th>HTTP</th></tr></thead><tbody>
<tr><td>Create</td><td>PUT</td></tr>
<tr><td>Read</td><td>GET</td></tr>
<tr><td>Update</td><td>PUT</td></tr>
<tr><td>Delete</td><td>DELETE</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h2 id="bases-de-données-2"><a class="header" href="#bases-de-données-2">Bases de données</a></h2>
<h3 id="acid"><a class="header" href="#acid">ACID</a></h3>
<p><strong>Atomicité Consistence Isolation Durabilité (ACID)</strong> est un ensemble de propriétés des transactions de bases de données devant
permettre de garantir une validité de données malgré les erreurs, pertes d'électricité et autres mésaventures. Dans le contexte
des bases de données, une séquence d'opération répondant aux propriétés ACID est appelé transaction.</p>
<p>Les caractéristiques de ces quatre propriétés sont les suivantes :</p>
<ul>
<li><strong>Atomicité</strong> : Les transactions sont souvent composées de déclarations multiples. L'atomicité garantit que chaque transaction
est traitée en tant qu'unité, qui soit réussit totalement, soit échoue totalement : si la moindre déclaration constituante
échoue, la transaction échoue, la transaction dans son ensemble échoue et la base de donnée reste inchangée. Un système atomique
doit garantir l'atomicité dans chaque situation. Par conséquent, une transaction ne peut pas être observée comme étant en
progrès par un autre client de la base de données.</li>
<li><strong>Consistence (validité)</strong> : La consistence s'assure qu'une transaction peut uniquement amener la base de données d'un état
correct vers un autre, en gardant les invariants de la base de données : toute donnée rentrée en base doit être valide selon
toutes les règles définies, cela inclut les contraintes, les cascades, les déclenchements, et leurs combinaisons. Cela empêche
une corruption de la base de données mais ne garantit pas qu'une transaction soit correcte. L'intégrité référentielle garantit
la relation clef primaire - clef étrangère.</li>
<li><strong>Isolation</strong> : Les transactions sont souvent exécutées de façon concurrente. L'isolation garantit que l'exécution concurrente
de transactions laisse la base de données dans le même état que si ces transactions avaient été exécutées de façon séquentielle.</li>
<li><strong>Durabilité</strong> : La durabilité garantit qu'une fois l'exécution de la transaction finie, elle sera toujours enregistrée même
dans le cas d'une panne. Cela signifie généralement que les transactions complétées sont enregistrées dans une mémoire non
volatile.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algèbre-relationnelle"><a class="header" href="#algèbre-relationnelle">Algèbre relationnelle</a></h2>
<p>Voir langage SQL.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="administration-sgbdr-postgresql"><a class="header" href="#administration-sgbdr-postgresql">Administration SGBDR PostgreSQL</a></h2>
<p>PostgreSQL est un système de gestion de base de données relationnel (SGBDR) libre et open source mettant l'accent sur
la notion d'extensibilité ainsi que le respect du standard SQL.</p>
<p>PostgreSQL a pour fonctionnalités des transactions avec les propriétés <em>ACID</em>, des vues misent à jours automatiquement, des vues
matérialisées, des déclencheurs, des clefs étrangères, et des procédures stockées. PostgreSQL est construit de façon à gérer
tout type de charge de travail, depuis un simple ordinateur jusqu'aux entrepôts de données ou des services webs répondant à de
nombreux utilisateurs concurrents.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="administration-sgbdr-postgresql-1"><a class="header" href="#administration-sgbdr-postgresql-1">Administration SGBDR PostgreSQL</a></h2>
<h3 id="stockage-et-réplication"><a class="header" href="#stockage-et-réplication">Stockage et réplication</a></h3>
<p>PostgreSQL inclus une réplication binaire basé sur l'import de changements (write-ahead logs (WAL)) pour répliquer des noeuds de
manière asynchrone, avec la possibilité d'exécuter des requêtes de lecture seule sur ces noeuds répliqués. Ceci permet de
séparer le traffic en lecture sur de multiples noeuds efficacement.</p>
<p>PostgreSQL inclus un mécanisme de réplication synchrone qui garantit que, pour chaque transaction d'écriture, le maître attende
jusqu'à ce qu'au moins un noeud répliqué ait écrit la donné dans sa log de transactions. Contrairement à d'autres systèmes de
base de données, la durabilité d'une transaction (selon qu'elle soit synchrone ou asynchrone) peut être spécifiée par base de
données, par utilisateur, par session ou même par transaction. Cela peut se révéler utile pour des charges qui ne demandent pas
de telles garanties, et peut ne pas être recherchée pour l'ensemble des données car cela diminue les performances du fait de la
nécessité de confirmation de la transaction pour atteindre la veille synchrone.</p>
<p>Les serveurs de veille peuvent être synchrones ou asynchrones. Des serveurs de veille synchrones peuvent être spécifiés dans la
configuration qui détermine quels serveurs sont candidats pour la réplication synchrone. Le premier dans la liste qui diffuse
activement sera utilisé comme serveur synchrone courant. Quand il échoue, le système retombe sur le suivant dans la liste.</p>
<p>La réplication multi-maître synchrone n'est par inclus dans PostgreSQL. Postgres-XC basé sur PostgreSQL fournit la réplication
multi-maître synchrone. Réplication bidirectionnelle (BDR) est un système de réplication multi-maître asynchrone pour
PostgreSQL.</p>
<p>Des outils tels que <em>remgr</em> permettent de gérer des groupes de réplication plus facilement.</p>
<p>PostgreSQL inclus un support pour arbre B et index de tables de hachages, ainsi que quatre méthodes d'accès aux index : les
arbres de recherche généralisés (GiST), les index inversés généralisés (GIN), GiST partitionnés espace (SP-GiST) et les index de
portée de bloc (BRIN). De plus, des méthodes d'index définis par l'utilisateur peuvent être crées. Les index dans PostgreSQL
supporte également les fonctionnalités suivantes :</p>
<ul>
<li>Les index d'expression peuvent être créés à l'aide d'un index du résultat d'une expression ou fonction, au lieu de la simple
valeur d'une colonne.</li>
<li>Les index partiels, qui indexent seulement une partie d'une table, qui peut être créé en ajoutant une clause WHERE à la fin de
la déclaration CREATE INDEX. Ceci permet la création d'index plus petits.</li>
<li>Le planificateur est capable d'utiliser des index multiples ensemble pour répondre à des requêtes complexes, en utilisant des
opérations temporaire d'index de tableaux de bits en mémoire.</li>
<li>L'indexation des k-proche voisins (KNN-GiST) fournit une recherche efficace des &quot;plus proches valeurs&quot; à celle spécifiée,
utile pour trouver des mots similaires, ou des objets proches ou des lieux avec des informations géographiques.</li>
<li>Les balayages uniquement-index permettent souvent au système de récupérer la donnée depuis des index sans jamais avoir à
accéder la table principale.</li>
</ul>
<p>Dans PostgreSQL, un schéma détient tous les objets, à l'exception des rôles et des tablespaces. Les schémas agissent
efficacement comme des espaces de noms, permettant à des objets de même noms de coexister dans la même base de données. Par
défaut, les bases de données ont un schéma appelé <em>public</em>, mais d'autres schémas peuvent être créés, et le schéma public n'est
pas obligatoire.</p>
<p>Un paramètre <em>search_path</em> détermine l'ordre dans lequel PostgreSQL vérifie les schémas les objets sans qualifications (sans
schéma préfixé). Par défaut, il est défini à <em>$user, public</em> (<em>$user</em> fait référence à l'utilisateur de la base de données
connecté). Ce paramètre peut être changé sur une base de données ou un niveau de rôle, mais il s'agit d'un paramètre de session,
il peut être changé librement (de multiples fois) pendant une session client, affectant uniquement cette session.</p>
<p>Les schémas non existants, listés dans <em>search_path</em> sont silencieusement ignorés pendant la recherche d'objets.</p>
<p>De nouveaux objets sont créés dans n'importe quel schéma valide qui apparaît en premier dans le <em>search_path</em></p>
<p>Une grande variété de types de données natifs sont supportés, incluant :</p>
<ul>
<li>Booléens</li>
<li>Nombre à précision arbitraire</li>
<li>Caractère (texte, varchar, char)</li>
<li>Binaire</li>
<li>Date/heure (horodatage/heure avec/sans fuseau horaire, date, intervalle)</li>
<li>Monnaie</li>
<li>Énumération</li>
<li>Chaîne de bits</li>
<li>Texte de recherche de type</li>
<li>Composé</li>
<li>HStore</li>
<li>Tableaux</li>
<li>Primitives géométriques</li>
<li>Adresses IPv4 et IPv6</li>
<li>CIDR et adresses MAC</li>
<li>XML</li>
<li>UUID</li>
<li>JSON, JSONB</li>
</ul>
<p>De plus, les utilisateurs peuvent créer leurs propres types de données qui peut généralement être fait complètement indexable
via les infrastructures d'indexation PostgreSQL - GiST, GIN, SP-GiST.</p>
<p>Il existe également un type de données appelé un <em>domaine</em>, qui est le même que n'importe quel type de données mais avec des
contraintes optionnelles définies par le créateur de ce domaine. Cela signifie que toute donnée entrée dans une colonne
utilisant le domaine devra se conformer aux contraintes définies comme faisant partie du domaine.</p>
<p>Un type qui représente un intervalle de donnée peut être utilisé et est appelé type intervalle. Ces intervalles peuvent être
discrets ou continus. Les types inclus disponibles sont les intervalles d'entiers, les nombres décimaux, les horodatages et les
dates.</p>
<p>Des types avec intervalles personnalisés peuvent être créés pour faire de nouveau types d'intervalles disponibles, tels que des
adresses IP qui utilisent un type inet comme base. Les types intervalle sont aussi compatibles avec des opérateurs existants
utilisés pour vérifier des intersections, l'inclusion, etc.</p>
<p>De nouveaux types de la plupart des objets à l'intérieur de la base de données peuvent être créés, tels que :</p>
<ul>
<li>Distributions</li>
<li>Conversions</li>
<li>Types de données</li>
<li>Domaines de données</li>
<li>Fonctions</li>
<li>Index</li>
<li>Opérateurs</li>
<li>Langages procéduraux</li>
</ul>
<p>Des tables peuvent être paramétrées pour hériter leurs caractéristiques d'une table parente. Les données d'une table descendante
apparaîtront comme existantes dans les tables parentes, à moins que les données ne soit lues depuis la table parente en
utilisant le mot clef ONLY. Ajouter une colonne dans la table parente la fera apparaître dans la table descendante.</p>
<p>L'héritage peut être utilisé pour implémenter un partitionnement de table, en utilisant soit des déclencheurs soit des règles
pour insérer directement depuis la table parente dans les tables descendante concernées.</p>
<p>L'héritage permet de fournir un moyen de relier les fonctions de généralisation hiérarchiques décrites dans des diagrammes
relations entités (ERDs) directement dans la base de données PostgreSQL.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="administration-sgbdr-postgresql-2"><a class="header" href="#administration-sgbdr-postgresql-2">Administration SGBDR PostgreSQL</a></h2>
<h3 id="contrôle-et-connectivité"><a class="header" href="#contrôle-et-connectivité">Contrôle et connectivité</a></h3>
<p>PostgreSQL peut se connecter à d'autres systèmes pour récupérer des données via des encapsulateurs de données étrangères (FDWs).
Ils peuvent prendre la forme de n'importe quelle source de données, telle qu'un système de fichier, un autre SGBDR, ou un
service web. Cela signifie que des requêtes classiques de base de données peuvent utiliser ces sources de données comme des
tables, et même joindre ensemble plusieurs sources de données.</p>
<p>Pour se connecter à des applications, PostgreSQL inclus l'interface libpq (l'interface d'applications C officielle) et ECPG (un
système C embarqué). Des bibliothèques tierces pour se connecter à PostgreSQL sont disponibles pour de nombreux langages de
programmation.</p>
<p>Des langages procéduraux permettent aux développeurs d'étendre la base de donnée à l'aide de fonctions personnalisées, souvent
appelées <strong>procédures stockées</strong>. Ces fonctions peuvent être utilisées pour construire des déclencheurs de base de données
(fonctions invoquées suite à la modification d'une donnée particulière), des types de données personnalisés et des fonctions
d'agrégations. Des langages procéduraux peuvent également être invoqués sans définir de fonction en utilisant une commande DO au
niveau du SQL.</p>
<p>Les langages sont divisés en deux groupes : les procédures écrites en langage sûr sont exécutées dans des bacs à sable et
peuvent être créées et utilisées par n'importe quel utilisateur. Les procédure écrites en langage non sûr sont uniquement créées
par des super utilisateurs, du fait qu'elles permettent un court circuit des restrictions de sécurité de la base de données,
mais également d'accéder à des ressources externe à la base de données. Quelques langages tel que Perl fournissent à la fois des
versions sûre et non sûres.</p>
<p>PostgreSQL fournit un support pour trois langages procéduraux :</p>
<ul>
<li>SQL (sûr). Des fonctions SQL plus simple peuvent être étendues dans une requête appelante, qui évite la surcharge à l'appel
de fonction et permet à l'optimiseur de requête de &quot;voir à l'intérieur&quot; de la fonction.</li>
<li>Langage procédural PostgreSQL (PL/pgSQL)(sûr), qui ressemble au langage procédural Oracle pour langage procédural SQL (PL/SQL)
et les modules stockés persistants SQL (SQL/PSM).</li>
<li>C (non sûr), qui permet de charger une ou plusieurs bibliothèques partagées personnalisées en base de données. Les fonctions
écrites en C offrent une meilleure performance, mais un bogue dans le code peut faire tomber et corrompre la base de données.
La plupart des fonctions incluses sont écrites en C.</li>
</ul>
<p>De plus, PostgreSQL permet aux langages procéduraux d'être chargés en base de données à l'aide d'extensions. Trois extensions
sont incluses dans PostgreSQL pour Perl, Tcl et Python.</p>
<p>Des déclencheurs sont des évènements déclenchés par l'action de déclarations de langage de manipulation de données SQL (DML). La
plupart des déclencheurs sont activés uniquement pour des déclarations INSERT ou UPDATE.</p>
<p>Les déclencheurs peuvent être liés à des tables. Ils peuvent être par colonnes et conditionnels, les déclencheurs UPDATE peuvent
cibler les colonnes spécifiques d'une table, et les déclencheurs peuvent être exécutés selon un ensemble de conditions spécifiés
par une clause WHERE. Les déclencheurs peuvent être liés à des vues en utilisant la condition INSTEAD OF. De multiples
déclencheurs sont traités par ordre alphabétique. En plus d'appeler des fonctions écrites en PL/pgSQL natif, les déclencheurs
peuvent également invoquer des fonctions écrites dans d'autres langages PL/Python ou PL/Perl.</p>
<p>PostgreSQL fournit un système de messagerie asynchrone qui peut être accédé à travers les commandes NOTIFY, LISTEN et UNLISTEN.
Une session peut émettre une commande NOTIFY, avec un canal spécifique à un utilisateur et une charge optionnelle, pour marquer
l'occurrence d'un évènement en particulier. D'autres sessions sont capables de détecter ces évènements en soumettant une
commande LISTEN, qui permet d'écouter un canal en particulier. Cette fonctionnalité peut être utilisée pour une grande variété
de situations, tels que faire savoir à d'autres sessions quand une table a été mise à jour, ou pour des applications séparées de
détecter quand une action particulière a été effectuée. Un tel système prévient le besoin de récupération d'informations par les
applications et réduit les surcharges inutiles. Les notifications sont pleinement transactionnelles, dans le sens où les
messages ne sont pas envoyés tant que la transaction desquels ils proviennent n'a été enregistrée. Cela élimine le problèmes des
messages envoyés pour une action en cours qui est ensuite redéroulée en sens inverse.</p>
<p>Beaucoup de connecteurs pour PostgreSQL fournissent un support pour le système de notification (incluant libpq, JDBC, Npgsql,
psycopg, Npgsql, psycopg et node.js) pour qu'il puisse être utilisé par des applications internes.</p>
<p>Les règles permettent l'arbre de requêtage d'une requête arrivante d'être réécrit. Des &quot;règles de réécriture de requête&quot; sont
liées à une table/classe et &quot;réécrire&quot; le DML arrivant (select, insert, update et/ou delete) en une ou plusieurs requêtes
supplémentaires qui soit remplacent la déclaration DML originale soit s'ajoutent à lui. Les réécriture de requêtes ont lieu
après l'analyse syntaxique de la déclaration de requête, mais avant la planification de requête.</p>
<p>D'autres fonctionnalités du requêtage incluent :</p>
<ul>
<li>Transactions</li>
<li>Recherche plein texte</li>
<li>Vues
<ul>
<li>Vues matérialisées</li>
<li>Vues actualisables</li>
<li>Vues récursives</li>
</ul>
</li>
<li>Joins internes, externes et croisés</li>
<li>Sous-selects
<ul>
<li>Sous-requêtes corrélées</li>
</ul>
</li>
<li>Expressions régulières</li>
<li>Expressions de tables communes et expression de table commune inscriptible</li>
<li>Connexions chiffrées via sécurité de couche transport (TLS)</li>
<li>Domaines</li>
<li>Points de sauvegardes</li>
<li>Enregistrement en deux temps</li>
<li>La technique de stockage d'attributs surdimensionnés (TOAST) est utilisée pour stocker de manière transparente de grand
attributs de table dans une aire séparée, avec compression automatique.</li>
<li>SQL embarqué est implémenté en utilisant un préprocesseur. Un code SQL est tout d'abord été écrite et embarquée dans du code
C. Puis le code est exécuté à travers un préprocesseur ECPG, qui remplace le SQL avec des appels au code de la bibliothèque.
Puis le code peut être compilé en utilisant un compilateur C.</li>
</ul>
<p>Le serveur PostgreSQL fonctionne au niveau des processus (et pas des fils d'exécution), et utilise un processus de système
d'exploitation par session de base de données. Des sessions multiples sont automatiquement réparties sur tout les processeurs
disponibles par le système d'exploitation. De nombreux types de requêtes peuvent aussi être parallélisés à travers plusieurs
processus en arrière plan, pour profiter des nombreux processeurs ou cœurs. Les applications clientes peuvent utiliser des fils
d'exécution et créer plusieurs connexions à la base de données depuis chaque fil d'exécution.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="administration-sgbdr-postgresql-3"><a class="header" href="#administration-sgbdr-postgresql-3">Administration SGBDR PostgreSQL</a></h2>
<h3 id="sécurité"><a class="header" href="#sécurité">Sécurité</a></h3>
<p>PostgreSQL gère sa sa sécurité interne à l'aide de rôles. Un rôle peut généralement être un utilisateur (un rôle pouvant se
connecter), ou un groupe (un rôle duquel d'autres rôles sont membres). Les permissions peuvent être accordées ou révoquées sur
tout objet jusqu'au niveau des colonnes, et peuvent également permettre/interdire la création de nouveaux objets au niveau de la
base de données, du schéma ou de la table.</p>
<p>La fonctionnalité PostgreSQL SECURITY LABEL permet un sécurité additionnelle; avec un module chargeable inclus permettant un
contrôle d'accès obligatoire d'étiquettes (MAC) basé sur la politique de sécurité SELinux.</p>
<p>PostgreSQL supporte nativement un large panel de mécanismes externes d'authentification, tels que :</p>
<ul>
<li>Mot de passe : soit SCRAM-SHA-256, soit MD5, soit en clair</li>
<li>GSSAPI</li>
<li>SSPI</li>
<li>Kerberos</li>
<li>ident (relie utilisateur système et utilisateur base de données par serveur ident)</li>
<li>peer (relie utilisateur local et utilisateur base de données)</li>
<li>LDAP
<ul>
<li>AD</li>
</ul>
</li>
<li>RADIUS</li>
<li>Certificat</li>
<li>PAM</li>
</ul>
<p>Les méthodes par GSSAPI, SSPI, Kerberos, pees, ident et certificats peuvent également spécifier un fichier &quot;map&quot; qui liste quels
utilisateurs vérifiés par le système d'authentification sont autorisés à se connecter spécifiquement en tant qu'utilisateur de
base de données.</p>
<p>Ces méthodes sont spécifiées dans le fichier de configuration d'authentification de groupe basé sur l'hôte (<em>pg_hba.conf</em>), qui
détermine quelles connexions sont autorisées. Cela permet un contrôle sur quel utilisateur peut se connecter à quelle base de
données, depuis quelle adresse IP, intervalle d'adresse IP ou domaine socket, avec quel système d'authentification, et si la
connexion doit utiliser la couche de transport de sécurité (TLS)</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="big-data-et-lac-de-données"><a class="header" href="#big-data-et-lac-de-données">Big data et lac de données</a></h2>
<p>Le big data désigne les ressources d'informations dont les caractéristiques en terme de volume, de vélocité et de variété
imposent l'utilisation de technologies et de méthodes analytiques particulières pour générer de la valeur, et qui dépassent en
général les capacités d'une seule et unique machine et nécessitent des traitements parallélisés.</p>
<p>L'explosion quantitative (et souvent redondante) des données numériques permet une nouvelle approche pour analyser le monde. Le
volume colossal de données numériques disponibles, implique de mettre en oeuvre de nouveaux ordres de grandeur concernant la
capture, le stockage, la recherche, le partage, l'analyse et la visualisation des données, celles-ci proviennent de nombreuses
sources numériques : les réseaux sociaux, l'OpenData, le Web, des bases de données privées, publiques à caractère commercial ou
scientifique.</p>
<p>La maturité grandissante du concept permet de se différencier de manière plus marqué vis à vis de l'informatique décisionnelle :</p>
<ul>
<li>L'informatique décisionnelle utilise des outils de mathématiques appliquées ainsi que des statistiques descriptives à l'aide
de données à haute densité d'informations pour mesurer, observer des tendances etc.  Le big data utilise l'analyse mathématique,
l'optimisation, les statistiques inductives ainsi que des concepts d'identification de systèmes non linéaires pour inférer des
règles (régressions, relations non linéaires et effets causaux) de larges ensembles de données avec une densité d'information
faible afin de révéler des relations et dépendances, ou pour fournir des prédictions de résultats et de comportements.</li>
</ul>
<p>Le big data peut être décrit par les caractéristiques suivantes :</p>
<ul>
<li><strong>Volume</strong> : La quantité de la donnée générée et stockée. La taille de la donnée détermine la valeur, la potentielle
perspicacité, et si elle peut être considérée big data ou non. La taille du big data est généralement supérieure aux térabits et
pétabits.</li>
<li><strong>Variété</strong> : Le type et la nature de la donnée. Les technologies plus anciennes tels que les SGBDR étaient capable de traiter
des données structurées de manière performante et efficace. Néanmoins, les changements du type et de la nature des données
structurées à semi-structurées puis déstructurées à mis à l'épreuve les outils et technologies existants. Les technologies big
data ont évoluées avec l'intention première de capturer, stocker et traiter la donnée semi-structurée et déstructurée (variété)
générée très rapidement  (vitesse), et avec une taille immense (volume). Plus récemment, ces outils et technologies sont
utilisés pour s'occuper de données structurées mais préférablement pour le stockage. Finalement, le traitement de données
structurées était toujours gardé en option, soit en utilisant du big data soit avec des SGBDR traditionnels. Ceci permet
d'analyser les données vers un usage efficace des perspicacités cachées exposées par les données collectées via les réseaux
sociaux, les fichiers de logs, les capteurs, etc. que le big data dessine depuis du texte, des images, audio, vidéo ; et
complète les pièces manquantes via la fusion de données.</li>
<li><strong>Vitesse</strong> : La rapidité à laquelle la donnée est générée et traitée pour satisfaire la demande et les nouveaux défis que
représentent le chemin de la croissance et du développement. Le big data est souvent disponible en temps réel. En comparaison
avec le small data, le big data est produit de façon plus continu. Deux types de vitesses liés au big data sont la fréquence de
production et la fréquence de gestion, enregistrement et publication.</li>
<li><strong>Véracité</strong> : La véracité et la fiabilité de la donnée, qui fait référence à sa qualité et sa valeur. Le big data ne doit pas
être uniquement grand par la taille, mais également fiable afin d'obtenir de la valeur dans son analyse. La qualité de la donnée
capturée peut largement varier et affecter la précision de l'analyse.</li>
<li><strong>Valeur</strong> : La valeur d'une information qui peut être obtenu par le traitement et l'analyse de grands ensembles de données.
La valeur peut aussi être mesurée par une évaluation des autres qualités du big data. La valeur peut aussi représenter la
profitabilité de l'information qui est extraite de l'analyse du big data.</li>
<li><strong>Variabilité</strong> : La caractéristiques des formats changeants, structure, ou sources de big data. Le big data peut inclure des
données structurées ou déstructurées ou encore une combinaison des deux. L'analyse du big data peut intégrer des données brutes
de sources multiples. Le traitement des données brutes peut également faire intervenir des transformations de données
déstructurées en données structurées.</li>
</ul>
<p>D'autres caractéristiques du big data sont :</p>
<ul>
<li><strong>Exhaustivité</strong> : Si le système dans son ensemble est capturé (enregistré) ou non. Le big data peut inclure toutes les
données depuis les sources ou pas.</li>
<li><strong>Fin et uniquement lexical</strong> : Respectivement, la proportion de données spécifiques de chaque élément par élément collecté et
si l'élément et ses caractéristiques sont correctement indexés ou identifiés.</li>
<li><strong>Relationnel</strong> : Si la donnée collectée contient des champs communs qui pourrait permettre une intersection, ou méta-analyse,
de différents ensembles de données.</li>
<li><strong>Extensible</strong> : Si de nouveaux champs dans chaque élément de la donnée collectée peuvent être ajoutés ou changés facilement.</li>
<li><strong>Mise à l'échelle</strong> : Si la taille du système de stockage big data peut rapidement s'agrandir.</li>
</ul>
<p>L'architecture du big data est généralement multi-couche. Une architecture parallèle distribuée distribue les données à travers
de multiples serveurs, ces exécutions dans des environnements parallèles permet d'améliorer considérablement les temps de
traitements. Ce type d'architecture rentre les données dans des systèmes de gestions de bases de données parallèles, qui
implémentent l'usage du modèle de programmation <em>MapReduce</em> de Google. Le concept <em>MapReduce</em> fournit un modèle de traitement
parallèle. Les requêtes sont réparties et distribuées à travers des noeuds parallèles et traités en parallèle. Les résultats
sont ensuite récupérés, rassemblés et fournis. Ce type de framework cherche à rendre transparent le pouvoir de traitement à
l'utilisateur final en utilisant des interfaces de serveurs d'applications.</p>
<p>Le lac de données peut permettre à une organisation de changer son fusil d'épaule en passant d'un contrôle centralisé à un
modèle partagé pour répondre aux changements dynamiques de la gestion d'information.</p>
<p>Un lac de données est un système ou bibliothèque de données stockées dans leurs formats naturels/bruts, généralement des objets
blobs ou des fichiers. Un lac de données est généralement un emplacement de stockage unique de données qui incluent des copies
brutes de données système, des données de capteurs, des données sociales etc. et des données transformées utilisées pour des
tâches comme la visualisation, l'analyse et l'apprentissage automatique. Un lac de données peut inclure des données structurées
de bases de données relationnelles, semi-structurées (CSV, logs, XML, JSON), ou déstructurées (emails, documents, PDFs) et des
données binaires (images, audio, vidéo).</p>
<p>Les principaux composants qui caractérisent un écosystème big data sont les suivants :</p>
<ul>
<li>Des techniques d'analyse de données, telles que les tests A/B, l'apprentissage automatique, et le traitement automatique des
langages.  Des technologies big data, telles que l'informatique décisionnelle, l'informatique en nuage, et les bases de données.</li>
<li>Une visualisation de la donnée, à travers des diagrammes, des graphes, ou d'autres types d'affichages.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="réseau"><a class="header" href="#réseau">Réseau</a></h1>
<h4 id="introduction-4"><a class="header" href="#introduction-4">Introduction</a></h4>
<p>Ce chapitre traite de la partie réseau du programme PSE.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="topologie-de-réseau"><a class="header" href="#topologie-de-réseau">Topologie de réseau</a></h2>
<p>Une topologie de réseau est un arrangement d'éléments (liens, noeuds, etc.) dans un réseau de communication.</p>
<p>La topologie de réseau est une structure topologique d'un réseau et peut-être décrite physiquement ou logiquement. Il s'agit
d'une application de la théorie des graphes à l'intérieur de laquelle les appareils de communication sont représentés comme des
noeuds et les connexions comme des liens ou lignes entre les noeuds. La <strong>topologie physique</strong> est le placement de divers
composants d'un réseau, tandis que la <strong>topologie logique</strong> illustre les flux de données à l'intérieur d'un réseau. La distance
entre noeuds, les interconnexions physiques, les taux de transmission, ou les types de signaux peuvent varier entre deux réseaux
différents, néanmoins leurs topologies peuvent être identiques. La topologie physique d'un réseau est un problème particulier à
la couche physique du modèle OSI.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="topologies-de-réseau"><a class="header" href="#topologies-de-réseau">Topologies de réseau</a></h2>
<h3 id="liens"><a class="header" href="#liens">Liens</a></h3>
<p>Le médium de transmission utilisé pour relier des appareils afin de créer un réseau informatique inclut des cables électriques,
fibres optiques et ondes radios sont appelés <strong>liens</strong>. Dans le modèle OSI, ceux-ci sont définis au niveau de la couche physique
et de la couche liaison.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="topologies-de-réseau-1"><a class="header" href="#topologies-de-réseau-1">Topologies de réseau</a></h2>
<h3 id="noeuds"><a class="header" href="#noeuds">Noeuds</a></h3>
<p>Les noeuds d'un réseau sont les points de connexion du médium de transmission aux transmetteurs et receveurs des signaux
électriques, optiques ou radio. Ils peuvent être :</p>
<ul>
<li>Interfaces réseau : Un contrôleur d'interface réseau (NIC) est un matériel fournissant à un ordinateur la capacité d'accéder
au média de transmission. Il a la capacité de traiter des informations réseaux de bas niveau. Le NIC répond au traffic qui lui
est adressé via une adresse réseau.</li>
<li>Répéteurs et concentrateurs</li>
<li>Commutateurs : Transmet et filtre les datagrammes de la couche lien(2) du modèle OSI.</li>
<li>Routeurs : Transmet et filtre les paquets entre réseaux en traitant l'information de routage inclue dans le datagramme de la
couche réseau(3) du modèle OSI.</li>
<li>Modems</li>
<li>Pare-feux</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="topologies-de-réseau-2"><a class="header" href="#topologies-de-réseau-2">Topologies de réseau</a></h2>
<h3 id="classification"><a class="header" href="#classification">Classification</a></h3>
<p>L'étude de la topologie de réseau reconnait huit topologies basiques :</p>
<ul>
<li><strong>Point à point</strong> : La topologie réseau la plus simple avec un lien dédié entre deux points.</li>
<li><strong>Daisy chain</strong> : Accomplie en connectant chaque machine en série à la suivante.</li>
<li><strong>Bus</strong> : Chaque noeud est connecté via des connecteurs d'interface à un cable central unique.</li>
<li><strong>Étoile</strong> : Chaque noeud périphérique est connecté à un noeud central appelé concentrateur ou commutateur.</li>
<li><strong>Anneau</strong> : Daisy chain dans une boucle fermée.</li>
<li><strong>Maille</strong> : Chaque noeud est interconnecté partiellement ou totalement avec les autres noeuds du réseau.</li>
<li><strong>Arbre</strong> : Collection de réseaux étoiles arrangés hiérarchiquement.</li>
<li><strong>Hybride</strong> : Combine plusieurs topologies réseaux.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="vlan"><a class="header" href="#vlan">VLAN</a></h2>
<p>Les LANs virtuels permette de subdiviser un LAN. Linux peut accepter un traffic marqué VLAN et présenter chaque identifiant VLAN
comme une interface réseau différente.</p>
<p>Les VLANs permettent :</p>
<ul>
<li>Séparation des flux</li>
<li>Segmentation, réduction d'un domaine de broadcast</li>
<li>Isolation pour améliorer la sécurité</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="vpn"><a class="header" href="#vpn">VPN</a></h2>
<p>Un réseau privé virtuel (<em>VPN</em>) étend un réseau privé à travers un réseau public et permet aux utilisateurs d'envoyer et de
recevoir des données à travers des réseaux publics partagés comme si les ordinateurs étaient directement connectés au réseau
privé. Les bénéfices d'un VPN incluent une plus grande fonctionnalité, sécurité, et améliore la gestion du réseau privé. Il
fournit un accès à des ressources inaccessibles sur le réseau public et est généralement utilisé pour les télétravailleurs. Le
chiffrement est commun bien qu'il ne soit pas une partie inhérente d'une connexion VPN.</p>
<p>Un VPN est créé en établissant une connexion virtuelle point à point via l'usage de circuits dédiés ou à l'aide de protocoles
tunnels à travers des réseaux existants. Un VPN disponible depuis un Internet public peut fournir certains bénéfices d'un WAN.
Pour l'utilisateur, les ressources disponibles dans un réseau privé peuvent être accédées à distance.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="nas"><a class="header" href="#nas">NAS</a></h2>
<p>Un stockage attaché réseau (<em>NAS</em>) est un serveur de stockage informatique de niveau fichier (à l'instar du stockage de niveau
bloc) connecté à un réseau informatique fournissant un accès aux données à un groupe de clients hétérogènes. Un NAS est
spécialisé dans le service de fichiers soit par son matériel, son logiciel ou sa configuration. Il est souvent fabriqué en tant
qu'application matérielle - généralement une réalisation fonctionnelle d'ordinateur spécialisé. Les systèmes NAS contiennent un
ou plusieurs disques de stockage, souvent arrangés logiquement dans des conteneurs de stockage redondants ou RAID. Ils
fournissent un accès aux fichiers en utilisant des protocoles de partage réseau tels que NFS ou SMB. Les bénéfices potentiels
d'un NAS dédié, comparé à un serveur classique servant également des fichiers sont :</p>
<ul>
<li>Un accès aux données plus rapide</li>
<li>Une facilité d'administration</li>
<li>Une configuration simplifiée.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="san"><a class="header" href="#san">SAN</a></h2>
<p>Une aire de stockage réseau (<em>SAN</em>) ou stockage réseau est un réseau informatique qui fournit un accès à un stockage de données
niveau bloc consolidé. Les SANs sont utilisés principalement afin d'accéder à des périphériques de stockage de données, tels que
des baies de disques ou des bibliothèques de bandes magnétiques, depuis des serveurs, de manière à ce que ces périphériques
apparaissent au système d'exploitation comme des stockages attachés directement. Un SAN est généralement un réseau dédié aux
périphériques de stockages inaccessibles depuis le réseau local (<em>LAN</em>).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="modèle-osi"><a class="header" href="#modèle-osi">Modèle OSI</a></h2>
<p>Le modèle OSI (<em>Open Systems Interconnection</em>) est un modèle conceptuel qui caractérise et standardise les fonctions de
communication d'un système de télécommunication ou informatique de manière détachée de la structure interne sous-jacente et de
la technologie. Le but est de garantir l'interopérabilité des divers systèmes de communication à l'aide de protocoles de
communication standards.</p>
<p>Le modèle sépare le flux des données dans un système de communication en sept couches abstraites, de l'implémentation physique
de la transmission de bits à travers un médium de communication jusqu'à la plus haute représentation des données d'une
application distribuée. Chaque couche intermédiaire fournit un classe de fonctions à la couche supérieure étant elle même servie
par la couche en dessous d'elle. Ces classes de fonctionnalités sont réalisées dans le logiciel par des protocoles de
communication standardisés.</p>
<table>
    <thead>
        <tr>
            <th colspan="3">Couche</th>
            <th>Unité de protocole de données (PDU)</th>
            <th>protocoles TCP/IP</th>
            <th>Fonctions</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <th rowspan="4">Couches Hôtes</th>
            <td>7</td>
            <td>Application</td>
            <td rowspan="3">Donnée</td>
            <td>NFS</td>
            <td>APIs de haut-niveau, partages de ressources, accès de fichiers distants</td>
        </tr>
        <tr>
            <td>6</td>
            <td>Présentation</td>
            <td>MIME-SSL-TLS-XDR</td>
            <td>Traduction de données entre services réseau et une application ; encodage, compression et chiffrement</td>
        </tr>
        <tr>
            <td>5</td>
            <td>Session</td>
            <td>Sockets(établissement de session TCP/RTP/PPTP)</td>
            <td>Gestion de sessions de communications, i.e., échange continu d'information sous la forme de mulptiples
            va-et-vient de transmissions entre deux noeuds</td>
        </tr>
        <tr>
            <td>4</td>
            <td>Transport</td>
            <td>Segment, Datagramme</td>
            <td>TCP-UDP-SCTP-DCCP</td>
            <td>Transmission fiables de segments de données entre points d'un réseau, incluant la segmentation, l'acquittement
            et le multiplexage</td>
        </tr>
        <tr>
            <th rowspan="3">Couches médias</th>
            <td>3</td>
            <td>Réseau</td>
            <td>Paquet</td>
            <td>IP-IPsec-ICMP-IGMP-OSPF-RIP</td>
            <td>Structurant et gérant un réseau multi-noeuds, incluant l'adressage, le routage et le contrôle du traffic</td>
        </tr>
        <tr>
            <td>2</td>
            <td>Liaison</td>
            <td>Trame</td>
            <td>PPP-SLIP</td>
            <td>Transmissions fiables de trames de données entre deux noeuds connectés par une couche physique</td>
        </tr>
        <tr>
            <td>1</td>
            <td>Physique</td>
            <td>Bit</td>
            <td>Bluetooth-CAN bus-Ethernet Physical Layer-SMB-USB Physical Layer</td>
            <td>Transmissions et Réceptions de flux de bits à travers un médium physique</td>
        </tr>
    </tbody>
</table>
<p>Les protocoles de communication permettent à une entité sur un hôte d'interagir avec une entité correspondante sur la même
couche dans un hôte différent. La définitions des services, comme le modèle OSI, décrit de manière abstraite la fonction de la
couche (N-1) pour la couche (N), ou N est une des sept couches de protocoles opérante sur l'hôte local.</p>
<p>A chaque niveau N, deux entités d'appareils communicants (couches N pairs) échangent des unités de protocole de données (PDUs)
par le moyen de la couche protocole N. Chaque PDU contient une charge, appelée unité de service de données (SDU), ainsi que les
entêtes et pieds reliés au protocole.</p>
<p>Le processus de données entre deux appareils compatibles OSI communicants est le suivant :</p>
<ol>
<li>La donnée à transmettre est composée au niveau de la couche la plus haute de l'appareil transmetteur (couche <em>N</em>) dans une
unité de protocole de données.</li>
<li>Le <em>PDU</em> est passé à la couche <em>N-1</em>, ou il est reconnu comme une unité de service de données (<em>SDU</em>).</li>
<li>Au niveau de la couche <em>N-1</em> le <em>SDU</em> est concaténé avec une entête, un pied, ou les deux, produisant un <em>PDU de couche N-1</em>.
Il est alors envoyé à la couche <em>N-2</em>.</li>
<li>Le processus continue jusqu'à ce que la couche la plus basse soit atteinte, depuis laquelle la donnée est transmise à
l'appareil récepteur.</li>
<li>Au niveau de l'appareil récepteur, la donnée est passée de la couche la plus basse à la couche la plus haute comme une suite
de <em>SDUs</em> tandis quelle est pelée successivement de chaque entête ou pied de couche jusqu'à atteindre la couche la plus haute,
où la donnée restante est consommée.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="architecture-tcpip"><a class="header" href="#architecture-tcpip">Architecture TCP/IP</a></h2>
<p>La suite des protocoles internet est un modèle conceptuel et un ensemble de protocoles de communication utilisés par internet et
les réseaux informatiques similaires. Elle est connue plus communément sous le nom d'architecture <strong>TCP/IP</strong> du fait que les
protocoles sur lesquels elles s'appuie sont, le protocole de contrôle de transmission (TCP) et le protocole internet (IP). Son
implémentation est une pile de protocoles.</p>
<p>La suite des protocoles internet fournit une communication de données bout en bout en spécifiant comment la donnée doit être
empaquetée, adressée, transmise, routée et reçue. Cette fonctionnalité est organisée en quatre couches d'abstraction, qui
classifient tous les protocoles rattachés en fonction de l'étendue de leur implication réseau. De la couche la plus basse à la
couche la plus haute :</p>
<ul>
<li><strong>Liaison</strong> : contient des méthodes de communications pour des données appartenant à un unique segment réseau (ou lien).</li>
<li><strong>Réseau</strong> : fournit l'interconnexion entre réseaux indépendants.</li>
<li><strong>Transport</strong> : gère la communication d'hôte à hôte.</li>
<li><strong>Application</strong> : fournit l'échange de données inter-processus pour les applications.</li>
</ul>
<p>Les trois couches les plus hautes du modèle OSI, i.e. la couche application, présentation et session, ne sont pas distinguées
séparément dans l'architecture TCP/IP. Néanmoins il n'y a aucune contrainte sur le fait que la pile de protocoles TCP/IP impose
une architecture monolithique au dessus de la couche transport. Par exemple le protocole applicatif NFS fonctionne au dessus du
protocole de présentation de représentation externe de données (XDR), qui lui-même s'appuie sur le protocole d'appel de
procedures distant (RPC). RPC fournit une transmission fiable des enregistrements, de façon qu'il puisse utiliser le protocole
de transport UDP de manière sûre.</p>
<p>La fonctionnalité de la couche session peut se retrouver dans des protocoles tels que HTTP et SMTP et de manière encore plus
évidente dans Telnet et le protocole d'initialisation de session (SIP). La fonctionnalité de la couche session est également
réalisée par la numérotation de port qui appartient à la couche transport de la suite TCP/IP. Les fonctions de la couche
présentation est réalisée dans les applications TCP/IP à l'aide du standard MIME dans l'échange de données.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="protocoles"><a class="header" href="#protocoles">Protocoles</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="protocoles-1"><a class="header" href="#protocoles-1">Protocoles</a></h2>
<h3 id="couche-application"><a class="header" href="#couche-application">Couche application</a></h3>
<ul>
<li><strong>DHCP</strong> (<em>Dynamic Host Configuration Protocol</em>) : protocole des gestion réseau utilisé sur des réseaux IP, où un serveur DHCP
assigne dynamiquement des adresses IP et autres paramètres de configuration réseaux à chaque appareil, de façon à ce qu'ils
puissent communiquer avec d'autres réseaux IP. DHCP utilise le protocole UDP. (Port 67 pour le serveur, 68 pour le client)</li>
<li><strong>DNS</strong> (<em>Domain Name System</em>) : système de nommage dynamique et hiérarchisé pour appareils, services et autres ressources
connectées à Internet ou un réseau privé. DNS utilise UDP pour les requêtes de moins de 512 octets sinon il utilise TCP. (Port</li>
</ul>
<ol start="53">
<li></li>
</ol>
<ul>
<li><strong>FTP</strong> (<em>File Transfer Protocol</em>) : protocole réseau standard utilisé pour le transfert de fichiers depuis un serveur à un
client. FTP est construit sur un modèle d'architecture client-serveur en utilisant des connexions de contrôles et de données
séparées entre le client et le serveur. Les utilisateurs FTP peuvent s'authentifier eux-mêmes à l'aide d'un protocole
d'authentification en clair, généralement sous la forme d'un nom d'utilisateur et d'un mot de passe, mais ils peuvent se
connecter de manière anonyme si le serveur est configuré en ce sens. Pour des transmission sécurisées protégeant le nom
d'utilisateur et le mot de passe, et qui chiffrent le contenu, FTP est souvent sécurisé à l'aide de SSL/TLS (FTPS) ou bien
remplacé par le protocole de transfert de fichier SSH (SFTP). Le client FTP initie des connexions TCP selon différents modes.
(Port 21 pour le serveur)</li>
<li><strong>HTTP</strong> (<em>Hypertext Transfer Protocol</em>) : protocole de la couche application pour systèmes d'information distribués,
collaboratifs, hypermedia. HTTP est la base de la communication de données pour le World Wide Web, où des documents hypertextes
incluent des hyper liens pour d'autres ressources que l'utilisateur peut accéder facilement, par exemple par un click
utilisateur ou en tapant à l'écran dans un navigateur web. Le client initie une connexion TCP. (Port 80 ou 8080)</li>
<li><strong>HTTPS</strong> (<em>Hypertext Transfer Protocol Secure</em>) : est une extension de HTTP. Il est utilisé pour une communication sécurisé à
travers un réseau, et très largement répandu sur Internet. En HTTPS, le protocole de communication est crypté avec la sécurité
de la couche transport (TLS) ou, précédemment la couche de sockets sécurisée (SSL). Le protocole est par conséquent désigné
également par HTTP sur TLS, ou HTTP sur SSL. (Port 443)</li>
<li><strong>IMAP</strong> (<em>Internet Message Access Protocol</em>) : est un protocole Internet standard utilisé par les clients emails pour
récupérer les messages d'un serveur de messagerie à travers une connexion TCP/IP. (Port 143 et 993 pour IMAP sur SSL/TLS)</li>
<li><strong>LDAP</strong> (<em>Lightwight Directory Access Protocol</em>) : est un protocole applicatif standard permettant d'accéder et de maintenir
des répertoires de services d'information distribués à travers un réseau IP. Les répertoires de services jouent un rôle
important dans le développement des applications intranets et Internet en permettant le partage d'informations à propos
d'utilisateurs, de systèmes, de réseaux, de services, et d'applications à travers le réseau. LDAP utilise TCP et UDP. (Port 389
et 636 pour LDAP sur SSL/TLS)</li>
<li><strong>NFS</strong> (<em>Network File System</em>) : est un protocole de système de fichiers distribué qui permet à un ordinateur client
d'accéder à des fichiers à travers un réseau informatique. NFS comme de nombreux protocoles est construit au-dessus du protocole
ONC/RPC. NFS 3 et 4 utilisent le protocole TCP. (Port 2049 pour NFSv4)</li>
<li><strong>NTP</strong> (<em>Network Time Protocol</em>) : est un protocole qui permet de synchroniser l'horloge locale d'ordinateurs sur une
référence d'heure. NTP utilse UDP. (Port 123)</li>
<li><strong>ONC/RPC</strong> (<em>Open Networking Computing/Remote Procedure Call</em>) : est un système d'appel procedural distant. Il sérialise la
donnée à l'aide de la représentation de données externes (XDR), qui permet également le transcodage pour l'accès sur de
multiples plateformes. ONC délivre alors la charge XDR à l'aide des protocoles UDP ou TCP. (Port 111)</li>
<li><strong>RIP</strong> (<em>Routing Information Protocol</em>) : est un protocole de routage IP de type vecteur s'appuyant sur l'algorithme de
détermination des routes décentralisé Bellman-Ford. Il permet à chaque routeur de communiquer aux routeurs voisins. La métrique
utilisée est la distance qui sépare un routeur d'un réseau IP déterminé quant au nombre de sauts. RIP utilise UPD. (Port 520)</li>
<li><strong>SIP</strong> (<em>Session Initiation Protocol</em>) : est un protocole de signalisation utilisé pour initier, maintenir et terminer des
sessions en temps réel, qui inclut des applications de messageries, vocales et vidéo. Les clients SIP utilisent TCP ou UDP.
(Port 5060 et 5061 pour SIP sur SSL/TLS)</li>
<li><strong>SMTP</strong> (<em>Simple Mail Transfer Protocol</em>) : est un protocole de communication pour la transmission de mail. Les serveurs
mails et autres agents de transferts utilisent SMPT pour envoyer et recevoir des messages mails. Les serveurs SMTP utilisent le
protocole TCP. (Port 25)</li>
<li><strong>SNMP</strong> (<em>Simple Network Management Protocol</em>) : SNMP est un protocole Internet standard utiliser pour collecter et organiser
l'information liée aux appareils sur des réseaux IP et pour modifier cette information afin de définir un nouvel état de
fonctionnement. Les appareils qui typiquement supportent SNMP sont les modems, les routeurs, les switch, les serveurs, les
postes de travail, les imprimantes, etc. SNMP est utilisé très largement pour la gestion et la surveillance réseau. SNMP expose
la gestion des données sous la forme de variables sur les systèmes gérés organisées dans une base informationnelle de gestion
(MIB) qui décrit le statut de la configuration système. Ces variables peuvent être elles même requêtées à distance (et, dans
certaines circonstances manipulées) par des applications de gestion.</li>
<li><strong>SSH</strong> (<em>Secure Shell</em>) : est un protocole réseau cryptographique pour des service réseaux sécurisés opérants sur des réseaux
non-sécurisés. SSH utilise une architecture client-serveur en connectant un client SSH à un serveur. SSH utilise TCP. (Port 22)</li>
<li><strong>TLS/SSL</strong> (<em>Transport Layer Security/Secure Sockets Layer</em>) : sont des protocoles cryptographiques permettant des
communications sécurisées à travers un réseau. Le protocole TLS a pour but principal de garantir le caractère privé et
l'intégrité de la donnée entre deux applications communicantes ou plus. Une connexion entre un client et un serveur doit quand
elle est sécurisé par TLS avoir une ou plusieurs des propriétés suivantes :
<ul>
<li>La connexion est privée (ou sécurisée) par un algorithme cryptographique symétrique pour chiffrer les données transmises.
Les clefs de cette encryption symmétrique sont générées de manière unique et à chaque connexion, elle sont créées à partir
d'un secret partagé négocié au début de la session. Le serveur et le client négocient les détails de l'algorithme
cryptographique utilisé avant que le premier octet de données soit échangé. La négociation du secret partagé est à la fois
sécurisé (ne peut être attaqué à l'aide d'un connexion intermédiaire) et fiable (aucun attaquant ne peut modifier les
communications pendant le processus de négociation sans être détecté).</li>
<li>L'identité des parties en communication peut être authentifiée via une clef cryptographique publique. Cette
authentification est requise pour le serveur et optionnelle pour le client.</li>
<li>La connexion est fiable du fait que chaque message transmis inclus un message de vérification d'intégrité en utilisant un
message de code d'authentification pour prévenir les pertes non-détectées ou l'altération des données durant la transmission.
En plus des propriétés ci-dessus, un configuration TLS peut fournir des propriétés de sécurisation supplémentaires telles que la
confidentialité persistante, assurant qu'aucune découverte future des clefs cryptographiques ne puisse être utilisée pour
déchiffrer une communication TLS enregistrée par le passé.</li>
</ul>
</li>
<li><strong>XDR</strong> (<em>External Data Representation</em>) : est un standard de format de sérialisation de données qui se retrouve dans de
nombreux protocoles réseau.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="protocoles-2"><a class="header" href="#protocoles-2">Protocoles</a></h2>
<h3 id="couche-transport"><a class="header" href="#couche-transport">Couche transport</a></h3>
<ul>
<li><strong>TCP</strong> (<em>Transmission Control Protocol</em>) : est un des principaux protocoles de la suite des protocoles internet. Il a été
développé à l'origine dans l'implémentation réseau initiale pour complémenter le protocole internet (IP). Par conséquent, la
suite entière est communément connue sous le nom d'architecture TCP/IP. TCP fournit des flux d'octets vérifiés ordonnés et
fiables entre applications s'exécutant sur des hôtes communiquant via un réseau IP. TCP est orienté connexion, et une connexion
entre client et serveur est établie avant qu'une donnée puisse être envoyée. Le serveur doit écouter (ouverture passive) les
requêtes de connexion des clients avant qu'une connexion soit établie. Un handshaking en trois temps (ouverture active), une
retransmission, et une détection d'erreurs permet une grande fiabilité mais ajoute de la latence. Les applications qui ne
requièrent pas un service de flux de données fiable peuvent utiliser le protocole datagramme utilisateur (UDP), qui fournit un
service datagramme sans connexion qui priorise le temps à la fiabilité. TCP permet d'éviter la congestion réseau. Néanmoins, le
TCP est vulnérable aux attaques de déni de service, au piratage de connexion, attaque par veto TCP et redémarrage de la
connexion.</li>
<li><strong>UDP</strong> (<em>User Datagram Protocol</em>) : est un des protocoles principals de la suite des protocoles internet. UDP utilise un
modèle de communication sans connexion très simple à l'aide d'un minimum de mécanismes protocolaires. UDP fournit des sommes de
vérification pour l'intégrité des données, et des numéros de ports pour adresser différentes fonctions au niveau de la source et
de la destination du datagramme. Il ne contient pas de dialogue d'handshaking et par conséquent expose le programme utilisateur
aux problèmes éventuels de fiabilité de la connexion réseau sous-jacente ; il n'y a aucune garantie de livraison, d'ordre ni de
double protection. Si une correction d'erreur est nécessaire au niveau de l'interface réseau, une application utilisera plutôt
le protocole de contrôle de transmission (TCP) ou le protocole de transmission de contrôle de flux (SCTP) implémentés pour cet
usage. UDP est adapté aux usages où ni les contrôles ni les corrections d'erreurs ne sont nécessaires ou sont à la charge de
l'application ; UDP évite la surchage d'un tel processus dans la pile de protocole. Les applications temporellement sensibles
utilisent souvent UDP du fait qu'il est souvent préférable d'oublier des paquets plutôt que d'attendre des paquets retransmis,
ce qui peut ne pas être une option dans un système temps réel.</li>
<li><strong>DCCP</strong> (<em>Datagram Congestion Control Protocol</em>) : est un protocole orienté message. DCCP implémente une mise en place de
connexion et une déconnexion fiables, une notification de congestion explicite (ECN), un contrôle de congestion, et des
fonctionnalités de négociations.</li>
<li><strong>SCTP</strong> (<em>Stream Control Transmission Protocol</em>) : est un protocole Internet standard il permet de garder les fonctionnalités
orientées message du protocole datagramme utilisateur (UDP), tout en assurant une fiabilité et un ordonnancement des messages
ainsi que des contrôles de congestion similaires au protocole de contrôle de transmission (TCP). Contrairement à UDP et TCP, le
protocole permet le multi-homing et la redondance des chemins afin d'augmenter la résilience et la fiabilité.</li>
<li><strong>RSVP</strong> (<em>Ressource Reservation Protocol</em>) : est un protocole utilisé pour réserver des ressources à travers un réseau en
utilisant un modèle de services intégrés. RSVP opère à travers des réseaux IP et fournit une installation initiée par le
receveur pour la réservation de ressources pour des flux de données unicast ou multicast. Il est similaire à un protocole de
contrôle comme le protocole de messages de contrôles internet (ICMP) ou le protocole de gestion de groupes internet (IGMP).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="protocoles-3"><a class="header" href="#protocoles-3">Protocoles</a></h2>
<h3 id="couche-réseau"><a class="header" href="#couche-réseau">Couche réseau</a></h3>
<ul>
<li><strong>IPv4</strong> (<em>Internet Protocol v.4</em>) : est le principal protocole de communication de la suite des protocoles internet en
relayant des datagrammes à travers les frontières de réseaux. Ces fonctions de routage permettent l'agrégation de réseaux, qui
établit essentiellement Internet. IP a pour fonction de livrer des paquets depuis un hôte source à un hôte destination
uniquement via l'adresse IP contenue dans l'entête. A cette fin, IP définit des structures de paquets qui encapsulent la donnée
à envoyer. Le protocole définit également les méthodes d'adressage utiliser pour étiqueter le datagramme des informations
concernant la source et la destination. IPv4 utilise des adresses de 32-bits qui fournissent un peu plus de 4 milliards
d'adresses. Néanmoins une grande partie de ces adresses est réservée pour des méthodes réseaux spéciales.</li>
<li><strong>IPv6</strong> (<em>Internet Protocol v.6</em>) : est la version la plus récente du protocole internet (IP). IPv6 a été développé pour
résoudre le problème d'épuisement du nombre d'adresse IPv4. IPv6 utilise des adresses de 128-bits soit 3,4.10^38 adresses. Les
deux protocoles ne sont pas interopérable, de fait aucune communication entre eux n'est possible. IPv6 fournit d'autres
avantages techniques en plus du plus grand espace d'adressage. En particulier, il permet des méthodes d'allocation d'adresses
hiérarchiques qui facilite l'agrégation de routes à travers Internet, limitant l'expansion des tables de routage. L'usage de
l'adressage multicast est étendu et simplifié, il contient également d'autres optimisations pour la livraison de services. La
mobilité des appareils, la sécurité, et la configuration ont été considérés lors de la création du protocole.</li>
<li><strong>ICMP</strong> (<em>Internet Control Message Protocol</em>) : est un protocole de la suite des protocoles internet utilisé par les
matériels d'interconnexion pour envoyer des messages d'erreurs et autres informations opérationnelles indiquant la réussite ou
l'échec lors d'une communication avec une autre adresse IP. ICMP n'est pas utilisé pour envoyer des données applicatives entre
systèmes (à part pour des outils de diagnostics tels ping et traceroute).</li>
<li><strong>ECN</strong> (<em>Explicit Congestion Notification</em>) : est une extension du protocole internet (IP) et du protocole de contrôle de
transmission (TCP). ECN permet la notification bout en bout d'une congestion réseau sans oublis de paquets. ECN est une
fonctionnalité optionnelle.</li>
<li><strong>IGMP</strong> (<em>Internet Group Management Protocol</em>) : est un protocole de communication entres hôtes et routeurs adjacents pour
établir une appartenance à des groupes de multicasts. IGMP fait partie du multicast IP et permet au réseau de diriger les
transmissions multicasts uniquement aux hôtes qui les ont demandées.</li>
<li><strong>IPsec</strong> (<em>Internet Protocol Secure</em>) : est une suite de protocoles réseau sécurisée qui authentifie et chiffre les paquets
de données pour fournir une communication sécurisée à travers un réseau IP. Elle est utilisé par les réseaux privés virtuels
(VPN).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="protocoles-4"><a class="header" href="#protocoles-4">Protocoles</a></h2>
<h3 id="couche-liaison"><a class="header" href="#couche-liaison">Couche Liaison</a></h3>
<ul>
<li><strong>ARP</strong> (<em>Address Resolution Protocol</em>) : est un protocole de communication utilisé pour découvrir l'adresse de la couche
liaison, telle que l'adresse MAC, associée à une une adresse de la couche internet donnée, typiquement, une adresse IP.</li>
<li><strong>NDP</strong> (<em>Neighbor Discovery Protocol</em>) : est un protocole de la suite des protocoles internet utilisé avec le protocole
internet version 6 (IPv6). Il est responsable de la récupération d'informations diverses requises pour la communication
internet, telles que la configuration de connexions locales et les DNS et passerelles utilisées pour communiquer avec des
systèmes plus lointains. Le protocole définit 5 paquets ICMPv6 différents pour des fonctions IPv6 similaires aux découvertes et
redirection de routeurs d'ARP et de ICMP pour IPv4. Il fournit aussi de nombreuses améliorations en ce qui concerne la
robustesse des livraisons de paquets.</li>
<li><strong>OSPF</strong> (<em>Open Shortest Path First</em>) : est un protocole de routage pour les réseaux IP.</li>
<li><strong>L2TP</strong> (<em>Layer 2 Tunneling Protocol</em>) : est un protocole de tunnellisation utilisé pour créer des réseaux privés virtuels
(VPN).</li>
<li><strong>PPP</strong> (<em>Point-to-Point Protocol</em>) : est un protocole de communication entre deux routeurs, sans hôte ni aucun autre
réseautage entre. Il fournit une authentification de connexion, le chiffrement des transmissions et la compression de données.</li>
<li><strong>STP</strong> (<em>Spanning Tree Protocol</em>) : est un protocole qui permet une topologie de réseaux Ethernet sans boucles. Le but étant
de prévenir les tempêtes de broadcast. STP permet aussi d'inclure des liens redondants ce qui fournit une tolérance aux pannes
en cas d'échec des liens actifs. STP créé un arbre couvrant qui caractérise la relation entre noeuds d'un réseau et désactive
les liens qui ne font pas partie de l'arbre couvrant, laissant un unique lien actif entre 2 noeuds.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="mib"><a class="header" href="#mib">MIB</a></h2>
<p>Une base de gestion d'information (<em>MIB</em>) est une base de données utilisée pour gérer les entités d'un réseau de communication.
La plupart du temps, elle est associée au protocole <em>SNMP</em>, le terme est également utilisé plus génériquement dans les contextes
tels que les modèles de gestion réseau OSI/ISO. Bien que faisant référence à l'ensemble de la collection des informations de
gestion disponible sur une entité, le terme est souvent utilisé pour faire référence à un sous ensemble, plus correctement
appelé <em>module MIB</em>.</p>
<p>La base de donnée est hiérarchique et chaque entrée est adressée à travers un identifiant d'objet (OID).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="active-directory"><a class="header" href="#active-directory">Active Directory</a></h2>
<p>Un Active Directory (<em>AD</em>) est un service de répertorisation (nommage) développé par Microsoft pour les domaines réseaux
Windows. Il est inclus dans la plupart des systèmes d'exploitation Windows Server comme un ensemble de processus et de services.
Initialement, Active Directory était utilisé uniquement pour une gestion du domaine centralisée. Néanmoins Active Directory est
finalement devenu un nom parapluie pour un large panel de services de relation/identité basé répertoire.</p>
<p>Un serveur exécutant le service de domaine active directory (AD DS) est appelé le contrôleur de domaine. Il authentifie et
autorise tous les utilisateurs et ordinateurs dans un domaine Windows de type réseau, gérant et appliquant les politiques de
sécurité pour tous les ordinateurs, installant et mettant à jour le logiciel. Un Active Directory permet la gestion et le
stockage d'information, fournit des mécanismes d'autorisation et d'authentification, et établit un cadre pour déployer d'autres
services liés : Service de certification, service de fédération d'Active Directory, service LDAP et service de gestion des
droits.</p>
<p>Active Directory utilise LDAP, la version Microsoft de Kerberos et DNS.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="samba"><a class="header" href="#samba">Samba</a></h2>
<p>Samba est une réimplémentation libre du protocole réseau propriétaire SMB. Samba fournit des services fichiers et d'impression
pour divers clients Microsoft Windows et peut s'intégrer avec un serveur de domaine Microsoft Windows, soit en tant que
contrôleur de domaine (DC) soit en tant que membre de domaine. Depuis la version 4, il supporte les domaines Microsoft Windows
NT et Active Directory.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logiciels"><a class="header" href="#logiciels">Logiciels</a></h1>
<h4 id="introduction-5"><a class="header" href="#introduction-5">Introduction</a></h4>
<p>Ce chapitre traite de la partie logiciels du programme PSE.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="architecture-logicielle"><a class="header" href="#architecture-logicielle">Architecture logicielle</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="architecture-logicielle-1"><a class="header" href="#architecture-logicielle-1">Architecture logicielle</a></h2>
<h3 id="client-serveur"><a class="header" href="#client-serveur">Client serveur</a></h3>
<p>Le modèle client serveur est une structure d'application distribué qui sépare les tâches ou charges de travail entre
fournisseurs de ressource ou service, appelés serveurs, et les demandeurs de ce service, appelés clients. Les clients et les
serveurs communiquent souvent à travers un réseau informatique sur des matériels séparés, mais les deux peuvent également se
trouver sur la même machine. Un serveur hôte exécute un ou plusieurs programmes serveurs, qui partagent leurs ressources avec
des clients. Un client ne partage habituellement aucune de ses ressources, mais demande le contenu ou le service au serveur. Par
conséquent, les clients initient la session de communication avec les serveurs, qui attendent les requêtes entrantes.</p>
<p>La caractéristique client-serveur décrit la relation de programmes coopérants dans une application. Le composant serveur fournit
une fonction ou un service à un ou plusieurs clients, qui initient des requêtes pour de tels services. Les serveurs sont
classifiés en fonction du service qu'ils fournissent. Par exemple, un serveur web, sert des pages web pour un serveur de fichier
qui sert des fichiers informatiques. Une ressource partagée peut être n'importe quel composant électronique ou logiciel
informatique du serveur, des programmes et des données aux processeurs et périphériques de stockages. Le partage des ressources
d'un serveur constitue un <em>service</em>.</p>
<p>La condition si un ordinateur est un client, un serveur ou les deux, est déterminé par la nature de l'application qui demande
les fonctions du service. Par exemple, un seul ordinateur peut exécuter un serveur web et un logiciel serveur de fichier en même
temps pour servir différentes données aux clients effectuant diverses requêtes. Le logiciel client peut aussi communiquer avec
un logiciel serveur sur le même ordinateur. La communication entre serveurs tel que la synchronisation de données, est quelques
fois appelée communication inter-serveur ou serveur à serveur.</p>
<p>En général, un service est une abstraction de ressources informatiques et un client n'a pas à être concerné du comment le
serveur procède tandis qu'il exécute la requête et livre la réponse. Le client doit uniquement comprendre la réponse selon les
protocoles applicatifs connus, i.e. le contenu et le formatage de la donnée pour le service requis.</p>
<p>Les clients et les serveurs échangent des messages à l'aide du motif de messagerie requête-réponse. Le client envoie une
requête, et le serveur retourne une réponse. Cet échange de message est un exemple de communication inter-processus. Pour
communiquer, les ordinateurs doivent avoir un langage commun, et doivent suivre des règles communes qui doivent être définis
dans le protocole de communications. Tous les protocoles client-serveur opère au niveau de la couche application. Le protocole
de la couche application définit des motifs basiques de dialogue. Pour formaliser un peu plus loin l'échange de données, le
serveur peut implémenter une interface de programmation applicative (API). L'API est une couche d'abstraction permettant
d'accéder un service. En restreignant la communication à des contenus formatés spécifiquement, cela facilite l'analyse
syntaxique. En rendant l'accès à la donnée abstrait, on facilite l'échange de données inter-plateformes.</p>
<p>Un serveur peut recevoir de multiples clients distincts sur une période de temps très courte. Un ordinateur peut uniquement
exécuter un nombre limité de tâches à la fois, et s'appuie sur l'ordonnanceur système pour prioriser les requêtes entrantes des
clients pour les traiter. Afin de prévenir les abus et une disponibilité maximale, le logiciel serveur peut limiter la
disponibilité aux clients. Les attaques de déni de service sont conçues pour exploiter les obligations du serveur à traiter des
requêtes en le surchargeant avec un taux de requêtes excessif. Le chiffrement doit être mis en place si des données sensibles
sont communiquées entre le client et le serveur.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="architecture-logicielle-2"><a class="header" href="#architecture-logicielle-2">Architecture logicielle</a></h2>
<h3 id="trois-niveaux"><a class="header" href="#trois-niveaux">Trois niveaux</a></h3>
<p>Une <em>architecture à trois niveaux</em> ou <em>architecture trois tiers</em> ajoute un niveau supplémentaire à l'architecture à 2 niveaux,
permettant de spécialiser les serveurs dans une tâche précise, ce qui donne un avantage de flexibilité, de sécurité et de
performance :</p>
<ul>
<li>un client qui demande une ressource via une interface utilisateur chargée de la présentation de la ressource ;</li>
<li>un serveur d'application (appelé middleware) qui fournit la ressource, mais en faisant appel aux ressources d'un autre serveur
;</li>
<li>un serveur de données qui fournit au serveur d'application les ressources requises pour répondre au client.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="architecture-logicielle-3"><a class="header" href="#architecture-logicielle-3">Architecture logicielle</a></h2>
<h3 id="n-tiers"><a class="header" href="#n-tiers">N-tiers</a></h3>
<p>Une architecture à <em>N niveaux</em> ou <em>architecture N-tiers</em> n'ajoute pas de niveaux supplémentaires à l'architecture à 3 niveaux
mais introduit la notion d'objets qui offre la possibilité de distribuer les services entre les 3 niveaux selon N couches,
permettant ainsi de davantage spécialiser les serveurs.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="architecture-logicielle-4"><a class="header" href="#architecture-logicielle-4">Architecture logicielle</a></h2>
<h3 id="modèle-vue-contrôleur"><a class="header" href="#modèle-vue-contrôleur">Modèle-Vue-Contrôleur</a></h3>
<p>Modèle-vue-contrôleur est un motif d'architecture typique utilisé afin de développer des interfaces utilisateur qui sépare la
logique liée du programme en trois éléments inter-connectés. Cela est réalisé en séparant les représentations internes de
l'information des façons dont l'information est présentée et acceptée par l'utilisateur.</p>
<p>Beaucoup de langages de programmation disposent de quadriciels MVC qui facilitent son implémentation.</p>
<p>Les trois composants du motifs sont :</p>
<ul>
<li>
<p><strong>Le modèle</strong> : Le composant central. Il s'agit de la structure de données dynamique de l'application, indépendant de
l'interface utilisateur. Il gère directement la donnée, la logique et les règles de l'application. Il reçoit l'entrée
utilisateur du contrôleur.</p>
</li>
<li>
<p><strong>La vue</strong> : Une représentation de l'information (un graphique, un diagramme ou une table). Plusieurs vues de la même
information sont possibles. C'est la présentation du modèle.</p>
</li>
<li>
<p><strong>Le contrôleur</strong> : Accepte et optionnellement valide les entrées pour le modèle. Il permet l'exécution des intérations sur
les objets du modèle de données.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="haute-disponibilité"><a class="header" href="#haute-disponibilité">Haute disponibilité</a></h2>
<p>La haute disponibilité est une caractéristique d'un système qui vise à assurer un certain niveau de performance opérationnelle,
généralement l'uptime (ou durée de fonctionnement), durant une période plus longue que celle attendue habituellement.</p>
<p>Il existe trois principes de conception système en ingénierie de fiabilité permettant d'atteindre une haute disponibilité :</p>
<ul>
<li>L'élimination des points de défaillances uniques. Cela signifie ajouter ou construire une redondance dans le système pour que
la défaillance d'un composant ne signifie pas la défaillance du système en entier.</li>
<li>Fiabilité des points de croisements. Au niveau des systèmes redondants, le point de croisement lui-même tend à devenir un
point de défaillance unique. Les systèmes fiables doivent fournir des points de croisement fiables.</li>
<li>Détection des défaillances lors de leurs occurrences. Si les deux principes ci-dessus sont observés, alors un utilisateur
pourra ne jamais voir de défaillance - mais l'activité de maintenance le doit.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="langages-de-présentation"><a class="header" href="#langages-de-présentation">Langages de présentation</a></h2>
<p>Voir HTML/CSS.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation"><a class="header" href="#construction-et-automatisation">Construction et automatisation</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation-1"><a class="header" href="#construction-et-automatisation-1">Construction et automatisation</a></h2>
<h3 id="maven"><a class="header" href="#maven">Maven</a></h3>
<p>Maven est un outil d'automatisation de construction utilisé généralement pour les projets Java. Maven peut également être
utiliser pour construire et gérer des projets dans d'autres langages.</p>
<p>Maven aborde deux aspects de la construction de logiciel : comment le logiciel est construit, et ses dépendances. Contrairement
à des outils précédents tels que Ant, il utilise des conventions pour la procédure de construction. Seules les exceptions ont
besoin d'être spécifiées. Un fichier XML décrit le projet logiciel en cours de construction, ces dépendances sur d'autres
modules externes et composants, l'ordre de construction, les répertoires, et plugins requis. Il embarque des cibles prédéfinies
pour exécuter certaines tâches bien définies telles que la compilation de code et la construction de paquets. Maven télécharge
dynamiquement des bibliothèques Java et des plugins Maven d'un ou plusieurs dépôts et les stocke dans un cache local. Ce cache
local d'artefacts téléchargés peut également être mis à jour à l'aide d'artefacts créés par des projets locaux. Les dépôts
publics peuvent également être mis à jour.</p>
<p>Maven est construit en utilisant une architecture de plugins qui permet de faire usage de n'importe quelle application
contrôlable via l'entrée standard.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation-2"><a class="header" href="#construction-et-automatisation-2">Construction et automatisation</a></h2>
<h3 id="jenkins"><a class="header" href="#jenkins">Jenkins</a></h3>
<p>Jenkins est un serveur d'automatisation open source. Il aide à automatiser certaines parties du développement logiciel lié à la
construction, le test, et le déploiement, facilitant l'intégration en continu (CI) et la livraison en continu (CD). C'est un
système serveur qui fonctionne dans des conteneurs servlets tels que Tomcat. Il supporte des outils de contrôle de version et
peut exécuter des projets basés sur Ant et Maven ainsi que des scripts shell arbitraires.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation-3"><a class="header" href="#construction-et-automatisation-3">Construction et automatisation</a></h2>
<h3 id="cobbler"><a class="header" href="#cobbler">Cobbler</a></h3>
<p>Cobbler est un serveur fournisseur linux qui facilite et automatise l'installation système via le réseau de multiples systèmes
d'exploitations informatiques depuis un point central en utilisant des services tels que DHCP, TFTP et DNS. Il peut
être configuré pour l'environnement d'exécution pré-démarrage (PXE), réinstallations, et invités virtuels utilisant Xen, KVM ou
VMware. Cobbler interagit avec le programme koan pour le support de la réinstallation et de la virtualisation. Koan et Cobbler
utilisent libvirt pour s'intégrer avec différents logiciels de virtualisation.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation-4"><a class="header" href="#construction-et-automatisation-4">Construction et automatisation</a></h2>
<h3 id="puppet"><a class="header" href="#puppet">Puppet</a></h3>
<p>Puppet est un outil logiciel de gestion de configuration qui inclut son propre langage de langage déclaratif pour décrire une
configuration système. C'est une solution orienté modèle qui nécessite une connaissance limitée en programmation pour son usage.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation-5"><a class="header" href="#construction-et-automatisation-5">Construction et automatisation</a></h2>
<h3 id="ansible"><a class="header" href="#ansible">Ansible</a></h3>
<p>Ansible est un outil logiciel open source de déploiement d'application, gestion de configuration et fournisseur permettant
l'infrastructure as code (Iac). Il inclut son propre langage déclaratif pour décrire des configurations systèmes. Ansible est
sans agent, se connectant temporairement via SSH pour faire ses opérations.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation-6"><a class="header" href="#construction-et-automatisation-6">Construction et automatisation</a></h2>
<h3 id="vagrant"><a class="header" href="#vagrant">Vagrant</a></h3>
<p>Vagrant est un produit logiciel open source pour construire et maintenir des environnements de développement logiciels virtuels
portables (VirtualBox, KVM, Hyper-V, conteneurs Docker, VMware, et AWS). Il essaie de simplifier la gestion de la configuration
de virtualisation afin d'augmenter la productivité de développement.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="construction-et-automatisation-7"><a class="header" href="#construction-et-automatisation-7">Construction et automatisation</a></h2>
<h3 id="terraform"><a class="header" href="#terraform">Terraform</a></h3>
<p>Terraform est un outil logiciel open source d'infrastructure as code. Les utilisateurs définissent et fournissent
l'infrastructure en utilisant un langage de configuration déclaratif ou du JSON.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="métrologie-et-supervision-nagios"><a class="header" href="#métrologie-et-supervision-nagios">Métrologie et supervision Nagios</a></h2>
<p>Nagios Core est une application informatique open source qui supervise des systèmes, réseaux et infrastructure.
Nagios offre des services de supervision et d'alerte pour des serveurs, switch, applications et services. Il alerte les
utilisateurs quand les choses se passent mal et les alerte une seconde fois lorsque le problème a été résolu.</p>
<p>Nagios fournit :</p>
<ul>
<li>Supervision de services réseaux (SMTP, POP3, HTTP, NNTP, ICMP, SNMP, FTP, SSH)</li>
<li>Supervision de ressources hôte (charge processeur, utilisation du disque, logs système) à l'aide d'agents de supervision.</li>
<li>Supervision de matériels (sondes de température, alarmes, etc.) ayant la capacité d'envoyer les données collectées via un
réseau à des plugins écrits spécifiquement.</li>
<li>Supervision via des scripts exécutés à distance via l'exécuteur de plugin à distance Nagios.</li>
<li>Supervision à distance via des tunnels chiffrés SSL ou SSH.</li>
<li>Un simple plugin qui permet aux utilisateurs de facilement développer leurs propres vérifications de services selon leurs
besoins, en utilisant les outils de leur choix (scripts shell, C++, Perl, Ruby, Python, PHP, C#, etc.)</li>
<li>Des plugins de mise en forme des données disponibles</li>
<li>Vérification de services parallélisée etc.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environnement"><a class="header" href="#environnement">Environnement</a></h1>
<h4 id="introduction-6"><a class="header" href="#introduction-6">Introduction</a></h4>
<p>Ce chapitre traite de la partie environnement du système d'information du programme PSE.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="normalisation"><a class="header" href="#normalisation">Normalisation</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="normalisation-1"><a class="header" href="#normalisation-1">Normalisation</a></h2>
<h3 id="itil"><a class="header" href="#itil">ITIL</a></h3>
<p>ITIL (<em>Information Technology Infrastructure Library</em>) est un ensemble d'ouvrages recensant les bonnes pratiques de gestion du
système d'information.</p>
<p>C'est un référentiel méthodologique très large qui aborde les sujets suivants :</p>
<ul>
<li>Comment organiser un système d'information ?</li>
<li>Comment améliorer l'efficacité d'un système d'information ?</li>
<li>Comment réduire les risques ?</li>
<li>Comment augmenter la qualité des services informatiques ?</li>
</ul>
<p>Les recommandations d'ITIL positionnent des blocs organisationnels et des flux d'information.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="normalisation-2"><a class="header" href="#normalisation-2">Normalisation</a></h2>
<h3 id="cobit"><a class="header" href="#cobit">COBIT</a></h3>
<p>COBIT (<em>Control Objectives for Information and related Technology</em>) est un référentiel de bonnes pratiques d'audit informatique
et de gouvernance des systèmes d'information.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="notions-générales-sur-le-droit-de-linformatique"><a class="header" href="#notions-générales-sur-le-droit-de-linformatique">Notions générales sur le droit de l'informatique</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="notions-générales-sur-le-droit-de-linformatique-1"><a class="header" href="#notions-générales-sur-le-droit-de-linformatique-1">Notions générales sur le droit de l'informatique</a></h2>
<h3 id="protection-des-données-individuelles"><a class="header" href="#protection-des-données-individuelles">Protection des données individuelles</a></h3>
<p>Le règlement général sur la protection des données (RGPD) est un règlement de l'Union européenne qui constitue le texte de
référence en matière de protection des données à caractère personnel. Il renforce et unifie la protection des données pour les
individus au sein de l'Union européenne.</p>
<p>Les principaux objectifs du RGPD sont d'accroître à la fois la protection des personnes concernées par un traitement de leurs
données à caractère personnel et la responsabilisation des acteurs de ce traitement. Ces principes pourront être appliqués grâce
à l'augmentation du pouvoir des autorités de contrôle.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="notions-générales-sur-le-droit-de-linformatique-2"><a class="header" href="#notions-générales-sur-le-droit-de-linformatique-2">Notions générales sur le droit de l'informatique</a></h2>
<h3 id="lusage-de-la-messagerie"><a class="header" href="#lusage-de-la-messagerie">L'usage de la messagerie</a></h3>
<div style="break-before: page; page-break-before: always;"></div><h2 id="notions-générales-sur-le-droit-de-linformatique-3"><a class="header" href="#notions-générales-sur-le-droit-de-linformatique-3">Notions générales sur le droit de l'informatique</a></h2>
<h3 id="rôle-de-la-cnil"><a class="header" href="#rôle-de-la-cnil">Rôle de la CNIL</a></h3>
<p>La Commission nationale de l'informatique et des libertés (CNIL) est une autorité administrative indépendante française. La CNIL
est chargée de veiller à ce que l'information soit au service du citoyen et qu'elle ne porte atteinte ni à l'identité humaine,
ni aux droits de l'homme, ni à la vie privée, ni aux libertés individuelles ou publiques.</p>
<h4 id="missions-principales"><a class="header" href="#missions-principales">Missions Principales</a></h4>
<ul>
<li><strong>Informer</strong> : La CNIL est investie d'une mission générale d'information des personnes sur leurs droits et leurs obligations.
Elle aide les citoyens dans l'exercice de leurs droits. Elle établit chaque année un rapport public rendant compte de
l'exécution de sa mission.</li>
<li><strong>Réguler</strong> :  La CNIL régule et recense les fichiers, autorise les traitements les plus sensibles avant leur mise en place.
L'avis de la CNIL doit d'ailleurs être sollicité avant toute transmission au Parlement d'un projet de loi relatif à la
protection des données personnelles ; il doit aussi être sollicité par le Gouvernement avant d'autoriser les traitements
intéressant la sûreté de l'État, la défense ou la sécurité publique. La CNIL établit des normes simplifiées, afin que les
traitements les plus courants fassent l'objet de formalités allégées. Elle peut aussi décider de dispenser de toute déclaration
des catégories de traitement sans risque pour les libertés individuelles. Elle agit par voie de recommandations.</li>
<li><strong>Protéger</strong> : La CNIL doit veiller à ce que les citoyens soient informés des données contenues dans les traitements les
concernant et qu'ils puissent y accéder facilement. Elle reçoit et instruit les plaintes des personnes qui rencontrent des
difficultés à exercer leurs droits. Elle exerce, pour le compte des citoyens qui le souhaitent, l'accès aux fichiers intéressant
la sûreté de l'État, la défense et la sécurité publique, notamment des services de renseignements de la police judiciaire.</li>
<li><strong>Contrôler</strong> : La CNIL vérifie que la loi est respectée en contrôlant les traitements informatiques. Elle peut de sa propre
initiative se rendre dans tout local professionnel et vérifier sur place et sur pièce les fichiers. La Commission use de ses
pouvoirs d'investigation pour instruire les plaintes et disposer d'une meilleure connaissance de certains fichiers. La CNIL
surveille par ailleurs la sécurité des système d'information en s'assurant que toutes les précautions sont prises pour empêcher
que les données ne soient déformées ou communiquées à des personnes non autorisées.</li>
<li><strong>Sanctionner</strong> : Lorsqu'elle constate un manquement à la loi, la CNIL peut, après avoir mis en demeure les intéressés de
mettre fin à ce manquement, prononcer diverses sanctions.</li>
<li><strong>Anticiper</strong> : La CNIL doit s'attacher à comprendre et anticiper les développements des technologies de l'information afin
d'être en mesure d'apprécier les conséquences qui en résulte pour l'exercice des droits et libertés. Elle propose au
Gouvernement les mesures législatives ou réglementaires de nature à adapter la protection des libertés et de la vie privée à
l'évolution des techniques.</li>
</ul>
<h4 id="droits"><a class="header" href="#droits">Droits</a></h4>
<ul>
<li><strong>Droit d'information</strong> : Toute personne peut s'adresser directement à un organisme pour savoir si elle est fichée ou pas.</li>
<li><strong>Droit d'accès</strong> : Sauf pour les fichiers relevant du droit d'accès indirect, toute personne peut, gratuitement, sur simple
demande avoir accès à l'intégralité des informations la concernant sous une forme accessible. Elle peut également obtenir copie
moyennant le paiement, le cas échéant, des frais de reproduction.</li>
<li><strong>Droit de rectification et de radiation</strong> : Toute personne peut demander directement que les informations détenues sur elles
soient rectifiées (si elles sont inexactes), complétées ou clarifiées (si elles sont incomplètes ou équivoques), mises à jour
(si elles sont périmées) ou effacées (si ces informations ne pouvaient pas être légalement collectées par l'organisme concerné).</li>
<li><strong>Droit d'opposition</strong> : Toute personne peut s'opposer à ce qu'il soit fait un usage des informations la concernant à des fins
publicitaires ou de prospection commerciale ou que ces informations la concernant soient cédées à des tiers à telles fins. La
personne concernée doit être mise en mesure d'exercer son droit d'opposition à la cession de ses données à des tiers dès leur
collecte.</li>
<li><strong>Droit d'accès indirect</strong> : Toute personne peut demander à la CNIL de vérifier les informations la concernant éventuellement
enregistrées dans des fichiers intéressant la sûreté de l'État, la défense, ou la sécurité publique (droit d'accès indirect). La
CNIL mandate l'un de ses membres magistrats (ou anciens magistrats) afin de vérifier leur rectification ou leur suppression.
Avec l'accord du responsable du traitement, les information concernant une personne peuvent lui être communiquées.</li>
</ul>
<h4 id="obligation-des-responsables-du-traitement"><a class="header" href="#obligation-des-responsables-du-traitement">Obligation des responsables du traitement</a></h4>
<ul>
<li>Notifier la mise en oeuvre du fichier de ses caractéristiques à la CNIL, sauf cas de dispense prévus par la loi ou par la
CNIL.</li>
<li>Mettre les personnes concernées en mesure d'exercer leur droits en les informant.</li>
<li>Assurer la sécurité des informations afin d'empêcher qu'elles soient déformées, endommagées ou que des tiers non autorisés n'y
ait accès. La loi prévoit une obligation de mesures techniques et d'organisation, un obligation de moyens, dénuée d'obligation
de résultat.</li>
<li>Se soumettre aux contrôles et vérifications sur place de la CNIL et répondre à toute demande de renseignement qu'elle formule
dans le cadre de ses missions.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="notions-générales-sur-le-droit-de-linformatique-4"><a class="header" href="#notions-générales-sur-le-droit-de-linformatique-4">Notions générales sur le droit de l'informatique</a></h2>
<h3 id="licences"><a class="header" href="#licences">Licences</a></h3>
<p>Une licence de logiciel est un contrat par lequel le titulaire des droits d'auteur sur un programme informatique définit avec
son cocontractant (exploitant ou utilisateur) les conditions dans lesquelles ce programme peut être utilisé ou modifié.</p>
<p>Une licence peut être :</p>
<ul>
<li><strong>nominative ou fixe</strong> : conçue pour être installée sur un ordinateur particulier.</li>
<li><strong>flottante</strong> : fonctionne à l'aide d'un serveur de licences. Celui-ci décompte le nombre de licences utilisées à un instant T
sur le réseau.</li>
<li><strong>shareware</strong> : ou partagiciel, attribue un droit temporaire et/ou avec des fonctionnalités limitées d'utilisation. Après
cette période d'essai, l'utilisateur devra rétribuer l'auteur pour continuer à utiliser le logiciel ou avoir accès à la version
complète.</li>
<li><strong>libre</strong> : qui donnent le droit d'usage de l'oeuvre, d'étude de l'oeuvre pour en comprendre le fonctionnement ou l'adapter à
ces besoins, de modification et de redistribution de l'oeuvre et des oeuvres dérivées, c'est à dire sa diffusion à d'autres
usages, y compris commercialement.</li>
<li><strong>propriétaire</strong> : ne permet pas légalement ou techniquement, ou par quelque autre moyen que ce soit d'exercer simultanément
les quatre libertés logicielles.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="organisation-du-travail"><a class="header" href="#organisation-du-travail">Organisation du travail</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="organisation-du-travail-1"><a class="header" href="#organisation-du-travail-1">Organisation du travail</a></h2>
<h3 id="méthode-agile"><a class="header" href="#méthode-agile">Méthode agile</a></h3>
<p>Dans le développement logiciel, les pratiques Agile incluent :</p>
<ul>
<li>une découverte des besoins,</li>
<li>des solutions d'amélioration à travers l'effort collaboratifs d'équipes transverses et auto-organisées avec leurs
clients/utilisateurs finaux,</li>
<li>une planification adaptative,</li>
<li>un développement évolutionnaire,</li>
<li>une livraison rapide,</li>
<li>une amélioration en continu,</li>
<li>des réponses flexibles aux changement de besoins,</li>
<li>une capacité et une compréhension des problèmes à résoudre.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="organisation-du-travail-2"><a class="header" href="#organisation-du-travail-2">Organisation du travail</a></h2>
<h3 id="devops"><a class="header" href="#devops">Devops</a></h3>
<p>Devops est un ensemble de pratiques qui combine développement logiciel (<em>Dev</em>) et informatique technique opérationnelle
(<em>Ops</em>). Il a pour but de réduire la durée des cycles de vie des développements systèmes et de permettre une livraison en
continu (<em>CD</em>) de logiciel de qualité. Devops est complémentaire du développement logiciel Agile ; certains aspects
sont issus de la méthodologie Agile.</p>
<p>Du fait que Devops se veut être une méthode de travail transverse, ceux qui pratiquent la méthodologie utilisent différents
ensembles d'outils - appelé chaîne d'outil - plutôt qu'un outil unique. Ces chaînes d'outils doivent correspondre à l'une ou
plusieurs des catégories suivantes, qui reflètent les aspects clefs des processus du développement et de la livraison.</p>
<ol>
<li>Code - le développement et la vérification du code, les outils de gestion du code source, la fusion de code.</li>
<li>Construction - les outils d'intégration continue, le statut de construction.</li>
<li>Test - les outils de tests en continu qui fournissent un retour rapide sur les risques opérationnels.</li>
<li>Empaquetage - Dépôt logiciel, mise à disposition de l'application pré-déploiement.</li>
<li>Publication - gestion des changements, approbation et automatisation des publications.</li>
<li>Configuration - configuration et gestion d'infrastructure, outils d'infrastructure as code.</li>
<li>Surveillance - applications de surveillance des performances, expérience de l'utilisateur final.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="fonctions-de-pse"><a class="header" href="#fonctions-de-pse">Fonctions de PSE</a></h2>
<h3 id="disi"><a class="header" href="#disi">DISI</a></h3>
<ul>
<li>Veiller à l'optimisation des performances des matériels et à celle du taux de disponibilité du système informatique.</li>
<li>Assurer la gestion des sécurités d'accès et des sauvegardes, ainsi que l'administration des bases de données.</li>
<li>Assurer la mise en oeuvre d'automates d'exploitation et de programmes utilitaires.</li>
<li>Exercer des missions d'assistance et de conseil des équipes d'exploitation.</li>
<li>Exercer un support technique pour les cellules d'assistance directe et pour l'administration des configurations informatiques
implantées dans les services locaux.</li>
</ul>
<h3 id="service-centraux"><a class="header" href="#service-centraux">Service centraux</a></h3>
<ul>
<li>Participer à la conception technique des systèmes de données et de traitements afin d'optimiser l'usage du système
informatique et préparer les modalités de mise en exploitation.</li>
<li>Procéder aux études préalables, aux acquisitions de matériels informatiques et de logiciels système.</li>
<li>Participer aux travaux sur les systèmes gros systèmes, X86, plateformes virtualisées et Cloud.</li>
<li>Gérer les techniques de cette exploitation ainsi que le suivi et l'environnement de cette exploitation.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="plan-de-secours"><a class="header" href="#plan-de-secours">Plan de secours</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="plan-de-secours-1"><a class="header" href="#plan-de-secours-1">Plan de secours</a></h2>
<h3 id="plan-de-continuité-dactivité"><a class="header" href="#plan-de-continuité-dactivité">Plan de continuité d'activité</a></h3>
<p>Un plan de continuité d'activité (PCA), a pour but de garantir la survie de l'entreprise en cas de sinistre important touchant
le système informatique. Il s'agit de redémarrer l'activité le plus rapidement possible avec le minimum de perte de données. Ce
plan est un des points essentiels de la politique de sécurité informatique d'une entreprise.</p>
<p>Pour qu'un plan de continuité soit réellement adapté aux exigences de l'entreprise, il doit reposer sur une analyse de risque et
une analyse d'impact :</p>
<ul>
<li><strong>L'analyse de risque</strong> débute par une identification des menaces sur l'informatique. Les menaces peuvent être internes ou
externes à l'entreprise. On déduit ensuite le risque qui découle des menaces identifiées ; on mesure l'impact possible de ces
risques. Enfin, on décide de mettre en oeuvre des mesures d'atténuation des risques en se concentrant sur ceux qui ont un impact
significatif. Par exemple, si le risque de panne d'un équipement risque de tout paralyser, on installe un équipement redondant.
Les mesures d'atténuation de risque qui sont mises en oeuvre diminuent le niveau de risque, mais elles ne l'annulent pas : il
subsiste toujours un risque résiduel, qui sera couvert soit par le plan de continuité, soit par d'autres moyens (assurance,
voire acceptation du risque).</li>
<li><strong>L'analyse d'impact</strong> consiste à évaluer quel est l'impact d'un risque qui se matérialise et à déterminer à partir de quand
cet impact est intolérable, généralement parce qu'il met en danger les processus essentiels (donc, la survie) de
l'entreprise.L'analyse d'impact se fait sur la base de désastres : on considère des désastres extrêmes voire improbables (par
exemple, la destruction totale du bâtiment) et on détermine les impacts financiers, humains, légaux, etc., pour des durées
d'interruption de plus en plus longues jusqu'à ce qu'on atteigne l'impact maximal tolérable. Le résultat principal de l'analyse
d'impact est donc une donnée temporelle : c'est la durée maximale admissible d'une interruption de chaque processus de
l'entreprise. En tenant compte des ressources informatiques (réseaux, serveurs, PCs, etc.) dont chaque processus dépend, on peut
déduire le temps maximal d'indisponibilité de chacune de ces ressources, en d'autres termes, le temps maximal après lequel une
ressource informatique doit avoir été remise en fonction.</li>
</ul>
<p>Une analyse de risque réussie est le résultat d'une action collective impliquant tous les acteurs du système d'information :
techniciens, utilisateurs et managers.</p>
<p>Il existe plusieurs méthodes pour assurer la continuité de service d'un système d'information. Certaines sont techniques (choix
des outils, méthodes de protection d'accès et de sauvegarde des données), d'autres reposent sur le comportement individuel des
utilisateurs (extinction des postes informatiques après usage, utilisation raisonnable des capacités de transfert
d'informations, respect des mesures de sécurité); sur des règles et connaissances collectives (protection incendie, sécurité
d'accès aux locaux, connaissance de l'organisation informatique interne de l'entreprise) et de plus en plus sur des conventions
passées avec des prestataires (copie des programmes, mise à disposition de matériel de secours, assistance au dépannage).</p>
<p>Les méthodes se distinguent entre préventives (éviter la discontinuité) et curatives (rétablir la continuité après un sinistre).
Les méthodes préventives sont souvent privilégiées, mais décrire les méthodes curatives est une nécessité car aucun système
n'est fiable à 100%.</p>
<p>La préservation des données passe par des copies de sauvegarde régulières. Il est important de ne pas stocker ces copies de
sauvegarde à côté du matériel informatique, voire dans la même pièce car elles disparaîtraient en même temps que les données à
sauvegarder en cas d'incendie, de dégât des eaux, de vol, etc. Lorsqu'il est probable que les sauvegardes disparaissent avec le
matériel, le stockage des copies de sauvegarde peut alors être nécessaire dans un autre lieu différent et distant.</p>
<p>L'analyse d'impact a fourni des exigences exprimées en temps maximal de rétablissement des ressources après un désastre (RTO :
<em>Recovery Time Objective</em> ou Durée maximale d'interruption admissible) et la perte maximale de données (RPO : <em>Recovery Point
Objective</em> ou Perte de données maximale admissible). La stratégie doit garantir que ces exigences seront observées.</p>
<p>Il s'agit de disposer d'un système informatique équivalent à celui pour lequel on veut limiter l'indisponibilité : ordinateurs,
périphériques, systèmes d'exploitation, programmes particuliers, etc. Une des solutions consiste à créer et maintenir un <strong>site
de secours</strong>, contenant un système en ordre de marche capable de prendre le relais de système défaillant. Selon que le système
de secours sera implanté sur le site d'exploitation ou sur un lieu géographiquement différent, on parlera d'un secours <em>in situ</em>
ou <em>déporté</em>.</p>
<p>Pour répondre aux problématiques de recouvrement de désastre, on utilise de plus en plus fréquemment des sites délocalisés,
c'est à dire physiquement séparés des utilisateurs de plusieurs centaines de mètres à plusieurs centaines de kilomètres : plus
le site est éloigné, moins il risque d'être touché par un désastre affectant le site de production. Mais la solution étant
d'autant plus chère, car la bande passante qui permet de transférer des données d'un site vers l'autre est alors généralement
plus coûteuse et risque d'être moins performante. Cependant la généralisation des réseaux longues distances et la baisse des
coûts de transmission rendent moins contraignante la notion de distance : le coût du site ou la compétence des opérateurs (leur
capacité à démarrer le secours rapidement et de rendre l'accès aux utilisateurs) sont d'autres arguments de choix.</p>
<p>Les sites de secours (<em>in situ</em> ou déportés) se classent selon les types suivants :</p>
<ul>
<li><strong>salle blanche</strong> (une salle machine protégée par des procédure d'accès particulières, généralement secourue électriquement).
Par extension on parle de <em>salle noire</em> pour une salle blanche entièrement pilotée à distance, sans aucun opérateur à
l'intérieur.</li>
<li><strong>site chaud</strong> : site de secours où l'ensemble des serveurs et autres systèmes sont allumés, à jour, interconnectés,
paramétrés, alimentés à partir des données sauvegardées et prêt à fonctionner. Le site doit aussi fournir l'ensemble des
infrastructures pour accueillir l'ensemble du personnel à tout moment et permet une reprise de l'activité dans des délais
relativement courts (quelques heures). Un tel site revient quasiment à doubler les capacités informatiques de l'entreprise (on
parle de <strong>redondance</strong>) et présente donc un poids budgétaire non négligeable.</li>
<li><strong>site froid</strong> : site de secours qui peut avoir une autre utilisation en temps normal. Les serveurs et autres systèmes sont
stockés mais non installés, connectés, etc. Lors d'un sinistre, un important travail doit être effectué pour mettre en service
le site ce qui conduit à des temps de reprise long (quelques jours). Mais sont coût de fonctionnement, hors période d'activation
est faible voire nul.</li>
</ul>
<p>Il est aussi possible d'utiliser des systèmes distribués sur plusieurs sites (diminution du risque de panne par effet de
foisonnement) ou un <strong>site de secours mobile</strong>.</p>
<p>Plus les temps de rétablissement garantis sont courts, plus la stratégie est coûteuse. Il faut donc choisir la stratégie qui
offre le meilleur équilibre entre le coût et la rapidité de reprise.</p>
<p>D'autre part pour des problème de haute disponibilité on a recours aussi à de la redondance mais de manière plus locale.</p>
<ul>
<li>Doublement d'alimentation des baies des serveurs</li>
<li>Redondance des disques en utilisant la technologie RAID</li>
<li>Redondance de serveurs avec des systèmes de répartition de charge ou de <em>heartbeat</em> (un serveur demande régulièrement sur le
réseau si son homologue est en fonctionnement et lorsque l'autre serveur ne répond pas, le serveur de secours prend le relais).</li>
</ul>
<p>Il est aussi possible de recourir à un site secondaire de haute disponibilité qui se situe généralement près du site de
production (moins de 10km) afin de permettre de les relier avec de la fibre optique et synchroniser les données des deux sites
quasiment en temps réel de manière synchrone ou asynchrone selon les technologies utilisées, les besoins et les contraintes
techniques.</p>
<p>Quel que soit le degré d'automatisation et de sécurisation d'un système informatique, la composante humaine reste un facteur
important. Pour limiter le risque de panne, les acteurs d'un service informatique doivent adopter les comportements les moins
risqués pour le système et éventuellement savoir accomplir des gestes techniques.</p>
<ul>
<li>Pour les utilisateurs, il s'agit :
<ul>
<li>de respecter les normes d'utilisation de leurs ordinateurs : n'utiliser que les applications référencées par les
mainteneur du SI, ne pas surcharger les réseaux par des communications inutiles, respecter la confidentialité des codes
d'accès.</li>
<li>de savoir reconnaître les symptômes d'une panne (distinguer un blocage d'accès d'un délai de réponse anormalement long par
exemple) et savoir en rendre compte le plus vite possible.</li>
</ul>
</li>
<li>Pour les opérateurs du SI, il s'agit d'avoir la meilleure connaissance du système en terme d'architecture (<em>cartographie</em> du
SI) et de fonctionnement (en temps réel si possible), de faire régulièrement les sauvegardes et de <strong>s'assurer qu'elles sont
utilisables</strong>.</li>
<li>Pour les responsables, il s'agit de faire les choix entre réalisations internes et prestations externes de manière à couvrir
en totalité le champ des actions à conduire en cas de panne, de passer les contrats avec les prestataires, d'organiser les
relations entre les opérateurs du SI et les utilisateurs, de décider et mettre en oeuvre les exercices de secours, y compris le
retour d'expérience.</li>
</ul>
<p>Selon la gravité du sinistre et la criticité du système en panne, les mesures de rétablissement seront différentes.</p>
<p>Dans l'hypothèse de la reprise de données, seules des données ont été perdues. L'utilisation des sauvegardes est nécessaire et
la méthode consiste à réimplanter le dernier jeu de sauvegardes. Cela peut se faire dans un laps de temps relativement court, si
l'on a bien identifié les données à reprendre et si les méthodes et outils de réimplantation sont accessibles et connus.</p>
<p>A un seuil de panne, plus important, une ou des applications sont indisponibles. L'utilisation d'un site de secours est
envisageable, le temps de rendre disponible l'application en cause.</p>
<p>Le redémarrage des machines :</p>
<ul>
<li>provisoire : utilisation des sites de secours</li>
<li>définitif : après dépannage de la machine d'exploitation habituelle, y rebasculer les utilisateurs, en s'assurant de ne pas
perdre de données et si possible de ne pas déconnecter les utilisateurs.</li>
</ul>
<p>Le plan de reprise contient les informations suivantes :</p>
<ul>
<li>La composition et le rôle des équipes de pilotage du plan de reprise. Ces équipes se situent au niveau stratégique :
<ol>
<li>les dirigeants qui ont autorité pour engager des dépenses ;</li>
<li>le porte-parole responsable des contacts avec les tiers ;</li>
<li>au niveau tactique, les responsables qui coordonnent les actions ;</li>
<li>au niveau opérationnel, les hommes de terrain qui travaillent sur le site sinistré et sur le site de remplacement.</li>
</ol>
</li>
</ul>
<p>La composition de ces équipes doit être connue et à jour, ainsi que les personnes de remplacement et les moyens de les prévenir.
Les membres des équipes doivent recevoir une formation.</p>
<ul>
<li>Les procédures qui mettent la stratégie en oeuvre. Ceci inclut les procédures d'intervention immédiate ;</li>
<li>Les procédures pour rétablir les services essentiels, y compris le rôle des prestataires externes ;</li>
<li>Les procédures doivent être accessibles aux membres des équipes de pilotage, même en cas d'indisponibilité des bâtiments.</li>
</ul>
<p>Le plan doit être régulièrement essayé au cours d'exercices. Un exercice peut être une simple revue des procédures,
éventuellement un jeu de rôles entre les équipes de pilotage. Un exercice peut aussi être mené en grandeur réelle, mais peut se
limiter à la reprise d'une ressource (par exemple un serveur principal), ou à une seule fonction du plan (par exemple la
procédure d'intervention immédiate). Le but de l'exercice est multiple :</p>
<ul>
<li>Vérifier que les procédures permettent d'assurer la continuité d'activité</li>
<li>Vérifier que le plan est complet et réalisable</li>
<li>Maintenir un niveau de compétence suffisant parmi les équipes de pilotage</li>
<li>Évaluer la résistance au stress des équipes de pilotage</li>
</ul>
<p>Un plan doit aussi être revu et mis à jour régulièrement pour tenir compte de l'évolution de la technologie et des objectifs de
l'entreprise. La seule façon efficace de mettre à jour le PCA est d'en sous traiter la maintenance aux métiers afin qu'il soit
réactualisé à chaque réunion mensuelle de service.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="plan-de-secours-2"><a class="header" href="#plan-de-secours-2">Plan de secours</a></h2>
<h3 id="plan-de-reprise-dactivité"><a class="header" href="#plan-de-reprise-dactivité">Plan de reprise d'activité</a></h3>
<p>Un plan de reprise d'activité (PRA) constitue l'ensemble des procédures documentées lui permettant de rétablir et de reprendre
ses activités en s'appuyant sur des mesures temporaires adoptées pour répondre aux exigences métier habituelles après un
incident.</p>
<p>Le plan de reprise d'activité comprend les tâche suivantes :</p>
<ul>
<li>Identification des activités critiques ;</li>
<li>Identification des ressources ;</li>
<li>Identification des solutions pour le maintien des activités critiques.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction-au-shell"><a class="header" href="#introduction-au-shell">Introduction au Shell</a></h1>
<h4 id="introduction-7"><a class="header" href="#introduction-7">Introduction</a></h4>
<p>Ce chapitre supplémentaire ne fait pas à proprement parler partie du programme mais est une introduction au shell.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="quest-ce-que-le-shell-"><a class="header" href="#quest-ce-que-le-shell-">Qu'est-ce que le shell ?</a></h2>
<p>Le Shell est un programme qui permet d'interpréter les commandes de l'utilisateur. C'est l'un des tout premiers moyens
d'interagir avec un ordinateur. Le shell est généralement plus puissant qu'une interface graphique utilisateur (GUI), dans le
sens où il permet d'accéder très efficacement aux fonctionnalités internes du système d'exploitation (OS).</p>
<p>Souvent les outils textuels dont il dispose sont construits de manière à pouvoir être composés. Ainsi de multiples assemblages
permettent à la fois une simplicité dans la décomposition des tâches, et une facilité de mise en oeuvre dans l'automatisation.</p>
<p>Les shells peuvent généralement dépendre des OS, sachant qu'il en existe une quantité pour chacun d'entre eux. Dans le cas de
Linux, le Bourne Again Shell ou bash est très largement répandu. C'est celui qui va nous intéresser ici.</p>
<p>Quand on ouvre un terminal, une fenêtre s'ouvre affichant un prompt shell. Dans le cadre du bash si aucune personnalisation n'a
été faite il se décompose ainsi :</p>
<pre><code class="language-bash ignore">    [utilisateur@machine répertoire\ de\ travail]$
</code></pre>
<p>Généralement un shell est fait pour passer des commandes, c'est à dire, exécuter des programmes avec ou sans arguments :</p>
<pre><code class="language-bash ignore">    $ date
    sam. 09 mai 2020 17:36:09 CEST
</code></pre>
<p>L'ajout de certains arguments permet de modifier le comportement de certains programmes. La commande <em>echo</em> permet par exemple
d'afficher à l'écran les arguments qui la suivent. Un argument est une chaîne de caractère séparée du nom du programme par un
espace :</p>
<pre><code class="language-bash ignore">    $ echo hello
    hello
</code></pre>
<p>Si l'on souhaite que l'argument contiennent lui-même un espace, et éviter d'ajouter un deuxième argument il suffit d'entourer la
chaîne de guillemets :</p>
<pre><code class="language-bash ignore">    $ echo &quot;Hello world!&quot;
    Hello world!
</code></pre>
<p>On peut également échapper le caractère espace à l'aide d'un antislash : $ echo Hello\ world!  Hello world!</p>
<blockquote>
<p>Exemple pour créer un répertoire Mes photos on écrit : <em>mkdir Mes\ photos</em></p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h2 id="les-chemins"><a class="header" href="#les-chemins">Les chemins</a></h2>
<p>Le shell sait quel programme (dont un certain nombre sont installés avec l'OS) utiliser et où celui-ci se situe dans le système
de fichiers à l'aide de ce que l'on appelle une variable d'environnement. Une variable connue et renseignée dès le lancement du
shell. Il s'agit de la variable PATH :</p>
<pre><code class="language-bash ignore">    $ echo $PATH
    /usr/local/sbin:/usr/local/bin:/usr/bin
</code></pre>
<p>Il s'agit d'une liste des chemins ordonnée dans lequel le shell va chercher les programmes.</p>
<p>La commande which permet de savoir dans quel répertoire se trouve le programme passé en argument, lequel sera celui exécuté lors
de l'appel par ce shell précisément :</p>
<pre><code class="language-bash ignore">    $ which echo
    /usr/bin/echo
</code></pre>
<p>Les chemins sont la description des emplacements des fichiers dans l'architecture du système de fichiers. Sur Linux et MacOS,
les répertoires sont séparés par des slash. Le premier slash sur la gauche symbolise le sommet du système de fichiers (celui-ci
étant hiérarchique) il est appelé root ou répertoire root, racine en français. Sous Windows les répertoires sont généralement
séparés par des antislash et chaque partition est la racine de son propre système de fichier hiérarchique. La partition est
généralement désignée par une lettre de l'alphabet (C:\ D:\ etc.).</p>
<p>Il existe 2 types de chemins :</p>
<ul>
<li>les chemins absolus : à partir de la racine.</li>
<li>les chemins relatifs : à partir du répertoire dans lequel on se situe.</li>
</ul>
<p>Pour savoir dans quel répertoire on se trouve actuellement il existe la commande <em>pwd</em> pour <em>print working directory</em> (affiche
le répertoire de travail) :</p>
<pre><code class="language-bash ignore">    $ pwd
    /home/hugo
</code></pre>
<p>A partir d'ici on peut changer de répertoire de travail avec la commande cd et, en argument un chemin relatif ou absolu :</p>
<pre><code class="language-bash ignore">    $ cd /home

    $ pwd
    /home
</code></pre>
<p>Il existe un certain nombre de symboles permettant &quot;d'expanser&quot; des noms de répertoires :</p>
<ul>
<li><strong>~</strong> : le répertoire de l'utilisateur courant (ie : /home/hugo)</li>
<li><strong>.</strong> : le répertoire de travail</li>
<li><strong>..</strong> : le répertoire parent du répertoire de travail</li>
<li><strong>-</strong> : l'ancien répertoire de travail</li>
</ul>
<p>Par exemple :</p>
<pre><code class="language-bash ignore">    $ cd ~/test/

    $ pwd
    /home/hugo/test

    $ cd ../../

    $ pwd
    /home

    $ cd -

    $ pwd
    /home/hugo/test
</code></pre>
<p>Cela permet de naviguer plus facilement à l'intérieur du système de fichiers.</p>
<blockquote>
<p>Note : Dans le cas de script shell, lors de l'appel d'un programme on évite les chemins relatifs. On préfère travailler avec
la variable d'environnement PATH ou bien on donne le chemin absolu.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h2 id="lister-le-contenu-dun-répertoire-et-droits"><a class="header" href="#lister-le-contenu-dun-répertoire-et-droits">Lister le contenu d'un répertoire et droits</a></h2>
<p>Par défaut (sans argument) un programme agit sur le répertoire de travail. Il est alors généralement intéressant de savoir que
contient ce répertoire. La commande ls permet de lister le contenu d'un répertoire.</p>
<pre><code class="language-bash ignore">    $ ls file1  file2  file3

    $ ls ../../ bleu rouge vert
</code></pre>
<p>Dans le cas de l'utilisation de certains programmes il peut être utile de connaître les arguments que l'utilitaire accepte. La
plupart des programmes implémentent des flags et des options. Un des flags les plus utiles est --help :</p>
<pre><code class="language-bash ignore">    $ ls --help
</code></pre>
<p>permet d'afficher l'aide de la commande <em>ls</em>.</p>
<p>Pour lire les usages, <em>...</em> signifie 1 ou plus et <em>[ ]</em> signifie que ce qui est dans les crochets est optionnel. En suit
généralement une brève description de la commande et à la suite les potentiels flags disponibles.</p>
<pre><code class="language-bash ignore">    $ ls -l
</code></pre>
<p>permet de lister au format long avec un nombre bien plus important d'information :</p>
<ul>
<li>le type de fichiers</li>
<li>les droits : utilisateur propriétaire, groupe principal du propriétaire, autres (user, group, others)</li>
<li>le nombre d'inodes (hard links)</li>
<li>l'utilisateur propriétaire</li>
<li>le groupe principal du propriétaire</li>
<li>le mtime (modification time)</li>
<li>le nom du fichier</li>
</ul>
<p>Les droits s'organisent ainsi :</p>
<ul>
<li>pour les fichiers
<ul>
<li>r : read, autorise à lire le contenu du fichier w : write, autorise à modifier le contenu du fichier x : execute, autorise
l'exécution du fichier</li>
</ul>
</li>
<li>pour les répertoires
<ul>
<li>r : read, autorise à lister le contenu du répertoire w : write, autorise la création de fichier, la modification du nom de
fichier et la suppression de fichier x : execute, autorise à traverser (entrer) dans le répertoire</li>
</ul>
</li>
</ul>
<p>Enfin le - présenté par la commande :</p>
<pre><code class="language-bash ignore">    $ ls -l
</code></pre>
<p>signifie l'absence du droit.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="dautres-commandes"><a class="header" href="#dautres-commandes">D'autres commandes</a></h2>
<p>La commande mv permet de renommer et/ou (non exclusif) déplacer un fichier:</p>
<pre><code class="language-bash ignore">    $ mv fichier_a_renommer ../../nouveau_fichier
</code></pre>
<p>La commande cp permet de copier un fichier :</p>
<pre><code class="language-bash ignore">    $ cp original ~/copie
</code></pre>
<p>La commande rm permet de supprimer un fichier :</p>
<pre><code class="language-bash ignore">    $ rm ~/copie
</code></pre>
<p>Par défaut la commande <em>rm</em> n'est pas récursive. Pour cela il est nécessaire d'ajouter le flag <em>-r</em> suivi du répertoire. La
commande <em>rmdir</em> permet également de supprimer un répertoire mais seulement si celui-ci est déjà vide.</p>
<p>Finalement pour créer un nouveau répertoire on utilise la commande :</p>
<pre><code class="language-bash ignore">    $ mkdir Mon\ Repertoire
</code></pre>
<p>Pour avoir encore plus d'informations sur une commande on peut se référer aux pages de manuel de celle-ci :</p>
<pre><code class="language-bash ignore">    $ man ls
</code></pre>
<p>Cela permet généralement d'avoir une meilleure vision de ce que fait la commande, avec une navigation facilitée.</p>
<blockquote>
<p>Note : Pour quitter le programme <em>man</em>, il suffit de presser la lettre <em>q</em>.</p>
</blockquote>
<p>Pour nettoyer le terminal on peut exécuter la commande :</p>
<pre><code class="language-bash ignore">    $ clear
</code></pre>
<p>ou plus facilement presser Ctrl + L.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="redirection-dentréesortie-descripteurs-de-fichiers-et-tubes"><a class="header" href="#redirection-dentréesortie-descripteurs-de-fichiers-et-tubes">Redirection d'entrée/sortie, descripteurs de fichiers et tubes</a></h2>
<p>Comme il a été évoqué plus haut, l'une des caractéristiques les plus importantes du shell est qu'il permet l'assemblage de
multiples programmes via des flux. Cela permet de combiner les fonctionnalités de différents programmes afin d'exécuter une
tâche spécifique.</p>
<p>Pour interagir avec ces flux le bash dispose de descripteurs de fichiers ou fd (pour file descriptor). Ceux-ci sont des chiffres
utilisés comme référence abstraite vers un fichier ou une ressource d'entrée/sortie (e.g pipe, IPC etc.) Le terme de fichier est
ici très large également (physique, virtuel, périphérique etc.)</p>
<p>Par défaut 3 ressources disposant de fd sont ouverts :</p>
<ul>
<li>le stdin ou (entrée standard) : fd 0, qui est saisi au clavier</li>
<li>le stdout ou (sortie standard) : fd 1, qui est affiché dans le terminal</li>
<li>le stderr ou (erreur standard) : fd 2, qui est affiché dans le terminal</li>
</ul>
<p>Pour alimenter l'entrée standard à l'aide du contenu d'un fichier, on utilise le chevron gauche :</p>
<pre><code class="language-bash ignore">    $ ma_commande &lt; nom_fichier
</code></pre>
<p>Pour vider le contenu de la sortie standard dans un fichier, on utilise le chevron droit :</p>
<pre><code class="language-bash ignore">    $ ma_commande &gt; nom_fichier
</code></pre>
<blockquote>
<p>Note : Si aucun chiffre de descripteur ne préfixe les chevrons, ce sera le stdin (0) pour un gauche et le stdout (1) pour un
droit.</p>
</blockquote>
<p>Dans ce cas précis, uniquement la sortie d'erreur standard sera affichée dans le terminal. Dans ce cas précis également, le
contenu préexistant au fichier est écrasé, ce qui peut être pratique si l'on souhaite vider un fichier ou créer un fichier vide
on peut exécuter la commande :</p>
<pre><code class="language-bash ignore">    $ &gt; nom_fichier
</code></pre>
<p>Pour ajouter le flux au fichier on utilise le double chevron :</p>
<pre><code class="language-bash ignore">    $ ma_commande &gt;&gt; nom_fichier
</code></pre>
<p>Si l'on souhaite conserver cette sortie d'erreur dans un fichier il faut préciser le descripteur de fichier :</p>
<pre><code class="language-bash ignore">    $ ma_commande &gt; nom_fichier 2&gt; erreur_log
</code></pre>
<p>Et si l'on souhaite simplement ajouter sans écraser :</p>
<pre><code class="language-bash ignore">    $ ma_commande &gt;&gt; nom_fichier 2&gt;&gt; erreur_log
</code></pre>
<p>Si l'on souhaite rediriger le fd i vers j :</p>
<pre><code class="language-bash ignore">    $ i&gt;&amp;j
</code></pre>
<p>Par exemple :</p>
<pre><code class="language-bash ignore">    $ ma_commande 2&gt;&amp;1 nom_fichier
</code></pre>
<p>redirige la stderr vers stdout.</p>
<p>Pour ouvrir un fichier et affecter un descripteur de fichier :</p>
<pre><code class="language-bash ignore">    $ exec 3&lt;&gt; nom_fichier
</code></pre>
<p>Et pour fermer le fichier :</p>
<pre><code class="language-bash ignore">    $ exec 3&gt;&amp;-
</code></pre>
<p>Cela permet d'accéder au fichier :</p>
<pre><code class="language-bash ignore">    $ exec 3&lt;&gt; nom_fichier

    $ read &lt;&amp;3         # Se déplacer d'une ligne vers le bas

    $ read -n 3 &lt;&amp;3    # Se déplacer de 3 caractères (en position 4)

    $ echo -n . &gt;&amp;3

    $ exec 3&gt;&amp;-
</code></pre>
<p>Le script ci-dessus permet par exemple de remplacer le 4ème caractère de la deuxième ligne du fichier par un point. La où le
shell se distingue réellement, c'est dans l'utilisation de pipe. Cet opérateur | permet de chaîner des programmes de façon à ce
que la sortie de l'un devienne l'entrée d'un autre :</p>
<pre><code class="language-bash ignore">    $ ls -l / | tail -n1
    $ pactl list sink-inputs | rg Volume | awk '{print $5}'
</code></pre>
<p>La première commande affiche le dernier item de la liste de fichiers du répertoire /. La deuxième affiche le pourcentage de
l'entrée son des destinations (sinks) audio (enceintes, casques etc.) Cela a de multiples avantages notamment pour
l'exploitation de fichiers de données.</p>
<p>Une commande conçue pour fonctionner avec l'opérateur pipe est xargs. xargs lit l'entrée standard et passe chaque item en
argument à la fonction suivante. Un exemple d'application :</p>
<pre><code class="language-bash ignore">    $ ls *.txt | xargs wc -l
</code></pre>
<p>La première commande liste l'ensemble des fichiers .txt et wc compte le nombre de ligne de chacun des fichiers passés en
argument.</p>
<p>Pour savoir ce qu'une commande peut faire, savoir quelle est son utilisation généralement celle-ci implémente une option --help
ou une référence (page) dans le man. Man est une commande qui renvoie une section du manuel système. Pour plus de détail :</p>
<pre><code class="language-bash ignore">    $ man man
</code></pre>
<p>Appuyer sur q pour quitter.</p>
<p>Pour reprendre l'opérateur | on peut afficher une page man et l'ouvrir au format pdf :</p>
<pre><code class="language-bash ignore">    $ man ma_commande -Tpdf | zathura -
</code></pre>
<p>Si on le souhaite (et qu'on dispose d'un lecteur pdf)...</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="un-outil-versatile-et-puissant"><a class="header" href="#un-outil-versatile-et-puissant">Un outil versatile et puissant</a></h2>
<p>Sur la plupart des systèmes Unix-like, il existe un utilisateur root. Cet utilisateur a le droit d'accéder à l'ensemble des
fichiers du système sans restriction (écriture, lecture, modification, suppression). Généralement il est dangereux de se
connecter en root sur une machine. De ce fait, on préfère donner des droits root à d'autres utilisateurs mais uniquement sur des
commandes spécifiques. Pour cela on utilise l'utilitaire sudo.</p>
<p>Par exemple, la luminosité d'un ordinateur portable apparaît dans un fichier système :</p>
<pre><code class="language-bash ignore">    /sys/class/backlight/brightness
</code></pre>
<p>En écrivant dans ce fichier on peut changer la luminosité de l'écran. Néanmoins, l'écriture doit être faite par root. En effet :</p>
<pre><code class="language-bash ignore">    $ sudo find -L /sys/class/backlight --maxdepth 2 -name &quot;*brightness&quot;

    $ sudo echo 3 &gt;/sys/class/backlight/brightness
</code></pre>
<p>Ne marche pas ! En effet, c'est le shell qui exécute l'écriture via &gt;. sudo sur la commande echo est inutile. Pour contourner le
problème on utilise un autre outil pour écrire le fichier :</p>
<pre><code class="language-bash ignore">    $ echo 3 | sudo tee /sys/class/blacklight/brightness
</code></pre>
<p>Puisque c'est le programme tee qui ouvre <em>/sys</em> pour l'écriture en tant que root, les permissions sont vérifiées. Un nombre de
choses intéressantes se trouve sous <em>/sys</em> (contrôle des périphériques, les infos cpu, mémoire etc.)</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="scripts-shell"><a class="header" href="#scripts-shell">Scripts shell</a></h2>
<p>La plupart des shells ont un langage de script qui leur est propre. Ce qui fait que le langage de script shell est différent de
langages de scripts plus traditionnels c'est qu'il est avant tout fait pour de l'administration système. Créer des commandes
pipes, écrire dans des fichiers, lire l'entrée standard etc. Dans cette section, le langage bash étant le plus répandu, c'est
celui que nous utiliserons.</p>
<p>Pour assigner des variable en bash, on utilise la syntaxe <em>foo=bar</em> et on accède au contenu de la variable avec <em>$foo</em>. <em>foo =
bar</em> ne marche pas puisque le bash l'interprète comme l'appel du programme <em>foo</em> avec 2 arguments <em>=</em> et <em>bar</em>. En général dans
les scripts shell le caractère espace sépare les arguments.</p>
<p>Les chaînes de caractères en bash peuvent être définies à l'aide des délimiteurs ' et &quot;, mais ils ne sont pas équivalents. Les
chaînes délimitées à l'aide de la simple quote sont des littéraux et ne substituent pas de variables contrairement aux chaînes
délimitées à l'aide d'une double quote :</p>
<pre><code class="language-bash ignore">    $ foo=bar
    $ echo &quot;$foo&quot;
      bar
    
    $ echo '$foo'
      $foo
</code></pre>
<p>Comme la plupart des langages de programmation, bash supporte des techniques de contrôle du flux d'exécution tel que if, case,
while et for. On peut également définir des fonctions en bash qui peuvent prendre des arguments. Exemple :</p>
<pre><code class="language-bash ignore">    mcd () {
        mkdir -p &quot;$1&quot;
        cd &quot;$1&quot;
    }
</code></pre>
<p>Ici $1 est le premier argument de la fonction. Contrairement aux autres langages de script, bash utilise un nombre assez
important de variables spéciales qui font référence à des arguments, codes d'erreurs etc. Voir liste ci-dessous :</p>
<ul>
<li>$0 - Nom du script</li>
<li>$1 à $9 - Arguments du script. $1 est le premier argument (resp. autres)</li>
<li>$@ - Tous les arguments</li>
<li>$# - Nombre d'arguments</li>
<li>$? - Code retour de la commande précédente (très utile pour une vérification par exemple)</li>
<li>$$ - Identifiant de processus (PID) du shell courant.</li>
<li>$! - Identifiant de processus (PID) de la dernière commande passée en background.</li>
<li>$_ - Dernier argument de la dernière commande. Dans un shell interactif on peut également faire Esc suivi du point.</li>
</ul>
<p>Les commandes génèrent généralement une sortie via stdout, des erreurs via stderr, et un code retour. Le code retour permet de
savoir le résultat d'exécution, qui peut être utilisé à la suite par d'autres scripts ou commandes. Généralement, une valeur de
0 signifie que tout s'est bien passé et tout autre valeur est une erreur.</p>
<p>Néanmoins, ce code peut aussi être utilisé pour des commandes conditionnées en utilisant les opérateurs &amp;&amp; (et) et || (ou). Les
commandes peuvent également être séparées sur la même ligne avec le ; . La commande true aura toujours un code retour à 0 tandis
que false aura toujours un code à 1. Exemples :</p>
<pre><code class="language-bash ignore">    false || echo &quot;Oups, raté !&quot;
    
    true || echo &quot;N'est pas affiché&quot;
    
    true &amp;&amp; echo &quot;Les choses se sont bien passées.&quot;
    
    false &amp;&amp; echo &quot;Pas affiché&quot;
    
    false ; echo &quot;Ca marche !&quot;
</code></pre>
<p>Parfois on souhaite avoir le contenu de la sortie d'une commande dans une variable. On peut le faire à l'aide d'une substitution
de commande. Quand on écrit $(commande) le bash exécutera la commande et substituera son contenu dans le script avant
l'exécution de celui-ci. Par exemple, si on écrit :</p>
<pre><code class="language-bash ignore">    for file in $(ls)
</code></pre>
<p>Le shell appellera dans un premier temps ls et parcourra ses valeurs par la suite.</p>
<p>Le bash permet également de substituer une commande de cette façon :</p>
<pre><code class="language-bash ignore">    diff &lt;(ls foo) &lt;(ls bar)
</code></pre>
<p>Cette commande montre la différence entre fichiers dans les répertoires foo et bar.</p>
<p>Puisque cela a été relativement rapide, voyons un exemple que montre quelques trucs qu'on peut faire. Le script parcourra les
arguments que nous lui donnerons, grep la chaîne foobar, et l'ajoutera comme commentaire ci celle-ci est absente.</p>
<pre><code class="language-bash ignore">    #!/bin/bash
    
    echo &quot;Début du programme à $(date)&quot; # Date sera substituée
    
    echo &quot;Exécution du program $0 avec $# arguments avec le pid $$&quot;
    
    for fichier in $@; do
        grep foobar $fichier 2&gt;&amp;1 &gt;/dev/null
        if [[ $? -ne 0 ]]; then
            echo &quot;Le fichier $fichier ne contient pas le mot foobar, ajout en cours !&quot;
            echo &quot;# foobar&quot; &gt;&gt; &quot;$fichier&quot;
        fi
    done
</code></pre>
<p>Dans le test de comparaison on teste si $? est égal à 0. Bash implémente de nombreuses comparaisons de la sorte (voir man test).
Dans un test on essaye généralement d'utiliser les doubles crochets, les chances de faire des erreurs sont moindres. Même si
cela n'est pas le standard POSIX.</p>
<p>Lors de l'exécution de scripts, on devra souvent fournir des arguments semblables. Bash rend les choses plus faciles, &quot;étendant&quot;
les expressions en supportant des expansions de nom de fichiers :</p>
<ul>
<li>Joker - On peut utiliser <em>?</em> et <em>*</em> pour respectivement vérifier 1 ou n'importe quel nombre de caractère. Par exemple, soit
les fichiers <em>foo1</em> <em>foo2</em>, <em>foo10</em> et <em>bar</em>, la commande <em>rm foo?</em> supprimera <em>foo1</em> et <em>foo2</em> alors que <em>rm foo*</em> supprimera
tout sauf <em>bar</em>.</li>
<li>Accolades <em>{}</em> - Quand il existe une sous-chaîne commune dans une série de commandes, on peut utiliser les accolades pour
étendre automatiquement. Cela peut-être pratique pour déplacer ou convertir des fichiers.</li>
</ul>
<p>Exemples :</p>
<pre><code class="language-bash ignore">    convert image.{png,jpg}
    # Deviens
    convert image.png image.jpg
    
    cp /chemin/du/projet/{foo,bar,baz}.sh /nouveau_chemin
    #Deviens
    cp /chemin/du/projet/foo.sh /chemin/du/projet/bar.sh /chemin/du/projet/baz.sh /nouveau_chemin
    
    # On peut également combiner des jokers
    mv *{.py,.sh} repertoire
    
    mkdir foo bar
    # Après la création de ces 2 répertoire,
    # La commande ci-dessous créé les fichiers foo/a foo/b, ...foo/h, bar/a, bar/b, ...
    touch {foo, bar}/{a..h}
    touch foo/x bar/y
    # Montre la différence entre les fichiers contenus dans foo et ceux dans bar
    diff &lt;(ls foo) &lt;(ls bar)
    # Sors
    # &lt; x
    # ---
    # &gt; y
</code></pre>
<p>Les scripts ne doivent pas nécessairement être écrit en bash pour être exécuté depuis le terminal. Exemple, ce script python qui
inverse les arguments qu'on lui fournit :</p>
<pre><code class="language-python ignore">    #!/usr/local/bin/python
    import sys
    for arg in reversed(sys.argv[1:]):
        print(arg)
</code></pre>
<p>Le noyau sait exécuter ce script avec le bon interpréteur grâce à l'inclusion du sheebang (la première ligne). C'est une bonne
pratique que d'inclure les sheebangs en utilisant la commande <em>env</em> (pour des question de portabilité) : <em>#!/usr/bin/env python</em>
<em>env</em> permet de résoudre où se trouve l'interpréteur via la variable d'environnement <em>PATH</em>.</p>
<blockquote>
<p>Note : Pour savoir où se trouve la commande exécutée dans le système de fichiers hiérarchique standard, on peut utiliser la
commande <em>which</em>.</p>
</blockquote>
<p>Quelques différences entre les fonctions shell et les scripts shell à garder en tête sont :</p>
<ul>
<li>Les fonctions doivent être écrites dans le même langage shell, alors que les scripts n'ont pas cette contrainte. D'où
l'utilité du sheebang.</li>
<li>Les fonctions sont chargées une fois que leur définition est lue. Les scripts sont chargés à chaque exécution.</li>
<li>Les fonctions sont exécutées dans le shell courant alors que les scripts exécutent leurs propres processus. Les fonctions
peuvent donc modifier des variables d'environnement, par exemple changer le répertoire de travail. A ce titre, les scripts
peuvent hériter de variables d'environnement si celles-ci ont été exportées précédemment à l'aide du mot-clef <em>export</em>.</li>
<li>Comme avec n'importe quel langage de programmation, les fonctions sont des outils modulaires permettant une réutilisation et
une meilleure clarté du code.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
